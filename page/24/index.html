<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/uploads/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/uploads/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.ligoudan.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="天气不错哇，你看这大冰雹下得">
<meta property="og:type" content="website">
<meta property="og:title" content="LIGOUDAN">
<meta property="og:url" content="https://www.ligoudan.cn/page/24/index.html">
<meta property="og:site_name" content="LIGOUDAN">
<meta property="og:description" content="天气不错哇，你看这大冰雹下得">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="李狗蛋">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.ligoudan.cn/page/24/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/24/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LIGOUDAN</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LIGOUDAN</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">好好学习，天天向上</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">326</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">137</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">462</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="李狗蛋"
      src="/uploads/ligoudan.png">
  <p class="site-author-name" itemprop="name">李狗蛋</p>
  <div class="site-description" itemprop="description">天气不错哇，你看这大冰雹下得</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">462</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">137</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">326</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yiyirushi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yiyirushi" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yuanhaohoo@163.com" title="E-Mail → mailto:yuanhaohoo@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/db5b69/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/db5b69/" class="post-title-link" itemprop="url">Java 内存管理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-28 16:19:00" itemprop="dateCreated datePublished" datetime="2020-06-28T16:19:00+08:00">2020-06-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/JavaSE/" itemprop="url" rel="index"><span itemprop="name">JavaSE</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/JavaSE/JVM/" itemprop="url" rel="index"><span itemprop="name">JVM</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Java-内存管理"><a href="#Java-内存管理" class="headerlink" title="Java 内存管理"></a>Java 内存管理</h1><h2 id="内存简介"><a href="#内存简介" class="headerlink" title="内存简介"></a>内存简介</h2><h3 id="物理内存和虚拟内存"><a href="#物理内存和虚拟内存" class="headerlink" title="物理内存和虚拟内存"></a>物理内存和虚拟内存</h3><p>所谓物理内存就是通常所说的 RAM（随机存储器）。</p>
<p>虚拟内存使得多个进程在同时运行时可以共享物理内存，这里的共享只是空间上共享，在逻辑上彼此仍然是隔离的。</p>
<h3 id="内核空间和用户空间"><a href="#内核空间和用户空间" class="headerlink" title="内核空间和用户空间"></a>内核空间和用户空间</h3><p>一个计算通常有固定大小的内存空间，但是程序并不能使用全部的空间。因为这些空间被划分为内核空间和用户空间，而程序只能使用用户空间的内存。</p>
<h3 id="使用内存的-Java-组件"><a href="#使用内存的-Java-组件" class="headerlink" title="使用内存的 Java 组件"></a>使用内存的 Java 组件</h3><p>Java 启动后，作为一个进程运行在操作系统中。</p>
<p>有哪些 Java 组件需要占用内存呢？</p>
<ul>
<li>堆内存：Java 堆、类和类加载器</li>
<li>栈内存：线程</li>
<li>本地内存：NIO、JNI</li>
</ul>
<h2 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h2><p>JVM 在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javacore/jvm/jvm-memory-runtime-data-area.png" alt="img"></p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p><strong><code>程序计数器（Program Counter Register）</code></strong> 是一块较小的内存空间，它可以看做是<strong>当前线程所执行的字节码的行号指示器</strong>。例如，分支、循环、跳转、异常、线程恢复等都依赖于计数器。</p>
<p>当执行的线程数量超过 CPU 数量时，线程之间会根据时间片轮询争夺 CPU 资源。如果一个线程的时间片用完了，或者是其它原因导致这个线程的 CPU 资源被提前抢夺，那么这个退出的线程就需要单独的一个程序计数器，来记录下一条运行的指令，从而在线程切换后能恢复到正确的执行位置。各条线程间的计数器互不影响，独立存储，我们称这类内存区域为 “线程私有” 的内存。</p>
<ul>
<li>如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；</li>
<li>如果正在执行的是 Native 方法，这个计数器值则为空（Undefined）。</li>
</ul>
<blockquote>
<p>🔔 注意：此内存区域是唯一一个在 JVM 中没有规定任何 <code>OutOfMemoryError</code> 情况的区域。</p>
</blockquote>
<h3 id="Java-虚拟机栈"><a href="#Java-虚拟机栈" class="headerlink" title="Java 虚拟机栈"></a>Java 虚拟机栈</h3><p><strong><code>Java 虚拟机栈（Java Virtual Machine Stacks）</code></strong> 也<strong>是线程私有的，它的生命周期与线程相同</strong>。</p>
<p>每个 Java 方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储 <strong>局部变量表</strong>、<strong>操作数栈</strong>、<strong>常量池引用</strong> 等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javacore/jvm/jvm-stack.png!w640" alt="img"></p>
<ul>
<li><strong>局部变量表</strong> - 32 位变量槽，存放了编译期可知的各种基本数据类型、对象引用、<code>ReturnAddress</code> 类型。</li>
<li><strong>操作数栈</strong> - 基于栈的执行引擎，虚拟机把操作数栈作为它的工作区，大多数指令都要从这里弹出数据、执行运算，然后把结果压回操作数栈。</li>
<li><strong>动态链接</strong> - 每个栈帧都包含一个指向运行时常量池（方法区的一部分）中该栈帧所属方法的引用。持有这个引用是为了支持方法调用过程中的动态连接。Class 文件的常量池中有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用，这种转化称为静态解析。另一部分将在每一次的运行期间转化为直接应用，这部分称为动态链接。</li>
<li><strong>方法出口</strong> - 返回方法被调用的位置，恢复上层方法的局部变量和操作数栈，如果无返回值，则把它压入调用者的操作数栈。</li>
</ul>
<blockquote>
<p>🔔 注意：</p>
<p>该区域可能抛出以下异常：</p>
<ul>
<li>如果线程请求的栈深度超过最大值，就会抛出 <code>StackOverflowError</code> 异常；</li>
<li>如果虚拟机栈进行动态扩展时，无法申请到足够内存，就会抛出 <code>OutOfMemoryError</code> 异常。</li>
</ul>
<p>💡 提示：</p>
<p>可以通过 <code>-Xss</code> 这个虚拟机参数来指定一个程序的 Java 虚拟机栈内存大小：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -Xss=512M HackTheJava</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p><strong><code>本地方法栈（Native Method Stack）</code></strong> 与虚拟机栈的作用相似。</p>
<p>二者的区别在于：<strong>虚拟机栈为 Java 方法服务；本地方法栈为 Native 方法服务</strong>。本地方法并不是用 Java 实现的，而是由 C 语言实现的。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javacore/jvm/jvm-native-method-stack.gif!w640" alt="img"></p>
<blockquote>
<p>🔔 注意：本地方法栈也会抛出 <code>StackOverflowError</code> 异常和 <code>OutOfMemoryError</code> 异常。</p>
</blockquote>
<h3 id="Java-堆"><a href="#Java-堆" class="headerlink" title="Java 堆"></a>Java 堆</h3><p><strong><code>Java 堆（Java Heap）</code> 的作用就是存放对象实例，几乎所有的对象实例都是在这里分配内存</strong>。</p>
<p>Java 堆是垃圾收集的主要区域（因此也被叫做”GC 堆”）。现代的垃圾收集器基本都是采用<strong>分代收集算法</strong>，该算法的思想是针对不同的对象采取不同的垃圾回收算法。</p>
<p>因此虚拟机把 Java 堆分成以下三块：</p>
<ul>
<li><strong><code>新生代（Young Generation）</code></strong><ul>
<li><code>Eden</code> - Eden 和 Survivor 的比例为 8:1</li>
<li><code>From Survivor</code></li>
<li><code>To Survivor</code></li>
</ul>
</li>
<li><strong><code>老年代（Old Generation）</code></strong></li>
<li><strong><code>永久代（Permanent Generation）</code></strong></li>
</ul>
<p>当一个对象被创建时，它首先进入新生代，之后有可能被转移到老年代中。新生代存放着大量的生命很短的对象，因此新生代在三个区域中垃圾回收的频率最高。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javacore/jvm/jvm-heap.gif!w640" alt="img"></p>
<blockquote>
<p>🔔 注意：Java 堆不需要连续内存，并且可以动态扩展其内存，扩展失败会抛出 <code>OutOfMemoryError</code> 异常。</p>
<p>💡 提示：可以通过 <code>-Xms</code> 和 <code>-Xmx</code> 两个虚拟机参数来指定一个程序的 Java 堆内存大小，第一个参数设置初始值，第二个参数设置最大值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -Xms=1M -Xmx=2M HackTheJava</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>方法区（Method Area）也被称为永久代。<strong>方法区用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据</strong>。</p>
<p>对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。</p>
<blockquote>
<p>🔔 注意：和 Java 堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 <code>OutOfMemoryError</code> 异常。</p>
<p>💡 提示：</p>
<ul>
<li>JDK 1.7 之前，HotSpot 虚拟机把它当成永久代来进行垃圾回收。可通过参数 <code>-XX:PermSize</code> 和 <code>-XX:MaxPermSize</code> 设置。</li>
<li>JDK 1.8 之后，取消了永久代，用 **<code>metaspace（元数据）</code>**区替代。可通过参数 <code>-XX:MaxMetaspaceSize</code> 设置。</li>
</ul>
</blockquote>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p><strong><code>运行时常量池（Runtime Constant Pool）</code> 是方法区的一部分</strong>，Class 文件中除了有类的版本、字段、方法、接口等描述信息，还有一项信息是常量池（Constant Pool Table），<strong>用于存放编译器生成的各种字面量和符号引用</strong>，这部分内容会在类加载后被放入这个区域。</p>
<ul>
<li><strong>字面量</strong> - 文本字符串、声明为 <code>final</code> 的常量值等。</li>
<li><strong>符号引用</strong> - 类和接口的完全限定名（Fully Qualified Name）、字段的名称和描述符（Descriptor）、方法的名称和描述符。</li>
</ul>
<p>除了在编译期生成的常量，还允许动态生成，例如 <code>String</code> 类的 <code>intern()</code>。这部分常量也会被放入运行时常量池。</p>
<blockquote>
<p>🔔 注意：当常量池无法再申请到内存时会抛出 <code>OutOfMemoryError</code> 异常。</p>
</blockquote>
<h3 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h3><p>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 JVM 规范中定义的内存区域。</p>
<p>在 JDK 1.4 中新加入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里的 <code>DirectByteBuffer</code> 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。</p>
<blockquote>
<p>🔔 注意：直接内存这部分也被频繁的使用，且也可能导致 <code>OutOfMemoryError</code> 异常。</p>
<p>💡 提示：直接内存容量可通过 <code>-XX:MaxDirectMemorySize</code> 指定，如果不指定，则默认与 Java 堆最大值（<code>-Xmx</code> 指定）一样。</p>
</blockquote>
<h3 id="Java-内存区域对比"><a href="#Java-内存区域对比" class="headerlink" title="Java 内存区域对比"></a>Java 内存区域对比</h3><table>
<thead>
<tr>
<th>内存区域</th>
<th>内存作用范围</th>
<th>异常</th>
</tr>
</thead>
<tbody><tr>
<td>程序计数器</td>
<td>线程私有</td>
<td>无</td>
</tr>
<tr>
<td>Java 虚拟机栈</td>
<td>线程私有</td>
<td><code>StackOverflowError</code> 和 <code>OutOfMemoryError</code></td>
</tr>
<tr>
<td>本地方法栈</td>
<td>线程私有</td>
<td><code>StackOverflowError</code> 和 <code>OutOfMemoryError</code></td>
</tr>
<tr>
<td>Java 堆</td>
<td>线程共享</td>
<td><code>OutOfMemoryError</code></td>
</tr>
<tr>
<td>方法区</td>
<td>线程共享</td>
<td><code>OutOfMemoryError</code></td>
</tr>
<tr>
<td>运行时常量池</td>
<td>线程共享</td>
<td><code>OutOfMemoryError</code></td>
</tr>
<tr>
<td>直接内存</td>
<td>非运行时数据区</td>
<td><code>OutOfMemoryError</code></td>
</tr>
</tbody></table>
<h2 id="JVM-运行原理"><a href="#JVM-运行原理" class="headerlink" title="JVM 运行原理"></a>JVM 运行原理</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JVMCase</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 常量</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">MAN_SEX_TYPE</span> <span class="operator">=</span> <span class="string">&quot;man&quot;</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 静态变量</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">WOMAN_SEX_TYPE</span> <span class="operator">=</span> <span class="string">&quot;woman&quot;</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="type">Student</span> <span class="variable">stu</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>();</span><br><span class="line">		stu.setName(<span class="string">&quot;nick&quot;</span>);</span><br><span class="line">		stu.setSexType(MAN_SEX_TYPE);</span><br><span class="line">		stu.setAge(<span class="number">20</span>);</span><br><span class="line"></span><br><span class="line">		<span class="type">JVMCase</span> <span class="variable">jvmcase</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JVMCase</span>();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 调用静态方法</span></span><br><span class="line">		print(stu);</span><br><span class="line">		<span class="comment">// 调用非静态方法</span></span><br><span class="line">		jvmcase.sayHello(stu);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 常规静态方法</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(Student stu)</span> &#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;name: &quot;</span> + stu.getName() + <span class="string">&quot;; sex:&quot;</span> + stu.getSexType() + <span class="string">&quot;; age:&quot;</span> + stu.getAge());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 非静态方法</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sayHello</span><span class="params">(Student stu)</span> &#123;</span><br><span class="line">		System.out.println(stu.getName() + <span class="string">&quot;say: hello&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>&#123;</span><br><span class="line">	String name;</span><br><span class="line">	String sexType;</span><br><span class="line">	<span class="type">int</span> age;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> name;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.name = name;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getSexType</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> sexType;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSexType</span><span class="params">(String sexType)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.sexType = sexType;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> age;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(<span class="type">int</span> age)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.age = age;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行以上代码时，JVM 处理过程如下：</p>
<p>（1）JVM 向操作系统申请内存，JVM 第一步就是通过配置参数或者默认配置参数向操作系统申请内存空间，根据内存大小找到具体的内存分配表，然后把内存段的起始地址和终止地址分配给 JVM，接下来 JVM 就进行内部分配。</p>
<p>（2）JVM 获得内存空间后，会根据配置参数分配堆、栈以及方法区的内存大小。</p>
<p>（3）class 文件加载、验证、准备以及解析，其中准备阶段会为类的静态变量分配内存，初始化为系统的初始值（这部分我在第 21 讲还会详细介绍）。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200630094250.png" alt="img"></p>
<p>（4）完成上一个步骤后，将会进行最后一个初始化阶段。在这个阶段中，JVM 首先会执行构造器 <code>&lt;clinit&gt;</code> 方法，编译器会在 <code>.java</code> 文件被编译成 <code>.class</code> 文件时，收集所有类的初始化代码，包括静态变量赋值语句、静态代码块、静态方法，收集在一起成为 <code>&lt;clinit&gt;()</code> 方法。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200630094329.png" alt="img"></p>
<p>（5）执行方法。启动 main 线程，执行 main 方法，开始执行第一行代码。此时堆内存中会创建一个 student 对象，对象引用 student 就存放在栈中。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200630094651.png" alt="img"></p>
<p>（6）此时再次创建一个 JVMCase 对象，调用 sayHello 非静态方法，sayHello 方法属于对象 JVMCase，此时 sayHello 方法入栈，并通过栈中的 student 引用调用堆中的 Student 对象；之后，调用静态方法 print，print 静态方法属于 JVMCase 类，是从静态方法中获取，之后放入到栈中，也是通过 student 引用调用堆中的 student 对象。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200630094714.png" alt="img"></p>
<h2 id="OutOfMemoryError"><a href="#OutOfMemoryError" class="headerlink" title="OutOfMemoryError"></a>OutOfMemoryError</h2><h3 id="什么是-OutOfMemoryError"><a href="#什么是-OutOfMemoryError" class="headerlink" title="什么是 OutOfMemoryError"></a>什么是 OutOfMemoryError</h3><p><code>OutOfMemoryError</code> 简称为 OOM。Java 中对 OOM 的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。通俗的解释是：JVM 内存不足了。</p>
<p>在 JVM 规范中，<strong>除了程序计数器区域外，其他运行时区域都可能发生 <code>OutOfMemoryError</code> 异常（简称 OOM）</strong>。</p>
<p>下面逐一介绍 OOM 发生场景。</p>
<h3 id="堆空间溢出"><a href="#堆空间溢出" class="headerlink" title="堆空间溢出"></a>堆空间溢出</h3><p><code>java.lang.OutOfMemoryError: Java heap space</code> 这个错误意味着：<strong>堆空间溢出</strong>。</p>
<p>更细致的说法是：Java 堆内存已经达到 <code>-Xmx</code> 设置的最大值。Java 堆用于存储对象实例，只要不断地创建对象，并且保证 GC Roots 到对象之间有可达路径来避免垃圾收集器回收这些对象，那么当堆空间到达最大容量限制后就会产生 OOM。</p>
<p>堆空间溢出有可能是**<code>内存泄漏（Memory Leak）</code>** 或 <strong><code>内存溢出（Memory Overflow）</code></strong> 。需要使用 jstack 和 jmap 生成 threaddump 和 heapdump，然后用内存分析工具（如：MAT）进行分析。</p>
<h4 id="Java-heap-space-分析步骤"><a href="#Java-heap-space-分析步骤" class="headerlink" title="Java heap space 分析步骤"></a>Java heap space 分析步骤</h4><ol>
<li>使用 <code>jmap</code> 或 <code>-XX:+HeapDumpOnOutOfMemoryError</code> 获取堆快照。</li>
<li>使用内存分析工具（visualvm、mat、jProfile 等）对堆快照文件进行分析。</li>
<li>根据分析图，重点是确认内存中的对象是否是必要的，分清究竟是是内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。</li>
</ol>
<h4 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h4><p><strong>内存泄漏是指由于疏忽或错误造成程序未能释放已经不再使用的内存的情况</strong>。</p>
<p>内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。内存泄漏随着被执行的次数不断增加，最终会导致内存溢出。</p>
<p>内存泄漏常见场景：</p>
<ul>
<li>静态容器<ul>
<li>声明为静态（<code>static</code>）的 <code>HashMap</code>、<code>Vector</code> 等集合</li>
<li>通俗来讲 A 中有 B，当前只把 B 设置为空，A 没有设置为空，回收时 B 无法回收。因为被 A 引用。</li>
</ul>
</li>
<li>监听器<ul>
<li>监听器被注册后释放对象时没有删除监听器</li>
</ul>
</li>
<li>物理连接<ul>
<li>各种连接池建立了连接，必须通过 <code>close()</code> 关闭链接</li>
</ul>
</li>
<li>内部类和外部模块等的引用<ul>
<li>发现它的方式同内存溢出，可再加个实时观察</li>
<li><code>jstat -gcutil 7362 2500 70</code></li>
</ul>
</li>
</ul>
<p>重点关注：</p>
<ul>
<li><code>FGC</code> — 从应用程序启动到采样时发生 Full GC 的次数。</li>
<li><code>FGCT</code> — 从应用程序启动到采样时 Full GC 所用的时间（单位秒）。</li>
<li><code>FGC</code> 次数越多，<code>FGCT</code> 所需时间越多，越有可能存在内存泄漏。</li>
</ul>
<p>如果是内存泄漏，可以进一步查看泄漏对象到 GC Roots 的对象引用链。这样就能找到泄漏对象是怎样与 GC Roots 关联并导致 GC 无法回收它们的。掌握了这些原因，就可以较准确的定位出引起内存泄漏的代码。</p>
<p>导致内存泄漏的常见原因是使用容器，且不断向容器中添加元素，但没有清理，导致容器内存不断膨胀。</p>
<p>【示例】</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 内存泄漏示例</span></span><br><span class="line"><span class="comment"> * 错误现象：java.lang.OutOfMemoryError: Java heap space</span></span><br><span class="line"><span class="comment"> * VM Args：-verbose:gc -Xms10M -Xmx10M -XX:+HeapDumpOnOutOfMemoryError</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HeapOutOfMemoryDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        List&lt;OomObject&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            list.add(<span class="keyword">new</span> <span class="title class_">OomObject</span>());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">OomObject</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h4><p>如果不存在内存泄漏，即内存中的对象确实都必须存活着，则应当检查虚拟机的堆参数（<code>-Xmx</code> 和 <code>-Xms</code>），与机器物理内存进行对比，看看是否可以调大。并从代码上检查是否存在某些对象生命周期过长、持有时间过长的情况，尝试减少程序运行期的内存消耗。</p>
<p>【示例】</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 堆溢出示例</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 错误现象：java.lang.OutOfMemoryError: Java heap space</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * VM Args：-verbose:gc -Xms10M -Xmx10M</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> &lt;a href=&quot;mailto:forbreak@163.com&quot;&gt;Zhang Peng&lt;/a&gt;</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019-06-25</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HeapOutOfMemoryDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        Double[] array = <span class="keyword">new</span> <span class="title class_">Double</span>[<span class="number">999999999</span>];</span><br><span class="line">        System.out.println(<span class="string">&quot;array length = [&quot;</span> + array.length + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行 <code>java -verbose:gc -Xms10M -Xmx10M -XX:+HeapDumpOnOutOfMemoryError io.github.dunwu.javacore.jvm.memory.HeapMemoryLeakMemoryErrorDemo</code></p>
<p>上面的例子是一个极端的例子，试图创建一个维度很大的数组，堆内存无法分配这么大的内存，从而报错：<code>Java heap space</code>。</p>
<p>但如果在现实中，代码并没有问题，仅仅是因为堆内存不足，可以通过 <code>-Xms</code> 和 <code>-Xmx</code> 适当调整堆内存大小。</p>
<h3 id="GC-开销超过限制"><a href="#GC-开销超过限制" class="headerlink" title="GC 开销超过限制"></a>GC 开销超过限制</h3><p><code>java.lang.OutOfMemoryError: GC overhead limit exceeded</code> 这个错误，官方给出的定义是：<strong>超过 <code>98%</code> 的时间用来做 GC 并且回收了不到 <code>2%</code> 的堆内存时会抛出此异常</strong>。这意味着，发生在 GC 占用大量时间为释放很小空间的时候发生的，是一种保护机制。导致异常的原因：一般是因为堆太小，没有足够的内存。</p>
<p>【示例】</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * GC overhead limit exceeded 示例</span></span><br><span class="line"><span class="comment"> * 错误现象：java.lang.OutOfMemoryError: GC overhead limit exceeded</span></span><br><span class="line"><span class="comment"> * 发生在GC占用大量时间为释放很小空间的时候发生的，是一种保护机制。导致异常的原因：一般是因为堆太小，没有足够的内存。</span></span><br><span class="line"><span class="comment"> * 官方对此的定义：超过98%的时间用来做GC并且回收了不到2%的堆内存时会抛出此异常。</span></span><br><span class="line"><span class="comment"> * VM Args: -Xms10M -Xmx10M</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GcOverheadLimitExceededDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        List&lt;Double&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="type">double</span> <span class="variable">d</span> <span class="operator">=</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            list.add(d++);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>【处理】</p>
<p>与 <strong>Java heap space</strong> 错误处理方法类似，先判断是否存在内存泄漏。如果有，则修正代码；如果没有，则通过 <code>-Xms</code> 和 <code>-Xmx</code> 适当调整堆内存大小。</p>
<h3 id="永久代空间不足"><a href="#永久代空间不足" class="headerlink" title="永久代空间不足"></a>永久代空间不足</h3><p>【错误】</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java<span class="selector-class">.lang</span><span class="selector-class">.OutOfMemoryError</span>: PermGen space</span><br></pre></td></tr></table></figure>

<p>【原因】</p>
<p>Perm （永久代）空间主要用于存放 <code>Class</code> 和 Meta 信息，包括类的名称和字段，带有方法字节码的方法，常量池信息，与类关联的对象数组和类型数组以及即时编译器优化。GC 在主程序运行期间不会对永久代空间进行清理，默认是 64M 大小。</p>
<p>根据上面的定义，可以得出 <strong>PermGen 大小要求取决于加载的类的数量以及此类声明的大小</strong>。因此，可以说造成该错误的主要原因是永久代中装入了太多的类或太大的类。</p>
<p>在 JDK8 之前的版本中，可以通过 <code>-XX:PermSize</code> 和 <code>-XX:MaxPermSize</code> 设置永久代空间大小，从而限制方法区大小，并间接限制其中常量池的容量。</p>
<h4 id="初始化时永久代空间不足"><a href="#初始化时永久代空间不足" class="headerlink" title="初始化时永久代空间不足"></a>初始化时永久代空间不足</h4><p>【示例】</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 永久代内存空间不足示例</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 错误现象：</span></span><br><span class="line"><span class="comment"> * &lt;ul&gt;</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;java.lang.OutOfMemoryError: PermGen space (JDK8 以前版本)&lt;/li&gt;</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;java.lang.OutOfMemoryError: Metaspace (JDK8 及以后版本)&lt;/li&gt;</span></span><br><span class="line"><span class="comment"> * &lt;/ul&gt;</span></span><br><span class="line"><span class="comment"> * VM Args:</span></span><br><span class="line"><span class="comment"> * &lt;ul&gt;</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;-Xmx100M -XX:MaxPermSize=16M (JDK8 以前版本)&lt;/li&gt;</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;-Xmx100M -XX:MaxMetaspaceSize=16M (JDK8 及以后版本)&lt;/li&gt;</span></span><br><span class="line"><span class="comment"> * &lt;/ul&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PermOutOfMemoryErrorDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100_000_000</span>; i++) &#123;</span><br><span class="line">            generate(<span class="string">&quot;eu.plumbr.demo.Generated&quot;</span> + i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Class <span class="title function_">generate</span><span class="params">(String name)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">ClassPool</span> <span class="variable">pool</span> <span class="operator">=</span> ClassPool.getDefault();</span><br><span class="line">        <span class="keyword">return</span> pool.makeClass(name).toClass();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在此示例中，源代码遍历循环并在运行时生成类。javassist 库正在处理类生成的复杂性。</p>
<h4 id="重部署时永久代空间不足"><a href="#重部署时永久代空间不足" class="headerlink" title="重部署时永久代空间不足"></a>重部署时永久代空间不足</h4><p>对于更复杂，更实际的示例，让我们逐步介绍一下在应用程序重新部署期间发生的 Permgen 空间错误。重新部署应用程序时，你希望垃圾回收会摆脱引用所有先前加载的类的加载器，并被加载新类的类加载器取代。</p>
<p>不幸的是，许多第三方库以及对线程，JDBC 驱动程序或文件系统句柄等资源的不良处理使得无法卸载以前使用的类加载器。反过来，这意味着在每次重新部署期间，所有先前版本的类仍将驻留在 PermGen 中，从而在每次重新部署期间生成数十兆的垃圾。</p>
<p>让我们想象一个使用 JDBC 驱动程序连接到关系数据库的示例应用程序。启动应用程序时，初始化代码将加载 JDBC 驱动程序以连接到数据库。对应于规范，JDBC 驱动程序向 java.sql.DriverManager 进行注册。该注册包括将对驱动程序实例的引用存储在 DriverManager 的静态字段中。</p>
<p>现在，当从应用程序服务器取消部署应用程序时，java.sql.DriverManager 仍将保留该引用。我们最终获得了对驱动程序类的实时引用，而驱动程序类又保留了用于加载应用程序的 java.lang.Classloader 实例的引用。反过来，这意味着垃圾回收算法无法回收空间。</p>
<p>而且该 java.lang.ClassLoader 实例仍引用应用程序的所有类，通常在 PermGen 中占据数十兆字节。这意味着只需少量重新部署即可填充通常大小的 PermGen。</p>
<h4 id="PermGen-space-解决方案"><a href="#PermGen-space-解决方案" class="headerlink" title="PermGen space 解决方案"></a>PermGen space 解决方案</h4><p>（1）解决初始化时的 <code>OutOfMemoryError</code></p>
<p>在应用程序启动期间触发由于 PermGen 耗尽导致的 <code>OutOfMemoryError</code> 时，解决方案很简单。该应用程序仅需要更多空间才能将所有类加载到 PermGen 区域，因此我们只需要增加其大小即可。为此，更改你的应用程序启动配置并添加（或增加，如果存在）<code>-XX:MaxPermSize</code> 参数，类似于以下示例：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -XX:<span class="attribute">MaxPermSize</span>=512m com.yourcompany.YourClass</span><br></pre></td></tr></table></figure>

<p>上面的配置将告诉 JVM，PermGen 可以增长到 512MB。</p>
<p>清理应用程序中 <code>WEB-INF/lib</code> 下的 jar，用不上的 jar 删除掉，多个应用公共的 jar 移动到 Tomcat 的 lib 目录，减少重复加载。</p>
<p>🔔 注意：<code>-XX:PermSize</code> 一般设为 64M</p>
<p>（2）解决重新部署时的 <code>OutOfMemoryError</code></p>
<p>重新部署应用程序后立即发生 OutOfMemoryError 时，应用程序会遭受类加载器泄漏的困扰。在这种情况下，解决问题的最简单，继续进行堆转储分析–使用类似于以下命令的重新部署后进行堆转储：</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -<span class="keyword">dump</span>:format=b,<span class="keyword">file</span>=<span class="keyword">dump</span>.hprof &lt;process-id&gt;</span><br></pre></td></tr></table></figure>

<p>然后使用你最喜欢的堆转储分析器打开转储（Eclipse MAT 是一个很好的工具）。在分析器中可以查找重复的类，尤其是那些正在加载应用程序类的类。从那里，你需要进行所有类加载器的查找，以找到当前活动的类加载器。</p>
<p>对于非活动类加载器，你需要通过从非活动类加载器收集到 GC 根的最短路径来确定阻止它们被垃圾收集的引用。有了此信息，你将找到根本原因。如果根本原因是在第三方库中，则可以进入 Google&#x2F;StackOverflow 查看是否是已知问题以获取补丁&#x2F;解决方法。</p>
<p>（3）解决运行时 <code>OutOfMemoryError</code></p>
<p>第一步是检查是否允许 GC 从 PermGen 卸载类。在这方面，标准的 JVM 相当保守-类是天生的。因此，一旦加载，即使没有代码在使用它们，类也会保留在内存中。当应用程序动态创建许多类并且长时间不需要生成的类时，这可能会成为问题。在这种情况下，允许 JVM 卸载类定义可能会有所帮助。这可以通过在启动脚本中仅添加一个配置参数来实现：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+CMSClassUnloadingEnabled</span></span><br></pre></td></tr></table></figure>

<p>默认情况下，此选项设置为 false，因此要启用此功能，你需要在 Java 选项中显式设置。如果启用 CMSClassUnloadingEnabled，GC 也会扫描 PermGen 并删除不再使用的类。请记住，只有同时使用 UseConcMarkSweepGC 时此选项才起作用。</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+UseConcMarkSweepGC</span></span><br></pre></td></tr></table></figure>

<p>在确保可以卸载类并且问题仍然存在之后，你应该继续进行堆转储分析–使用类似于以下命令的方法进行堆转储：</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -<span class="keyword">dump</span>:<span class="keyword">file</span>=<span class="keyword">dump</span>.hprof,format=b &lt;process-id&gt;</span><br></pre></td></tr></table></figure>

<p>然后，使用你最喜欢的堆转储分析器（例如 Eclipse MAT）打开转储，然后根据已加载的类数查找最昂贵的类加载器。从此类加载器中，你可以继续提取已加载的类，并按实例对此类进行排序，以使可疑对象排在首位。</p>
<p>然后，对于每个可疑者，就需要你手动将根本原因追溯到生成此类的应用程序代码。</p>
<h3 id="元数据区空间不足"><a href="#元数据区空间不足" class="headerlink" title="元数据区空间不足"></a>元数据区空间不足</h3><p>【错误】</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Exception</span> <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.lang.<span class="built_in">OutOfMemoryError</span>: Metaspace</span><br></pre></td></tr></table></figure>

<p>【原因】</p>
<p>Java8 以后，JVM 内存空间发生了很大的变化。取消了永久代，转而变为元数据区。</p>
<p><strong>元数据区的内存不足，即方法区和运行时常量池的空间不足</strong>。</p>
<p>方法区用于存放 Class 的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。</p>
<p>一个类要被垃圾收集器回收，判定条件是比较苛刻的。在经常动态生成大量 Class 的应用中，需要特别注意类的回收状况。这类常见除了 CGLib 字节码增强和动态语言以外，常见的还有：大量 JSP 或动态产生 JSP 文件的应用（JSP 第一次运行时需要编译为 Java 类）、基于 OSGi 的应用（即使是同一个类文件，被不同的加载器加载也会视为不同的类）等。</p>
<p>【示例】方法区出现 <code>OutOfMemoryError</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MethodAreaOutOfMemoryDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="type">Enhancer</span> <span class="variable">enhancer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Enhancer</span>();</span><br><span class="line">            enhancer.setSuperclass(Bean.class);</span><br><span class="line">            enhancer.setUseCache(<span class="literal">false</span>);</span><br><span class="line">            enhancer.setCallback(<span class="keyword">new</span> <span class="title class_">MethodInterceptor</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> Object <span class="title function_">intercept</span><span class="params">(Object obj, Method method, Object[] args, MethodProxy proxy)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">                    <span class="keyword">return</span> proxy.invokeSuper(obj, args);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            enhancer.create();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Bean</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>【解决】</p>
<p>当由于元空间而面临 <code>OutOfMemoryError</code> 时，第一个解决方案应该是显而易见的。如果应用程序耗尽了内存中的 Metaspace 区域，则应增加 Metaspace 的大小。更改应用程序启动配置并增加以下内容：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:<span class="attribute">MaxMetaspaceSize</span>=512m</span><br></pre></td></tr></table></figure>

<p>上面的配置示例告诉 JVM，允许 Metaspace 增长到 512 MB。</p>
<p>另一种解决方案甚至更简单。你可以通过删除此参数来完全解除对 Metaspace 大小的限制，JVM 默认对 Metaspace 的大小没有限制。但是请注意以下事实：这样做可能会导致大量交换或达到本机物理内存而分配失败。</p>
<h3 id="无法新建本地线程"><a href="#无法新建本地线程" class="headerlink" title="无法新建本地线程"></a>无法新建本地线程</h3><p><code>java.lang.OutOfMemoryError: Unable to create new native thread</code> 这个错误意味着：<strong>Java 应用程序已达到其可以启动线程数的限制</strong>。</p>
<p>【原因】</p>
<p>当发起一个线程的创建时，虚拟机会在 JVM 内存创建一个 <code>Thread</code> 对象同时创建一个操作系统线程，而这个系统线程的内存用的不是 JVM 内存，而是系统中剩下的内存。</p>
<p>那么，究竟能创建多少线程呢？这里有一个公式：</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">线程数 = <span class="comment">(MaxProcessMemory - JVMMemory - ReservedOsMemory)</span> / <span class="comment">(ThreadStackSize)</span></span><br></pre></td></tr></table></figure>

<p>【参数】</p>
<ul>
<li><code>MaxProcessMemory</code> - 一个进程的最大内存</li>
<li><code>JVMMemory</code> - JVM 内存</li>
<li><code>ReservedOsMemory</code> - 保留的操作系统内存</li>
<li><code>ThreadStackSize</code> - 线程栈的大小</li>
</ul>
<p>**给 JVM 分配的内存越多，那么能用来创建系统线程的内存就会越少，越容易发生 <code>unable to create new native thread</code>**。所以，JVM 内存不是分配的越大越好。</p>
<p>但是，通常导致 <code>java.lang.OutOfMemoryError</code> 的情况：无法创建新的本机线程需要经历以下阶段：</p>
<ol>
<li>JVM 内部运行的应用程序请求新的 Java 线程</li>
<li>JVM 本机代码代理为操作系统创建新本机线程的请求</li>
<li>操作系统尝试创建一个新的本机线程，该线程需要将内存分配给该线程</li>
<li>操作系统将拒绝本机内存分配，原因是 32 位 Java 进程大小已耗尽其内存地址空间（例如，已达到（2-4）GB 进程大小限制）或操作系统的虚拟内存已完全耗尽</li>
<li>引发 <code>java.lang.OutOfMemoryError: Unable to create new native thread</code> 错误。</li>
</ol>
<p>【示例】</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UnableCreateNativeThreadErrorDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        TimeUnit.MINUTES.sleep(<span class="number">5</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>【处理】</p>
<p>可以通过增加操作系统级别的限制来绕过无法创建新的本机线程问题。例如，如果限制了 JVM 可在用户空间中产生的进程数，则应检查出并可能增加该限制：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@dev ~]# ulimit -a</span><br><span class="line">core file size          (blocks, -c) 0</span><br><span class="line">--- cut for brevity ---</span><br><span class="line">max user processes              (-u) 1800</span><br></pre></td></tr></table></figure>

<p>通常，<code>OutOfMemoryError</code> 对新的本机线程的限制表示编程错误。当应用程序产生数千个线程时，很可能出了一些问题—很少有应用程序可以从如此大量的线程中受益。</p>
<p>解决问题的一种方法是开始进行线程转储以了解情况。</p>
<h3 id="直接内存溢出"><a href="#直接内存溢出" class="headerlink" title="直接内存溢出"></a>直接内存溢出</h3><p>由直接内存导致的内存溢出，一个明显的特征是在 Head Dump 文件中不会看见明显的异常，如果发现 OOM 之后 Dump 文件很小，而程序中又直接或间接使用了 NIO，就可以考虑检查一下是不是这方面的原因。</p>
<p>【示例】直接内存 <code>OutOfMemoryError</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 本机直接内存溢出示例</span></span><br><span class="line"><span class="comment"> * 错误现象：java.lang.OutOfMemoryError</span></span><br><span class="line"><span class="comment"> * VM Args：-Xmx20M -XX:MaxDirectMemorySize=10M</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DirectOutOfMemoryDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">_1MB</span> <span class="operator">=</span> <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IllegalAccessException &#123;</span><br><span class="line">        <span class="type">Field</span> <span class="variable">unsafeField</span> <span class="operator">=</span> Unsafe.class.getDeclaredFields()[<span class="number">0</span>];</span><br><span class="line">        unsafeField.setAccessible(<span class="literal">true</span>);</span><br><span class="line">        <span class="type">Unsafe</span> <span class="variable">unsafe</span> <span class="operator">=</span> (Unsafe) unsafeField.get(<span class="literal">null</span>);</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            unsafe.allocateMemory(_1MB);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="StackOverflowError"><a href="#StackOverflowError" class="headerlink" title="StackOverflowError"></a>StackOverflowError</h2><p>对于 HotSpot 虚拟机来说，栈容量只由 <code>-Xss</code> 参数来决定如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出 <code>StackOverflowError</code> 异常。</p>
<p>从实战来说，栈溢出的常见原因：</p>
<ul>
<li><strong>递归函数调用层数太深</strong></li>
<li><strong>大量循环或死循环</strong></li>
</ul>
<p>【示例】递归函数调用层数太深导致 <code>StackOverflowError</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StackOverflowDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">stackLength</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">recursion</span><span class="params">()</span> &#123;</span><br><span class="line">        stackLength++;</span><br><span class="line">        recursion();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">StackOverflowDemo</span> <span class="variable">obj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StackOverflowDemo</span>();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            obj.recursion();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;栈深度：&quot;</span> + obj.stackLength);</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/34907497/">《深入理解 Java 虚拟机》</a></li>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100028001">《Java 性能调优实战》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.douban.com/doulist/2545443/">从表到里学习 JVM 实现</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/28935cbfbae0">作为测试你应该知道的 JAVA OOM 及定位分析</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_29912455/article/details/51125748">异常、堆内存溢出、OOM 的几种情况</a></li>
<li><a target="_blank" rel="noopener" href="https://tianmingxing.com/2019/11/17/%E4%BB%8B%E7%BB%8DJVM%E4%B8%ADOOM%E7%9A%848%E7%A7%8D%E7%B1%BB%E5%9E%8B/">介绍 JVM 中 OOM 的 8 种类型</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/ed757c/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/ed757c/" class="post-title-link" itemprop="url">Redis 基本数据类型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>18k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-基本数据类型"><a href="#Redis-基本数据类型" class="headerlink" title="Redis 基本数据类型"></a>Redis 基本数据类型</h1><blockquote>
<p>关键词：<code>String</code>、<code>Hash</code>、<code>List</code>、<code>Set</code>、<code>Zset</code></p>
</blockquote>
<p>Redis 提供了多种数据类型，每种数据类型有丰富的命令支持。</p>
<p>Redis 支持的基本数据类型：STRING、HASH、LIST、SET、ZSET</p>
<p>Redis 支持的高级数据类型：BitMap、HyperLogLog、GEO、Stream</p>
<p>使用 Redis ，不仅要了解其数据类型的特性，还需要根据业务场景，灵活的、高效的使用其数据类型来建模。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309232155082.png"></p>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><h3 id="String-简介"><a href="#String-简介" class="headerlink" title="String 简介"></a>String 简介</h3><p>String 类型是键值对结构。</p>
<p>String 类型是<strong>二进制安全</strong>的。二进制安全是指，String 类型不仅可以保存文本数据，还可以保存任意格式的二进制数据，如：图片、音频、视频、压缩文件等。</p>
<p>默认情况下，String 类型的值最大可为 <strong>512 MB</strong>。</p>
<div align="center">
<img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-datatype-string.png" width="400"/>
</div>

<h3 id="String-实现"><a href="#String-实现" class="headerlink" title="String 实现"></a>String 实现</h3><p>String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。</p>
<p>SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：</p>
<ul>
<li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 <code>SDS</code> 使用 <code>len</code> 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 <code>buf[]</code> 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li>
<li>**SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 <code>len</code> 属性记录了字符串长度，所以复杂度为 <code>O(1)</code>。</li>
<li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li>
</ul>
<p><strong>字符串对象的编码可以是 <code>int</code> 、 <code>raw</code> 或者 <code>embstr</code></strong> 。</p>
<p>字符串对象保存各类型值的编码方式：</p>
<table>
<thead>
<tr>
<th align="left">值</th>
<th align="left">编码</th>
</tr>
</thead>
<tbody><tr>
<td align="left">可以用 <code>long</code> 类型保存的整数。</td>
<td align="left"><code>int</code></td>
</tr>
<tr>
<td align="left">可以用 <code>long double</code> 类型保存的浮点数。</td>
<td align="left"><code>embstr</code> 或者 <code>raw</code></td>
</tr>
<tr>
<td align="left">字符串值， 或者因为长度太大而没办法用 <code>long</code> 类型表示的整数， 又或者因为长度太大而没办法用 <code>long double</code> 类型表示的浮点数。</td>
<td align="left"><code>embstr</code> 或者 <code>raw</code></td>
</tr>
</tbody></table>
<p>如果一个字符串对象保存的是整数值， 并且这个整数值可以用 <code>long</code> 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 <code>ptr</code> 属性里面（将 <code>void*</code> 转换成 <code>long</code> ）， 并将字符串对象的编码设置为 <code>int</code> 。</p>
<p>【示例】</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SET number 10086</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">OBJECT ENCODING number</span></span><br><span class="line">&quot;int&quot;</span><br></pre></td></tr></table></figure>

<p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度大于 <code>39</code> 字节， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为 <code>raw</code> 。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; SET story <span class="string">&quot;Long, long, long ago there lived a king ...&quot;</span></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">&gt; STRLEN <span class="title function_">story</span></span><br><span class="line"><span class="params">(integer)</span> 43</span><br><span class="line"></span><br><span class="line">&gt; OBJECT ENCODING story</span><br><span class="line">&quot;raw&quot;</span><br></pre></td></tr></table></figure>

<p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于 <code>39</code> 字节， 那么字符串对象将使用 <code>embstr</code> 编码的方式来保存这个字符串值。<code>embstr</code> 编码是专门用于保存短字符串的一种优化编码方式。</p>
<p>【示例】</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; SET msg <span class="string">&quot;hello&quot;</span></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">&gt; OBJECT ENCODING msg</span><br><span class="line"><span class="string">&quot;embstr&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="String-命令"><a href="#String-命令" class="headerlink" title="String 命令"></a>String 命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>SET</code></td>
<td>存储一个字符串值</td>
</tr>
<tr>
<td><code>SETNX</code></td>
<td>仅当键不存在时，才存储字符串值</td>
</tr>
<tr>
<td><code>GET</code></td>
<td>获取指定 key 的值</td>
</tr>
<tr>
<td><code>MGET</code></td>
<td>获取一个或多个指定 key 的值</td>
</tr>
<tr>
<td><code>INCRBY</code></td>
<td>将 key 中储存的数字加上指定的增量值</td>
</tr>
<tr>
<td><code>DECRBY</code></td>
<td>将 key 中储存的数字减去指定的减量值</td>
</tr>
</tbody></table>
<blockquote>
<p>更多命令请参考：<a target="_blank" rel="noopener" href="https://redis.io/commands#string">Redis String 类型官方命令文档</a></p>
</blockquote>
<p>【示例】SET、GET、DEL 操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(name) 的 value 保存为 dunwu</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="built_in">set</span> name dunwu</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 key(name) 的 value</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">get name</span></span><br><span class="line">&quot;dunwu&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(name) 的 value 保存为 unknown（覆盖原 value）</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="built_in">set</span> name unknown</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">get name</span></span><br><span class="line">&quot;unknown&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查 key(name) 是否存在</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">exists name</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除 key(name)</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">del name</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">exists name</span></span><br><span class="line">(integer) 0</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">get name</span></span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure>

<p>【示例】SETNX 操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查 key(lock) 是否存在</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">exists lock</span></span><br><span class="line">(integer) 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(lock) 的 value 保存为 1，保存成功</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">setnx lock 1</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(lock) 的 value 保存为 2，由于 key 已存在，保存失败</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">setnx lock 2</span></span><br><span class="line">(integer) 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 key(lock) 的 value</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">get lock</span></span><br><span class="line">&quot;1&quot;</span><br></pre></td></tr></table></figure>

<p>【示例】MSET、MGET 操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">批量设置 one、two、three 这 3 个 key</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">mset one 1 tow 2 three 3</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">批量获取 one、two、three 3 个 key 的 value</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">mget one tow three</span></span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br></pre></td></tr></table></figure>

<p>【示例】INCR、DECR、INCRBY、DECRBY 操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(counter) 的 value 保存为 0</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="built_in">set</span> counter 0</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(counter) 的 value 加 1</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">incr counter</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(counter) 的 value 加 9</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">incrby counter 9</span></span><br><span class="line">(integer) 10</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(counter) 的 value 减 1</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">decr counter</span></span><br><span class="line">(integer) 9</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 key(counter) 的 value 减 9</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">decrby counter 9</span></span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure>

<h3 id="String-应用"><a href="#String-应用" class="headerlink" title="String 应用"></a>String 应用</h3><p><strong>适用场景：缓存、计数器、共享 Session</strong></p>
<h4 id="缓存对象"><a href="#缓存对象" class="headerlink" title="缓存对象"></a>缓存对象</h4><p>使用 String 来缓存对象有两种方式：</p>
<p>（1）缓存对象的 JSON 值</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="built_in">set</span> user:1 &#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;dunwu&quot;</span>,<span class="string">&quot;sex&quot;</span>:<span class="string">&quot;man&quot;</span>&#125;</span></span><br></pre></td></tr></table></figure>

<p>（2）将 key 分离为 user:ID:属性的形式，采用 MSET 存储，用 MGET 获取各属性值</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">mset user:1:name dunwu user:1:sex man</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">mget user:1:name user:1:sex</span></span><br><span class="line">1) &quot;dunwu&quot;</span><br><span class="line">2) &quot;man&quot;</span><br></pre></td></tr></table></figure>

<h4 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h4><p>【需求场景】</p>
<p>统计网站某内容的点击量、收藏量、点赞数等等。</p>
<p>【解决方案】</p>
<blockquote>
<p>使用 Redis 的 String 类型存储一个计数器。</p>
</blockquote>
<p>维护计数器的常见操作如下：</p>
<ul>
<li>增加统计值 - 使用 <code>INCR</code>、<code>DECR</code> 命令</li>
<li>减少统计值 - 使用 <code>INCRBY</code>、<code>DECRBY</code> 操作</li>
</ul>
<p>【示例代码】</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化 ID 为 1024 的博文访问量为 0</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="built_in">set</span> blog:view:1024 0</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ID 为 1024 的博文访问量加 1</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">incr blog:view:1024</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ID 为 1024 的博文访问量加 1</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">incr blog:view:1024</span></span><br><span class="line">(integer) 2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 ID 为 1024 的博文访问量</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">get blog:view:1024</span></span><br><span class="line">&quot;2&quot;</span><br></pre></td></tr></table></figure>

<h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>（1）申请锁</p>
<p>SET 命令有个 NX 参数可以实现“key 不存在才插入”，可以用它来实现分布式锁：</p>
<ul>
<li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li>
<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li>
</ul>
<p>一般而言，还会对分布式锁加上过期时间，分布式锁的命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value NX PX 30000</span><br></pre></td></tr></table></figure>

<ul>
<li>key - 就是分布式锁的关键字；</li>
<li>value - 是客户端生成的唯一的标识；</li>
<li>NX - 表示只有 <code>key</code> 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 <code>nil</code>）</li>
<li>PX 30000 - 表示：30s 后，key 会被删除（这意味着锁被释放了）。设置过期时间，是为了防止出现各种意外，导致锁始终无法释放的情况。</li>
</ul>
<p>（2）释放锁</p>
<p>释放锁就是删除 key ，但是一般可以用 <code>lua</code> 脚本删除，判断 value 一样才删除，这是为了保证释放锁操作和申请所操作是同一个客户端。由于涉及两个操作，为了保证原子性，可以使用 lua 脚本来实现，因为 Redis 执行 Lua 脚本时，是以原子性方式执行的。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。</span></span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<h4 id="共享-Session-信息"><a href="#共享-Session-信息" class="headerlink" title="共享 Session 信息"></a>共享 Session 信息</h4><p>在分布式场景下，一个用户的 Session 如果只存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器上，该服务器没有用户的 Session，就可能导致用户需要重新进行登录等操作。</p>
<p>分布式 Session 的几种实现策略：</p>
<ol>
<li>粘性 session</li>
<li>应用服务器间的 session 复制共享</li>
<li>基于缓存的 session 共享 ✅</li>
</ol>
<p>基于缓存的 session 共享实现</p>
<blockquote>
<p><strong>使用一个单独的存储服务器存储 Session 数据</strong>，可以存在 MySQL 数据库上，也可以存在 Redis 或者 Memcached 这种内存型数据库。</p>
<p>缺点：需要去实现存取 Session 的代码。</p>
</blockquote>
<div align="center">
<img src="https://raw.githubusercontent.com/dunwu/images/master/cs/design/architecture/MultiNode-SpringSession.jpg" />
</div>
## Hash

<h3 id="Hash-简介"><a href="#Hash-简介" class="headerlink" title="Hash 简介"></a>Hash 简介</h3><div align="center">
<img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-datatype-hash.png" width="400"/>
</div>

<p>Hash 是一个键值对（key - value）集合，其中 value 的形式如： <code>value=[&#123;field1，value1&#125;，...&#123;fieldN，valueN&#125;]</code>。Hash 特别适合用于存储对象。</p>
<h3 id="Hash-实现"><a href="#Hash-实现" class="headerlink" title="Hash 实现"></a>Hash 实现</h3><p>哈希对象的编码可以是 <code>ziplist</code> 或者 <code>hashtable</code> 。</p>
<p><code>ziplist</code> 编码的哈希对象使用压缩列表作为底层实现，每当有新的键值对要加入到哈希对象时， 程序会先将保存了键的压缩列表节点推入到压缩列表表尾， 然后再将保存了值的压缩列表节点推入到压缩列表表尾。</p>
<p><code>hashtable</code> 编码的哈希对象使用字典作为底层实现， 哈希对象中的每个键值对都使用一个字典键值对来保存。</p>
<p>当哈希对象同时满足以下两个条件时， 使用 <code>ziplist</code> 编码；否则，使用 <code>hashtable</code> 编码。</p>
<ol>
<li>哈希对象保存的所有键值对的键和值的字符串长度都小于 <code>64</code> 字节（可由 <code>hash-max-ziplist-value</code> 配置）；</li>
<li>哈希对象保存的键值对数量小于 <code>512</code> 个（可由 <code>hash-max-ziplist-entries</code> 配置）；</li>
</ol>
<blockquote>
<p>注意：这两个条件的上限值是可以修改的， 具体请看配置文件中关于 <code>hash-max-ziplist-value</code> 选项和 <code>hash-max-ziplist-entries</code> 选项的说明。</p>
</blockquote>
<h3 id="Hash-命令"><a href="#Hash-命令" class="headerlink" title="Hash 命令"></a>Hash 命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td><code>HSET</code></td>
<td>将指定字段的值设为 value</td>
</tr>
<tr>
<td><code>HGET</code></td>
<td>获取指定字段的值</td>
</tr>
<tr>
<td><code>HGETALL</code></td>
<td>获取所有键值对</td>
</tr>
<tr>
<td><code>HMSET</code></td>
<td>设置多个键值对</td>
</tr>
<tr>
<td><code>HMGET</code></td>
<td>获取所有指定字段的值</td>
</tr>
<tr>
<td><code>HDEL</code></td>
<td>删除指定字段</td>
</tr>
<tr>
<td><code>HINCRBY</code></td>
<td>为指定字段的整数值加上增量</td>
</tr>
<tr>
<td><code>HKEYS</code></td>
<td>获取所有字段</td>
</tr>
</tbody></table>
<blockquote>
<p>更多命令请参考：<a target="_blank" rel="noopener" href="https://redis.io/commands#hash">Redis Hash 类型官方命令文档</a></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">存储一个哈希表key的键值</span></span><br><span class="line">HSET key field value</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取哈希表key对应的field键值</span></span><br><span class="line">HGET key field</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在一个哈希表key中存储多个键值对</span></span><br><span class="line">HMSET key field value [field value...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">批量获取哈希表key中多个field键值</span></span><br><span class="line">HMGET key field [field ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除哈希表key中的field键值</span></span><br><span class="line">HDEL key field [field ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回哈希表key中field的数量</span></span><br><span class="line">HLEN key</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回哈希表key中所有的键值</span></span><br><span class="line">HGETALL key</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为哈希表key中field键的值加上增量n</span></span><br><span class="line">HINCRBY key field n</span><br></pre></td></tr></table></figure>

<h3 id="Hash-应用"><a href="#Hash-应用" class="headerlink" title="Hash 应用"></a>Hash 应用</h3><blockquote>
<p><strong>Hash 类型适用于存储结构化数据</strong>。</p>
</blockquote>
<h4 id="缓存对象-1"><a href="#缓存对象-1" class="headerlink" title="缓存对象"></a>缓存对象</h4><p>Hash 类型的（key，field，value）的结构与对象的（对象 id，属性，值）的结构相似，也可以用来存储对象。</p>
<p>我们以用户信息为例，它在关系型数据库中的结构是这样的：</p>
<p>我们可以使用如下命令，将用户对象的信息存储到 Hash 类型：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">存储一个哈希表uid:1的键值</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">HMSET uid:1 name Tom age 15</span></span><br><span class="line">2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">存储一个哈希表uid:2的键值</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">HMSET uid:2 name Jerry age 13</span></span><br><span class="line">2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取哈希表用户<span class="built_in">id</span>为1中所有的键值</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">HGETALL uid:1</span></span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;Tom&quot;</span><br><span class="line">3) &quot;age&quot;</span><br><span class="line">4) &quot;15&quot;</span><br></pre></td></tr></table></figure>

<p>Redis Hash 存储其结构如下图：</p>
<p>在介绍 String 类型的应用场景时有所介绍，String + Json 也是存储对象的一种方式，那么存储对象时，到底用 String + json 还是用 Hash 呢？</p>
<p>一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。</p>
<h4 id="购物车"><a href="#购物车" class="headerlink" title="购物车"></a>购物车</h4><p>【需求场景】</p>
<p>用户浏览电商平台，添加商品到购物车，并支持查看购物车。需要考虑未登录的情况。</p>
<p>【解决方案】</p>
<blockquote>
<p>可以使用 HASH 类型来实现购物车功能。</p>
<p>以用户 session 为 key，存储了商品 ID 和商品数量的映射。其中，商品 id 为 field，商品数量为 value。</p>
<p>为什么不使用用户 ID？</p>
<p>因为很多场景下需要支持用户在免登陆的情况下使用购物车的，因为未登录，所以无法知道用户的用户 ID，这种情况下使用用户 session 更合适。并且由于绑定的是 session，可以在清空 session 时，顺便清空购物车缓存，更加方便。</p>
</blockquote>
<p>维护购物车的常见操作如下：</p>
<ul>
<li>添加商品 - <code>HSET cart:&#123;session&#125; &#123;商品id&#125; 1</code></li>
<li>添加数量 - <code>HINCRBY cart:&#123;session&#125; &#123;商品id&#125; 1</code></li>
<li>商品总数 - <code>HLEN cart:&#123;session&#125;</code></li>
<li>删除商品 - <code>HDEL cart:&#123;session&#125; &#123;商品id&#125;</code></li>
<li>获取购物车所有商品 - <code>HGETALL cart:&#123;session&#125;</code></li>
</ul>
<p>当前仅仅是将商品 ID 存储到了 Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息。</p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>Redis 中的 List 类型就是有序列表。</p>
<h3 id="List-简介"><a href="#List-简介" class="headerlink" title="List 简介"></a>List 简介</h3><div align="center">
<img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-datatype-list.png" width="400"/>
</div>

<p>List 列表是简单的字符串列表，<strong>按照插入顺序排序</strong>，可以从头部或尾部向 List 列表添加元素。</p>
<p>列表的最大长度为 <code>2^32 - 1</code>，也即每个列表支持超过 <code>40 亿</code>个元素。</p>
<h3 id="List-实现"><a href="#List-实现" class="headerlink" title="List 实现"></a>List 实现</h3><p>列表对象的编码可以是 <code>ziplist</code> 或者 <code>linkedlist</code> 。</p>
<p><code>ziplist</code> 编码的列表对象使用压缩列表作为底层实现， 每个压缩列表节点（entry）保存了一个列表元素。</p>
<p><img src="http://redisbook.com/_images/graphviz-a8d31075b4c0537f4eb6d84aaba1df928c67c953.png"></p>
<p><code>inkedlist</code> 编码的列表对象使用双链表作为底层实现。</p>
<p><img src="http://redisbook.com/_images/graphviz-84c0d231f30c740a431407c7aaf3851b96399590.png"></p>
<p>当列表对象可以同时满足以下两个条件时， 列表对象使用 <code>ziplist</code> 编码；否则，使用 <code>linkedlist</code> 编码</p>
<ol>
<li>列表对象保存的所有字符串元素的长度都小于 <code>64</code> 字节；</li>
<li>列表对象保存的元素数量小于 <code>512</code> 个；</li>
</ol>
<blockquote>
<p>注意</p>
<p>以上两个条件的上限值是可以修改的， 具体请看配置文件中关于 <code>list-max-ziplist-value</code> 选项和 <code>list-max-ziplist-entries</code> 选项的说明。</p>
</blockquote>
<h3 id="List-命令"><a href="#List-命令" class="headerlink" title="List 命令"></a>List 命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td><code>LPUSH</code></td>
<td>将给定值推入列表的右端。</td>
</tr>
<tr>
<td><code>RPUSH</code></td>
<td>将给定值推入列表的右端。</td>
</tr>
<tr>
<td><code>LPOP</code></td>
<td>从列表的左端弹出一个值，并返回被弹出的值。</td>
</tr>
<tr>
<td><code>RPOP</code></td>
<td>从列表的右端弹出一个值，并返回被弹出的值。</td>
</tr>
<tr>
<td><code>LRANGE</code></td>
<td>获取列表在给定范围上的所有值。</td>
</tr>
<tr>
<td><code>LINDEX</code></td>
<td>获取列表在给定位置上的单个元素。</td>
</tr>
<tr>
<td><code>LREM</code></td>
<td>从列表的左端弹出一个值，并返回被弹出的值。</td>
</tr>
<tr>
<td><code>LTRIM</code></td>
<td>只保留指定区间内的元素，删除其他元素。</td>
</tr>
</tbody></table>
<blockquote>
<p>更多命令请参考：<a target="_blank" rel="noopener" href="https://redis.io/commands#list">Redis List 类型官方命令文档</a></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面</span></span><br><span class="line">LPUSH key value [value ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将一个或多个值value插入到key列表的表尾(最右边)</span></span><br><span class="line">RPUSH key value [value ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">移除并返回key列表的头元素</span></span><br><span class="line">LPOP key</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">移除并返回key列表的尾元素</span></span><br><span class="line">RPOP key</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从0开始</span></span><br><span class="line">LRANGE key start stop</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从key列表表头弹出一个元素，没有就阻塞<span class="built_in">timeout</span>秒，如果<span class="built_in">timeout</span>=0则一直阻塞</span></span><br><span class="line">BLPOP key [key ...] timeout</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从key列表表尾弹出一个元素，没有就阻塞<span class="built_in">timeout</span>秒，如果<span class="built_in">timeout</span>=0则一直阻塞</span></span><br><span class="line">BRPOP key [key ...] timeout</span><br></pre></td></tr></table></figure>

<h3 id="List-应用"><a href="#List-应用" class="headerlink" title="List 应用"></a>List 应用</h3><h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><p>消息队列在存取消息时，必须要满足三个需求，分别是<strong>消息保序、处理重复的消息和保证消息可靠性</strong>。</p>
<p>Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于 List 的消息队列实现方法，后面在介绍 Stream 数据类型时候，在详细说说 Stream。</p>
<p><em>1、如何满足消息保序需求？</em></p>
<p>List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。</p>
<p>List 可以使用 LPUSH + RPOP（或者反过来，RPUSH+LPOP）命令实现消息队列。</p>
<ul>
<li><p>生产者使用 <code>LPUSH key value[value...]</code> 将消息插入到队列的头部，如果 key 不存在则会创建一个空的队列再插入消息。</p>
</li>
<li><p>消费者使用 <code>RPOP key</code> 依次读取队列的消息，先进先出。</p>
</li>
</ul>
<p>不过，在消费者读取数据时，有一个潜在的性能风险点。</p>
<p>在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 <code>RPOP</code> 命令（比如使用一个 while(1) 循环）。如果有新消息写入，RPOP 命令就会返回结果，否则，RPOP 命令返回空值，再继续循环。</p>
<p>所以，即使没有新消息写入 List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。</p>
<p>为了解决这个问题，Redis 提供了 BRPOP 命令。<strong>BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong>。和消费者程序自己不停地调用 RPOP 命令相比，这种方式能节省 CPU 开销。</p>
<p><em>2、如何处理重复的消息？</em></p>
<p>消费者要实现重复消息的判断，需要 2 个方面的要求：</p>
<ul>
<li>每个消息都有一个全局的 ID。</li>
<li>消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。</li>
</ul>
<p>但是 <strong>List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一 ID</strong>，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。</p>
<p>例如，我们执行以下命令，就把一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">LPUSH mq <span class="string">&quot;111000102:stock:99&quot;</span></span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p><em>3、如何保证消息可靠性？</em></p>
<p>当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。</p>
<p>为了留存消息，List 类型提供了 <code>BRPOPLPUSH</code> 命令，这个命令的<strong>作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存</strong>。</p>
<p>这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。</p>
<p>好了，到这里可以知道基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）。</p>
<ul>
<li>消息保序：使用 LPUSH + RPOP；</li>
<li>阻塞读取：使用 BRPOP；</li>
<li>重复消息处理：生产者自行实现全局唯一 ID；</li>
<li>消息的可靠性：使用 BRPOPLPUSH</li>
</ul>
<blockquote>
<p>List 作为消息队列有什么缺陷？</p>
</blockquote>
<p><strong>List 不支持多个消费者消费同一条消息</strong>，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。</p>
<p>要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 <strong>List 类型并不支持消费组的实现</strong>。</p>
<p>这就要说起 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持“消费组”形式的消息读取。</p>
<h4 id="输入自动补全"><a href="#输入自动补全" class="headerlink" title="输入自动补全"></a>输入自动补全</h4><p>【需求场景】</p>
<p>根据用户输入，自动补全信息，如：联系人、商品名等。</p>
<ul>
<li>典型场景一 - 社交网站后台记录用户最近联系过的 100 个好友，当用户查找好友时，根据输入的关键字自动补全姓名。</li>
<li>典型场景二 - 电商网站后台记录用户最近浏览过的 10 件商品，当用户查找商品是，根据输入的关键字自动补全商品名称。</li>
</ul>
<p>【解决方案】</p>
<blockquote>
<p>使用 Redis 的 List 类型存储一个最近信息列表，然后在需要自动补全信息时展示相应数量的数据。</p>
</blockquote>
<p>维护最近信息列表的常见操作如下：</p>
<ul>
<li>如果指定信息经存在于最近信息列表里，那么从列表里移除。使用 <code>LREM</code> 命令。</li>
<li>将指定信息添加到最近信息列表的头部。使用 <code>LPUSH</code> 命令。</li>
<li>添加操作完成后，如果最近信息列表中的数量超过上限 N，进行裁剪操作。使用 <code>LTRIM</code> 命令。</li>
</ul>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>Redis 中的 Set 类型就是无序且去重的集合。</p>
<h3 id="Set-简介"><a href="#Set-简介" class="headerlink" title="Set 简介"></a>Set 简介</h3><div align="center">
<img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-datatype-set.png" width="400"/>
</div>

<p>Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。</p>
<p>一个集合最多可以存储 <code>2^32-1</code> 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。</p>
<p>Set 类型和 List 类型的区别如下：</p>
<ul>
<li>List 可以存储重复元素，Set 只能存储非重复元素；</li>
<li>List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。</li>
</ul>
<h3 id="Set-实现"><a href="#Set-实现" class="headerlink" title="Set 实现"></a>Set 实现</h3><p>集合对象的编码可以是 <code>intset</code> 或者 <code>hashtable</code> 。</p>
<p><code>intset</code> 编码的集合对象使用整数集合作为底层实现， 集合对象包含的所有元素都被保存在整数集合里面。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241059483.png"></p>
<p><code>hashtable</code> 编码的集合对象使用字典作为底层实现， 字典的每个键都是一个字符串对象， 每个字符串对象包含了一个集合元素， 而字典的值则全部被设置为 <code>NULL</code> 。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241100174.png"></p>
<p>当集合对象可以同时满足以下两个条件时，集合对象使用 <code>intset</code> 编码；否则，使用 <code>hashtable</code> 编码：</p>
<ol>
<li>集合对象保存的所有元素都是整数值；</li>
<li>集合对象保存的元素数量不超过 <code>512</code> 个；</li>
</ol>
<blockquote>
<p>注意：第二个条件的上限值是可以修改的， 具体请看配置文件中关于 <code>set-max-intset-entries</code> 选项的说明。</p>
</blockquote>
<h3 id="Set-命令"><a href="#Set-命令" class="headerlink" title="Set 命令"></a>Set 命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td><code>SADD</code></td>
<td>将给定元素添加到集合。</td>
</tr>
<tr>
<td><code>SMEMBERS</code></td>
<td>返回集合包含的所有元素。</td>
</tr>
<tr>
<td><code>SISMEMBER</code></td>
<td>检查给定元素是否存在于集合中。</td>
</tr>
<tr>
<td><code>SREM</code></td>
<td>如果给定的元素存在于集合中，那么移除这个元素。</td>
</tr>
</tbody></table>
<blockquote>
<p>更多命令请参考：<a target="_blank" rel="noopener" href="https://redis.io/commands#set">Redis Set 类型官方命令文档</a></p>
</blockquote>
<p>Set 常用操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">往集合key中存入元素，元素存在则忽略，若key不存在则新建</span></span><br><span class="line">SADD key member [member ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从集合key中删除元素</span></span><br><span class="line">SREM key member [member ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取集合key中所有元素</span></span><br><span class="line">SMEMBERS key</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取集合key中的元素个数</span></span><br><span class="line">SCARD key</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">判断member元素是否存在于集合key中</span></span><br><span class="line">SISMEMBER key member</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从集合key中随机选出count个元素，元素不从key中删除</span></span><br><span class="line">SRANDMEMBER key [count]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从集合key中随机选出count个元素，元素从key中删除</span></span><br><span class="line">SPOP key [count]</span><br></pre></td></tr></table></figure>

<p>Set 运算操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">交集运算</span></span><br><span class="line">SINTER key [key ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将交集结果存入新集合destination中</span></span><br><span class="line">SINTERSTORE destination key [key ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">并集运算</span></span><br><span class="line">SUNION key [key ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将并集结果存入新集合destination中</span></span><br><span class="line">SUNIONSTORE destination key [key ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">差集运算</span></span><br><span class="line">SDIFF key [key ...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将差集结果存入新集合destination中</span></span><br><span class="line">SDIFFSTORE destination key [key ...]</span><br></pre></td></tr></table></figure>

<h3 id="Set-应用"><a href="#Set-应用" class="headerlink" title="Set 应用"></a>Set 应用</h3><p>集合的主要几个特性，无序、不可重复、支持并交差等操作。</p>
<p>因此 Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。</p>
<p>但是要提醒你一下，这里有一个潜在的风险。<strong>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞</strong>。</p>
<p>在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。</p>
<h4 id="点赞"><a href="#点赞" class="headerlink" title="点赞"></a>点赞</h4><p>Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章 id，value 是用户 id。</p>
<p><code>uid:1</code> 、<code>uid:2</code>、<code>uid:3</code> 三个用户分别对 article:1 文章点赞了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">uid:1 用户对文章 article:1 点赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SADD article:1 uid:1</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">uid:2 用户对文章 article:1 点赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SADD article:1 uid:2</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">uid:3 用户对文章 article:1 点赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SADD article:1 uid:3</span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p><code>uid:1</code> 取消了对 article:1 文章点赞。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; SREM article:1 uid:1</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p>获取 article:1 文章所有点赞用户 :</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SMEMBERS article:1</span></span><br><span class="line">1) &quot;uid:3&quot;</span><br><span class="line">2) &quot;uid:2&quot;</span><br></pre></td></tr></table></figure>

<p>获取 article:1 文章的点赞用户数量：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SCARD article:1</span></span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure>

<p>判断用户 <code>uid:1</code> 是否对文章 article:1 点赞了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SISMEMBER article:1 uid:1</span></span><br><span class="line">(integer) 0  # 返回0说明没点赞，返回1则说明点赞了</span><br></pre></td></tr></table></figure>

<h4 id="共同关注"><a href="#共同关注" class="headerlink" title="共同关注"></a>共同关注</h4><p>Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。</p>
<p>key 可以是用户 id，value 则是已关注的公众号的 id。</p>
<p><code>uid:1</code> 用户关注公众号 id 为 5、6、7、8、9，<code>uid:2</code> 用户关注公众号 id 为 7、8、9、10、11。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">uid:1 用户关注公众号 <span class="built_in">id</span> 为 5、6、7、8、9</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SADD uid:1 5 6 7 8 9</span></span><br><span class="line">(integer) 5</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">uid:2  用户关注公众号 <span class="built_in">id</span> 为 7、8、9、10、11</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SADD uid:2 7 8 9 10 11</span></span><br><span class="line">(integer) 5</span><br></pre></td></tr></table></figure>

<p><code>uid:1</code> 和 <code>uid:2</code> 共同关注的公众号：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取共同关注</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SINTER uid:1 uid:2</span></span><br><span class="line">1) &quot;7&quot;</span><br><span class="line">2) &quot;8&quot;</span><br><span class="line">3) &quot;9&quot;</span><br></pre></td></tr></table></figure>

<p>给 <code>uid:2</code> 推荐 <code>uid:1</code> 关注的公众号：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SDIFF uid:1 uid:2</span></span><br><span class="line">1) &quot;5&quot;</span><br><span class="line">2) &quot;6&quot;</span><br></pre></td></tr></table></figure>

<p>验证某个公众号是否同时被 <code>uid:1</code> 或 <code>uid:2</code> 关注：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SISMEMBER uid:1 5</span></span><br><span class="line">(integer) 1 # 返回1，说明关注了</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SISMEMBER uid:2 5</span></span><br><span class="line">(integer) 0 # 返回0，说明没关注</span><br></pre></td></tr></table></figure>

<h4 id="抽奖活动"><a href="#抽奖活动" class="headerlink" title="抽奖活动"></a>抽奖活动</h4><p>存储某活动中中奖的用户名，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。</p>
<p>key 为抽奖活动名，value 为员工名称，把所有员工名称放入抽奖箱：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">SADD lucky Tom Jerry John Sean Marry Lindy Sary Mark</span></span><br><span class="line">(integer) 5</span><br></pre></td></tr></table></figure>

<p>如果允许重复中奖，可以使用 SRANDMEMBER 命令。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">抽取 1 个一等奖：</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SRANDMEMBER lucky 1</span></span><br><span class="line">1) &quot;Tom&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">抽取 2 个二等奖：</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SRANDMEMBER lucky 2</span></span><br><span class="line">1) &quot;Mark&quot;</span><br><span class="line">2) &quot;Jerry&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">抽取 3 个三等奖：</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SRANDMEMBER lucky 3</span></span><br><span class="line">1) &quot;Sary&quot;</span><br><span class="line">2) &quot;Tom&quot;</span><br><span class="line">3) &quot;Jerry&quot;</span><br></pre></td></tr></table></figure>

<p>如果不允许重复中奖，可以使用 SPOP 命令。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">抽取一等奖1个</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SPOP lucky 1</span></span><br><span class="line">1) &quot;Sary&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">抽取二等奖2个</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SPOP lucky 2</span></span><br><span class="line">1) &quot;Jerry&quot;</span><br><span class="line">2) &quot;Mark&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">抽取三等奖3个</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SPOP lucky 3</span></span><br><span class="line">1) &quot;John&quot;</span><br><span class="line">2) &quot;Sean&quot;</span><br><span class="line">3) &quot;Lindy&quot;</span><br></pre></td></tr></table></figure>

<h2 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h2><p>Redis 中的 Zset 类型就是有序且去重的集合。</p>
<h3 id="Zset-简介"><a href="#Zset-简介" class="headerlink" title="Zset 简介"></a>Zset 简介</h3><p>Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。</p>
<p>有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。</p>
<div align="center">
<img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-datatype-zset.png" width="400"/>
</div>

<h3 id="Zset-实现"><a href="#Zset-实现" class="headerlink" title="Zset 实现"></a>Zset 实现</h3><p>有序集合的编码可以是 <code>ziplist</code> 或者 <code>skiplist</code> 。</p>
<p><code>ziplist</code> 编码的有序集合对象使用压缩列表作为底层实现， 每个集合元素使用两个紧挨在一起的压缩列表节点来保存， 第一个节点保存元素的成员（member）， 而第二个元素则保存元素的分值（score）。压缩列表内的集合元素按分值从小到大进行排序， 分值较小的元素被放置在靠近表头的方向， 而分值较大的元素则被放置在靠近表尾的方向。</p>
<p><code>skiplist</code> 编码的有序集合对象使用 <code>zset</code> 结构作为底层实现， 一个 <code>zset</code> 结构同时包含一个字典和一个跳跃表</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line"></span><br><span class="line">    zskiplist *zsl;</span><br><span class="line"></span><br><span class="line">    dict *dict;</span><br><span class="line"></span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure>

<p><code>zset</code> 结构中的 <code>zsl</code> 跳跃表按分值从小到大保存了所有集合元素， 每个跳跃表节点都保存了一个集合元素： 跳跃表节点的 <code>object</code> 属性保存了元素的成员， 而跳跃表节点的 <code>score</code> 属性则保存了元素的分值。 通过这个跳跃表， 程序可以对有序集合进行范围型操作， 比如 ZRANK 、 ZRANGE 等命令就是基于跳跃表 API 来实现的。</p>
<p>除此之外， <code>zset</code> 结构中的 <code>dict</code> 字典为有序集合创建了一个从成员到分值的映射， 字典中的每个键值对都保存了一个集合元素： 字典的键保存了元素的成员， 而字典的值则保存了元素的分值。 通过这个字典， 程序可以用 O(1) 复杂度查找给定成员的分值， ZSCORE 命令就是根据这一特性实现的， 而很多其他有序集合命令都在实现的内部用到了这一特性。</p>
<p>有序集合每个元素的成员都是一个字符串对象， 而每个元素的分值都是一个 <code>double</code> 类型的浮点数。 值得一提的是， 虽然 <code>zset</code> 结构同时使用跳跃表和字典来保存有序集合元素， 但这两种数据结构都会通过指针来共享相同元素的成员和分值， 所以同时使用跳跃表和字典来保存集合元素不会产生任何重复成员或者分值， 也不会因此而浪费额外的内存。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241108347.png"></p>
<p>当有序集合对象可以同时满足以下两个条件时，有序集合对象使用 <code>ziplist</code> 编码；否则，使用 <code>skiplist</code> 编码。</p>
<ul>
<li>有序集合保存的元素数量小于 <code>128</code> 个；</li>
<li>有序集合保存的所有元素成员的长度都小于 <code>64</code> 字节；</li>
</ul>
<blockquote>
<p>注意：以上两个条件的上限值是可以修改的， 具体请看配置文件中关于 <code>zset-max-ziplist-entries</code> 选项和 <code>zset-max-ziplist-value</code> 选项的说明。</p>
</blockquote>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p>
<h3 id="Zset-命令"><a href="#Zset-命令" class="headerlink" title="Zset 命令"></a>Zset 命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td><code>ZADD</code></td>
<td>将一个带有给定分值的成员添加到有序集合里面</td>
</tr>
<tr>
<td><code>ZRANGE</code></td>
<td>顺序排序，并返回指定排名区间的成员</td>
</tr>
<tr>
<td>ZREVRANGE</td>
<td>反序排序，并返回指定排名区间的成员</td>
</tr>
<tr>
<td><code>ZRANGEBYSCORE</code></td>
<td>顺序排序，并返回指定排名区间的成员及其分值</td>
</tr>
<tr>
<td>ZREVRANGEBYSCORE</td>
<td>反序排序，并返回指定排名区间的成员及其分值</td>
</tr>
<tr>
<td><code>ZREM</code></td>
<td>移除指定的成员</td>
</tr>
<tr>
<td><code>ZSCORE</code></td>
<td>返回指定成员的分值</td>
</tr>
<tr>
<td><code>ZCARD</code></td>
<td>返回所有成员数</td>
</tr>
</tbody></table>
<blockquote>
<p>更多命令请参考：<a target="_blank" rel="noopener" href="https://redis.io/commands#sorted_set">Redis ZSet 类型官方命令文档</a></p>
</blockquote>
<p>Zset 常用操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">往有序集合key中加入带分值元素</span></span><br><span class="line">ZADD key score member [[score member]...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">往有序集合key中删除元素</span></span><br><span class="line">ZREM key member [member...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回有序集合key中元素member的分值</span></span><br><span class="line">ZSCORE key member</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回有序集合key中元素个数</span></span><br><span class="line">ZCARD key</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为有序集合key中元素member的分值加上increment</span></span><br><span class="line">ZINCRBY key increment member</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">正序获取有序集合key从start下标到stop下标的元素</span></span><br><span class="line">ZRANGE key start stop [WITHSCORES]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">倒序获取有序集合key从start下标到stop下标的元素</span></span><br><span class="line">ZREVRANGE key start stop [WITHSCORES]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回有序集合中指定分数区间内的成员，分数由低到高排序。</span></span><br><span class="line">ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回指定成员区间内的成员，按字典正序排列, 分数必须相同。</span></span><br><span class="line">ZRANGEBYLEX key min max [LIMIT offset count]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回指定成员区间内的成员，按字典倒序排列, 分数必须相同</span></span><br><span class="line">ZREVRANGEBYLEX key max min [LIMIT offset count]</span><br></pre></td></tr></table></figure>

<p>Zset 运算操作（相比于 Set 类型，ZSet 类型没有支持差集运算）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">并集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积</span></span><br><span class="line">ZUNIONSTORE destkey numberkeys key [key...]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">交集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积</span></span><br><span class="line">ZINTERSTORE destkey numberkeys key [key...]</span><br></pre></td></tr></table></figure>

<h3 id="Zset-应用"><a href="#Zset-应用" class="headerlink" title="Zset 应用"></a>Zset 应用</h3><p>Zset 类型（Sorted Set，有序集合）可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。</p>
<p>在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用 Sorted Set。</p>
<h4 id="排行榜"><a href="#排行榜" class="headerlink" title="排行榜"></a>排行榜</h4><p>【需求场景】</p>
<p>各种排行榜，如：内容平台（视频、歌曲、文章）的播放量&#x2F;收藏量&#x2F;评分排行榜；电商网站的销售排行榜；</p>
<p>【解决方案】</p>
<p>有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。</p>
<p>我们以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:1 文章获得了200个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 200 arcticle:1</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:2 文章获得了40个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 40 arcticle:2</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:3 文章获得了100个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 100 arcticle:3</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:4 文章获得了50个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 50 arcticle:4</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:5 文章获得了150个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 150 arcticle:5</span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p>文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合 key 中元素 member 的分值加上 increment）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZINCRBY user:xiaolin:ranking 1 arcticle:4</span></span><br><span class="line">&quot;51&quot;</span><br></pre></td></tr></table></figure>

<p>查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合 key 中元素个数）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZSCORE user:xiaolin:ranking arcticle:4</span></span><br><span class="line">&quot;50&quot;</span><br></pre></td></tr></table></figure>

<p>获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从 start 下标到 stop 下标的元素）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">WITHSCORES 表示把 score 也显示出来</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES</span></span><br><span class="line">1) &quot;arcticle:1&quot;</span><br><span class="line">2) &quot;200&quot;</span><br><span class="line">3) &quot;arcticle:5&quot;</span><br><span class="line">4) &quot;150&quot;</span><br><span class="line">5) &quot;arcticle:3&quot;</span><br><span class="line">6) &quot;100&quot;</span><br></pre></td></tr></table></figure>

<p>获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES</span></span><br><span class="line">1) &quot;arcticle:3&quot;</span><br><span class="line">2) &quot;100&quot;</span><br><span class="line">3) &quot;arcticle:5&quot;</span><br><span class="line">4) &quot;150&quot;</span><br><span class="line">5) &quot;arcticle:1&quot;</span><br><span class="line">6) &quot;200&quot;</span><br></pre></td></tr></table></figure>

<h4 id="前缀排序"><a href="#前缀排序" class="headerlink" title="前缀排序"></a>前缀排序</h4><p>使用有序集合的 <code>ZRANGEBYLEX</code> 或 <code>ZREVRANGEBYLEX</code> 可以帮助我们实现电话号码或姓名的排序，我们以 <code>ZRANGEBYLEX</code> （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。</p>
<p><strong>注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX 和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。</strong></p>
<p><em>1、电话排序</em></p>
<p>我们可以将电话号码存储到 SortSet 中，然后根据需要来获取号段：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD phone 0 13100111100 0 13110114300 0 13132110901</span></span><br><span class="line">(integer) 3</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD phone 0 13200111100 0 13210414300 0 13252110901</span></span><br><span class="line">(integer) 3</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD phone 0 13300111100 0 13310414300 0 13352110901</span></span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure>

<p>获取所有号码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYLEX phone - +</span></span><br><span class="line">1) &quot;13100111100&quot;</span><br><span class="line">2) &quot;13110114300&quot;</span><br><span class="line">3) &quot;13132110901&quot;</span><br><span class="line">4) &quot;13200111100&quot;</span><br><span class="line">5) &quot;13210414300&quot;</span><br><span class="line">6) &quot;13252110901&quot;</span><br><span class="line">7) &quot;13300111100&quot;</span><br><span class="line">8) &quot;13310414300&quot;</span><br><span class="line">9) &quot;13352110901&quot;</span><br></pre></td></tr></table></figure>

<p>获取 132 号段的号码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYLEX phone [132 (133</span></span><br><span class="line">1) &quot;13200111100&quot;</span><br><span class="line">2) &quot;13210414300&quot;</span><br><span class="line">3) &quot;13252110901&quot;</span><br></pre></td></tr></table></figure>

<p>获取 132、133 号段的号码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYLEX phone [132 (134</span></span><br><span class="line">1) &quot;13200111100&quot;</span><br><span class="line">2) &quot;13210414300&quot;</span><br><span class="line">3) &quot;13252110901&quot;</span><br><span class="line">4) &quot;13300111100&quot;</span><br><span class="line">5) &quot;13310414300&quot;</span><br><span class="line">6) &quot;13352110901&quot;</span><br></pre></td></tr></table></figure>

<p><em>2、姓名排序</em></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">zadd names 0 Toumas 0 Jake 0 Bluetuo 0 Gaodeng 0 Aimini 0 Aidehua</span></span><br><span class="line">(integer) 6</span><br></pre></td></tr></table></figure>

<p>获取所有人的名字：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYLEX names - +</span></span><br><span class="line">1) &quot;Aidehua&quot;</span><br><span class="line">2) &quot;Aimini&quot;</span><br><span class="line">3) &quot;Bluetuo&quot;</span><br><span class="line">4) &quot;Gaodeng&quot;</span><br><span class="line">5) &quot;Jake&quot;</span><br><span class="line">6) &quot;Toumas&quot;</span><br></pre></td></tr></table></figure>

<p>获取名字中大写字母 A 开头的所有人：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYLEX names [A (B</span></span><br><span class="line">1) &quot;Aidehua&quot;</span><br><span class="line">2) &quot;Aimini&quot;</span><br></pre></td></tr></table></figure>

<p>获取名字中大写字母 C 到 Z 的所有人：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYLEX names [C [Z</span></span><br><span class="line">1) &quot;Gaodeng&quot;</span><br><span class="line">2) &quot;Jake&quot;</span><br><span class="line">3) &quot;Toumas&quot;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Redis 常见的五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）及 Zset(sorted set：有序集合)**。</p>
<p>这五种数据类型都由多种数据结构实现的，主要是出于时间和空间的考虑，当数据量小的时候使用更简单的数据结构，有利于节省内存，提高性能。</p>
<p>可以看到，Redis 数据类型的底层数据结构随着版本的更新也有所不同，比如：</p>
<ul>
<li>在 Redis 3.0 版本中 List 对象的底层数据结构由“双向链表”或“压缩表列表”实现，但是在 3.2 版本之后，List 数据类型底层数据结构是由 quicklist 实现的；</li>
<li>在最新的 Redis 代码中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</li>
</ul>
<p>Redis 五种数据类型的应用场景：</p>
<ul>
<li>String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。</li>
<li>List 类型的应用场景：消息队列（有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li>
<li>Hash 类型：缓存对象、购物车等。</li>
<li>Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</li>
<li>Zset 类型：排序场景，比如排行榜、电话和姓名排序等。</li>
</ul>
<p>Redis 后续版本又支持四种数据类型，它们的应用场景如下：</p>
<ul>
<li>BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</li>
<li>HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；</li>
<li>GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；</li>
<li>Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息 ID，支持以消费组形式消费数据。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309232144470.jpg"></p>
<p>针对 Redis 是否适合做消息队列，关键看你的业务场景：</p>
<ul>
<li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li>
<li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11791607.html">《Redis 实战》</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
<li><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/data_struct/command.html#string">Redis 常见数据类型和应用场景</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/518280/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/518280/" class="post-title-link" itemprop="url">Redis 高级数据类型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-高级数据类型"><a href="#Redis-高级数据类型" class="headerlink" title="Redis 高级数据类型"></a>Redis 高级数据类型</h1><blockquote>
<p>关键词：<code>BitMap</code>、<code>HyperLogLog</code>、<code>Geo</code>、<code>Stream</code></p>
</blockquote>
<p>Redis 支持的高级数据类型：BitMap、HyperLogLog、GEO、Stream</p>
<p>使用 Redis ，不仅要了解其数据类型的特性，还需要根据业务场景，灵活的、高效的使用其数据类型来建模。</p>
<h2 id="BitMap"><a href="#BitMap" class="headerlink" title="BitMap"></a>BitMap</h2><h3 id="BitMap-简介"><a href="#BitMap-简介" class="headerlink" title="BitMap 简介"></a>BitMap 简介</h3><p>Bitmap，<strong>即位图，是一串连续的二进制数组（0 和 1）</strong>，可以通过偏移量（offset）定位元素。由于 bit 是计算机中最小的单位，使用它进行储存将<strong>非常节省空间</strong>，特别适合一些数据量大且使用<strong>二值统计的场景</strong>。例如在一个系统中，不同的用户使用单调递增的用户 ID 表示。40 亿（$$2^{32}$$ &#x3D; $$4<em>1024</em>1024*1024$$ ≈ 40 亿）用户只需要 512M 内存就能记住某种状态，例如用户是否已登录。</p>
<h3 id="BitMap-实现"><a href="#BitMap-实现" class="headerlink" title="BitMap 实现"></a>BitMap 实现</h3><p>实际上，<strong>BitMap 不是真实的数据结构，而是针对 String 实现的一组位操作</strong>。</p>
<p>由于 STRING 是二进制安全的，并且其最大长度是 512 MB，所以 BitMap 能最大设置 $$2^{32}$$ 个不同的 bit。</p>
<h3 id="BitMap-命令"><a href="#BitMap-命令" class="headerlink" title="BitMap 命令"></a>BitMap 命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td><code>SETBIT</code></td>
<td>对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)</td>
</tr>
<tr>
<td><code>GETBIT</code></td>
<td>对 key 所储存的字符串值，获取指定偏移量上的位(bit)</td>
</tr>
<tr>
<td><code>BITOP</code></td>
<td>对一个或多个字符串执行位运算</td>
</tr>
</tbody></table>
<p>【示例】SETBIT、GETBIT 操作</p>
<p>假设有 1000 个传感器，标记为 0-999。现在，想要快速确定某传感器是否在一小时内对服务器执行了 ping 操作。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">传感器 123 在 2024 年 1 月 1 日 00:00 内对服务器执行 ping 操作</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">SETBIT pings:2024-01-01-00:00 123 1</span></span><br><span class="line">(integer) 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">传感器 123 是否在 2024 年 1 月 1 日 00:00 内对服务器执行 ping 操作</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">GETBIT pings:2024-01-01-00:00 123</span></span><br><span class="line">1</span><br><span class="line">What about sensor 456?</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">GETBIT pings:2024-01-01-00:00 456</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>【示例】BITOP 操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">BitMap间的运算</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">operations 位移操作符，枚举值</span></span><br><span class="line">  AND 与运算 &amp;</span><br><span class="line">  OR 或运算 |</span><br><span class="line">  XOR 异或 ^</span><br><span class="line">  NOT 取反 ~</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">result 计算的结果，会存储在该key中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。</span></span><br><span class="line">BITOP [operations] [result] [key1] [keyn…]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回指定key中第一次出现指定value(0/1)的位置</span></span><br><span class="line">BITPOS [key] [value]</span><br></pre></td></tr></table></figure>

<h3 id="BitMap-应用"><a href="#BitMap-应用" class="headerlink" title="BitMap 应用"></a>BitMap 应用</h3><p>Bitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间。</p>
<h4 id="签到统计"><a href="#签到统计" class="headerlink" title="签到统计"></a>签到统计</h4><p>在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。</p>
<p>签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。</p>
<p>假设我们要统计 ID 100 的用户在 2022 年 6 月份的签到情况，就可以按照下面的步骤进行操作。</p>
<p>第一步，执行下面的命令，记录该用户 6 月 3 号已签到。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETBIT uid:sign:100:202206 2 1</span><br></pre></td></tr></table></figure>

<p>第二步，检查该用户 6 月 3 日是否签到。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETBIT uid:sign:100:202206 2</span><br></pre></td></tr></table></figure>

<p>第三步，统计该用户在 6 月份的签到次数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITCOUNT uid:sign:100:202206</span><br></pre></td></tr></table></figure>

<p>这样，我们就知道该用户在 6 月份的签到情况了。</p>
<blockquote>
<p>如何统计这个月首次打卡时间呢？</p>
</blockquote>
<p>Redis 提供了 <code>BITPOS key bitValue [start] [end]</code>指令，返回数据表示 Bitmap 中第一个值为 <code>bitValue</code> 的 offset 位置。</p>
<p>在默认情况下，命令将检测整个位图，用户可以通过可选的 <code>start</code> 参数和 <code>end</code> 参数指定要检测的范围。所以我们可以通过执行这条命令来获取 userID &#x3D; 100 在 2022 年 6 月份<strong>首次打卡</strong>日期：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITPOS uid:sign:100:202206 1</span><br></pre></td></tr></table></figure>

<p>需要注意的是，因为 offset 从 0 开始的，所以我们需要将返回的 value + 1。</p>
<h4 id="判断用户是否登录"><a href="#判断用户是否登录" class="headerlink" title="判断用户是否登录"></a>判断用户是否登录</h4><p>Bitmap 提供了 <code>GETBIT、SETBIT</code> 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 offset 从 0 开始。</p>
<p>只需要一个 key &#x3D; login_status 表示存储用户登陆状态集合数据，将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 <code>GETBIT</code>判断对应的用户是否在线。50000 万 用户只需要 6 MB 的空间。</p>
<p>假如我们要判断 ID &#x3D; 10086 的用户的登陆情况：</p>
<p>第一步，执行以下指令，表示用户已登录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETBIT login_status 10086 1</span><br></pre></td></tr></table></figure>

<p>第二步，检查该用户是否登陆，返回值 1 表示已登录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETBIT login_status 10086</span><br></pre></td></tr></table></figure>

<p>第三步，登出，将 offset 对应的 value 设置成 0。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETBIT login_status 10086 0</span><br></pre></td></tr></table></figure>

<h4 id="连续签到用户总数"><a href="#连续签到用户总数" class="headerlink" title="连续签到用户总数"></a>连续签到用户总数</h4><p>如何统计出这连续 7 天连续打卡用户总数呢？</p>
<p>我们把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。</p>
<p>key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。</p>
<p>一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 “与”运算。同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit &#x3D; 1 就说明该用户 7 天连续打卡。</p>
<p>结果保存到一个新 Bitmap 中，我们再通过 <code>BITCOUNT</code> 统计 bit &#x3D; 1 的个数便得到了连续打卡 7 天的用户总数了。</p>
<p>Redis 提供了 <code>BITOP operation destkey key [key ...]</code>这个指令用于对一个或者多个 key 的 Bitmap 进行位元操作。</p>
<ul>
<li><code>operation</code> 可以是 <code>and</code>、<code>OR</code>、<code>NOT</code>、<code>XOR</code>。当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 <code>0</code> 。空的 <code>key</code> 也被看作是包含 <code>0</code> 的字符串序列。</li>
</ul>
<p>假设要统计 3 天连续打卡的用户数，则是将三个 bitmap 进行 AND 操作，并将结果保存到 destmap 中，接着对 destmap 执行 BITCOUNT 统计，如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">与操作</span></span><br><span class="line">BITOP AND destmap bitmap:01 bitmap:02 bitmap:03</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">统计 bit 位 =  1 的个数</span></span><br><span class="line">BITCOUNT destmap</span><br></pre></td></tr></table></figure>

<p>即使一天产生一个亿的数据，Bitmap 占用的内存也不大，大约占 12 MB 的内存（10^8&#x2F;8&#x2F;1024&#x2F;1024），7 天的 Bitmap 的内存开销约为 84 MB。同时我们最好给 Bitmap 设置过期时间，让 Redis 删除过期的打卡数据，节省内存。</p>
<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><h3 id="HyperLogLog-简介"><a href="#HyperLogLog-简介" class="headerlink" title="HyperLogLog 简介"></a>HyperLogLog 简介</h3><p>Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于“统计基数”的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。</p>
<p>所以，简单来说 HyperLogLog <strong>提供不精确的去重计数</strong>。</p>
<p>HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。</p>
<p>在 Redis 里面，<strong>每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 <code>2^64</code> 个不同元素的基数</strong>，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。</p>
<p>这什么概念？举个例子给大家对比一下。</p>
<p>用 Java 语言来说，一般 long 类型占用 8 字节，而 1 字节有 8 位，即：1 byte &#x3D; 8 bit，即 long 数据类型最大可以表示的数是：<code>2^63-1</code>。对应上面的<code>2^64</code>个数，假设此时有<code>2^63-1</code>这么多个数，从 <code>0 ~ 2^63-1</code>，按照<code>long</code>以及<code>1k = 1024 字节</code>的规则来计算内存总数，就是：<code>((2^63-1) * 8/1024)K</code>，这是很庞大的一个数，存储空间远远超过<code>12K</code>，而 <code>HyperLogLog</code> 却可以用 <code>12K</code> 就能统计完。</p>
<h3 id="HyperLogLog-实现"><a href="#HyperLogLog-实现" class="headerlink" title="HyperLogLog 实现"></a>HyperLogLog 实现</h3><p>HyperLogLog 的实现涉及到很多数学问题，太费脑子了，我也没有搞懂，如果你想了解一下，课下可以看看这个：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a>。</p>
<h3 id="HyperLogLog-命令"><a href="#HyperLogLog-命令" class="headerlink" title="HyperLogLog 命令"></a>HyperLogLog 命令</h3><p>HyperLogLog 命令很少，就三个。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加指定元素到 HyperLogLog 中</span></span><br><span class="line">PFADD key element [element ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回给定 HyperLogLog 的基数估算值。</span></span><br><span class="line">PFCOUNT key [key ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将多个 HyperLogLog 合并为一个 HyperLogLog</span></span><br><span class="line">PFMERGE destkey sourcekey [sourcekey ...]</span><br></pre></td></tr></table></figure>

<h3 id="HyperLogLog-应用"><a href="#HyperLogLog-应用" class="headerlink" title="HyperLogLog 应用"></a>HyperLogLog 应用</h3><h4 id="百万级网页-UV-计数"><a href="#百万级网页-UV-计数" class="headerlink" title="百万级网页 UV 计数"></a>百万级网页 UV 计数</h4><p>Redis HyperLogLog 优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。</p>
<p>所以，非常适合统计百万级以上的网页 UV 的场景。</p>
<p>在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFADD page1:uv user1 user2 user3 user4 user5</span><br></pre></td></tr></table></figure>

<p>接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFCOUNT page1:uv</span><br></pre></td></tr></table></figure>

<p>不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。</p>
<p>这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</p>
<h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><h3 id="GEO-简介"><a href="#GEO-简介" class="headerlink" title="GEO 简介"></a>GEO 简介</h3><p>Redis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。</p>
<p>在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。</p>
<h3 id="GEO-实现"><a href="#GEO-实现" class="headerlink" title="GEO 实现"></a>GEO 实现</h3><p>GEO 本身并没有设计新的底层数据结构，而是直接使用了 Zset 类型。</p>
<p>GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是“对二维地图做区间划分”和“对区间进行编码”。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。</p>
<p>这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。</p>
<h3 id="GEO-命令"><a href="#GEO-命令" class="headerlink" title="GEO 命令"></a>GEO 命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。</span></span><br><span class="line">GEOADD key longitude latitude member [longitude latitude member ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。</span></span><br><span class="line">GEOPOS key member [member ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回两个给定位置之间的距离。</span></span><br><span class="line">GEODIST key member1 member2 [m|km|ft|mi]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。</span></span><br><span class="line">GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]</span><br></pre></td></tr></table></figure>

<h3 id="GEO-应用"><a href="#GEO-应用" class="headerlink" title="GEO 应用"></a>GEO 应用</h3><h4 id="滴滴叫车"><a href="#滴滴叫车" class="headerlink" title="滴滴叫车"></a>滴滴叫车</h4><p>这里以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。</p>
<p>假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。</p>
<p>执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEOADD cars:locations 116.034579 39.030452 33</span><br></pre></td></tr></table></figure>

<p>当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。</p>
<p>例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10</span><br></pre></td></tr></table></figure>

<h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><h3 id="Stream-简介"><a href="#Stream-简介" class="headerlink" title="Stream 简介"></a>Stream 简介</h3><p>Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。</p>
<p>在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：</p>
<ul>
<li>发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；</li>
<li>List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。</li>
</ul>
<p>基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。</p>
<h3 id="Stream-命令"><a href="#Stream-命令" class="headerlink" title="Stream 命令"></a>Stream 命令</h3><p>Stream 消息队列操作命令：</p>
<ul>
<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li>
<li>XLEN：查询消息长度；</li>
<li>XREAD：用于读取消息，可以按 ID 读取数据；</li>
<li>XDEL：根据消息 ID 删除消息；</li>
<li>DEL：删除整个 Stream；</li>
<li>XRANGE：读取区间消息</li>
<li>XREADGROUP：按消费组形式读取消息；</li>
<li>XPENDING 和 XACK：<ul>
<li>XPENDING 命令可以用来查询每个消费组内所有消费者“已读取、但尚未确认”的消息；</li>
<li>XACK 命令用于向消息队列确认消息处理已完成；</li>
</ul>
</li>
</ul>
<h3 id="Stream-应用"><a href="#Stream-应用" class="headerlink" title="Stream 应用"></a>Stream 应用</h3><h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><p>生产者通过 XADD 命令插入一条消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">* 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">往名称为 mymq 的消息队列中插入一条消息，消息的键是 name，值是 xiaolin</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XADD mymq * name xiaolin</span></span><br><span class="line">&quot;1654254953808-0&quot;</span><br></pre></td></tr></table></figure>

<p>插入成功后会返回全局唯一的 ID：”1654254953808-0”。消息的全局唯一 ID 由两部分组成：</p>
<ul>
<li>第一部分“1654254953808”是数据插入时，以毫秒为单位计算的当前服务器时间；</li>
<li>第二部分表示插入消息在当前毫秒内的消息序号，这是从 0 开始编号的。例如，“1654254953808-0”就表示在“1654254953808”毫秒内的第 1 条消息。</li>
</ul>
<p>消费者通过 XREAD 命令从消息队列中读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取（注意是输入消息 ID 的下一条信息开始读取，不是查询输入 ID 的消息）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从 ID 号为 1654254953807-0 的消息开始，读取后续的所有消息（示例中一共 1 条）。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREAD STREAMS mymq 1654254953807-0</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br></pre></td></tr></table></figure>

<p>如果<strong>想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 BLOCK 配置项</strong>，实现类似于 BRPOP 的阻塞读取操作。</p>
<p>比如，下面这命令，设置了 BLOCK 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令最后的“$”符号表示读取最新的消息</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREAD BLOCK 10000 STREAMS mymq $</span></span><br><span class="line">(nil)</span><br><span class="line">(10.00s)</span><br></pre></td></tr></table></figure>

<p>Stream 的基础方法，使用 xadd 存入消息和 xread 循环阻塞读取消息的方式可以实现简易版的消息队列，交互流程如下图所示：</p>
<blockquote>
<p>前面介绍的这些操作 List 也支持的，接下来看看 Stream 特有的功能。</p>
</blockquote>
<p>Stream 可以以使用 <strong>XGROUP 创建消费组</strong>，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。</p>
<p>创建两个消费组，这两个消费组消费的消息队列是 mymq，都指定从第一条消息开始读取：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个名为 group1 的消费组，0-0 表示从第一条消息开始读取。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XGROUP CREATE mymq group1 0-0</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个名为 group2 的消费组，0-0 表示从第一条消息开始读取。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XGROUP CREATE mymq group2 0-0</span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>消费组 group1 内的消费者 consumer1 从 mymq 消息队列中读取所有消息的命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令最后的参数“&gt;”，表示从第一条尚未被消费的消息开始读取。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group1 consumer1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br></pre></td></tr></table></figure>

<p><strong>消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息</strong>。</p>
<p>比如说，我们执行完刚才的 XREADGROUP 命令后，再执行一次同样的命令，此时读到的就是空值了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group1 consumer1 STREAMS mymq &gt;</span></span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure>

<p>但是，<strong>不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）</strong>。</p>
<p>比如说，刚才 group1 消费组里的 consumer1 消费者消费了一条 id 为 1654254953808-0 的消息，现在用 group2 消费组里的 consumer1 消费者消费消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group2 consumer1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br></pre></td></tr></table></figure>

<p>因为我创建两组的消费组都是从第一条消息开始读取，所以可以看到第二组的消费者依然可以消费 id 为 1654254953808-0 的这一条消息。因此，不同的消费组的消费者可以消费同一条消息。</p>
<p>使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。</p>
<p>例如，我们执行下列命令，让 group2 中的 consumer1、2、3 各自读取一条消息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">让 group2 中的 consumer1 从 mymq 消息队列中消费一条消息</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group2 consumer1 COUNT 1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">让 group2 中的 consumer2 从 mymq 消息队列中消费一条消息</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group2 consumer2 COUNT 1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654256265584-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolincoding&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">让 group2 中的 consumer3 从 mymq 消息队列中消费一条消息</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group2 consumer3 COUNT 1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654256271337-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;Tom&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？</p>
</blockquote>
<p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。</p>
<p>消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成，整个流程的执行如下图所示：</p>
<p>如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，<strong>消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息</strong>。</p>
<p>例如，我们来查看一下 group2 中各个消费者已读取、但尚未确认的消息个数，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; XPENDING mymq group2</span><br><span class="line">1) (integer) 3</span><br><span class="line">2) &quot;1654254953808-0&quot;  # 表示 group2 中所有消费者读取的消息最小 ID</span><br><span class="line">3) &quot;1654256271337-0&quot;  # 表示 group2 中所有消费者读取的消息最大 ID</span><br><span class="line">4) 1) 1) &quot;consumer1&quot;</span><br><span class="line">      2) &quot;1&quot;</span><br><span class="line">   2) 1) &quot;consumer2&quot;</span><br><span class="line">      2) &quot;1&quot;</span><br><span class="line">   3) 1) &quot;consumer3&quot;</span><br><span class="line">      2) &quot;1&quot;</span><br></pre></td></tr></table></figure>

<p>如果想查看某个消费者具体读取了哪些数据，可以执行下面的命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 group2 里 consumer2 已从 mymq 消息队列中读取了哪些消息</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XPENDING mymq group2 - + 10 consumer2</span></span><br><span class="line">1) 1) &quot;1654256265584-0&quot;</span><br><span class="line">   2) &quot;consumer2&quot;</span><br><span class="line">   3) (integer) 410700</span><br><span class="line">   4) (integer) 1</span><br></pre></td></tr></table></figure>

<p>可以看到，consumer2 已读取的消息的 ID 是 1654256265584-0。</p>
<p><strong>一旦消息 1654256265584-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除</strong>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XACK mymq group2 1654256265584-0</span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p>当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XPENDING mymq group2 - + 10 consumer2</span></span><br><span class="line">(empty array)</span><br></pre></td></tr></table></figure>

<p>好了，基于 Stream 实现的消息队列就说到这里了，小结一下：</p>
<ul>
<li>消息保序：XADD&#x2F;XREAD</li>
<li>阻塞读取：XREAD block</li>
<li>重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；</li>
<li>消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；</li>
<li>支持消费组形式消费数据</li>
</ul>
<blockquote>
<p>Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？</p>
</blockquote>
<p>一个专业的消息队列，必须要做到两大块：</p>
<ul>
<li>消息不丢。</li>
<li>消息可堆积。</li>
</ul>
<p><em>1、Redis Stream 消息会丢失吗？</em></p>
<p>使用一个消息队列，其实就分为三大块：<strong>生产者、队列中间件、消费者</strong>，所以要保证消息就是保证三个环节都不能丢失数据。</p>
<p>Redis Stream 消息队列能不能保证三个环节都不丢失数据？</p>
<ul>
<li>Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到（MQ 中间件）的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。</li>
<li>Redis 消费者会不会丢消息？不会，因为 Stream（MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，但是未被确认的消息。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失。</li>
<li>Redis 消息中间件会不会丢消息？<strong>会</strong>，Redis 在以下 2 个场景下，都会导致数据丢失：<ul>
<li>AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能</li>
<li>主从复制也是异步的，<a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/cluster/master_slave_replication.html#redis-%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1">主从切换时，也存在丢失数据的可能</a>。</li>
</ul>
</li>
</ul>
<p>可以看到，Redis 在队列中间件环节无法保证消息不丢。像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写“多个节点”，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。</p>
<p><em>2、Redis Stream 消息可堆积吗？</em></p>
<p>Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。</p>
<p>所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。</p>
<p>当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。</p>
<p>但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。</p>
<p>因此，把 Redis 当作队列来使用时，会面临的 2 个问题：</p>
<ul>
<li>Redis 本身可能会丢数据；</li>
<li>面对消息挤压，内存资源会紧张；</li>
</ul>
<p>所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：</p>
<ul>
<li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li>
<li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li>
</ul>
<blockquote>
<p>补充：Redis 发布&#x2F;订阅机制为什么不可以作为消息队列？</p>
</blockquote>
<p>发布订阅机制存在以下缺点，都是跟丢失数据有关：</p>
<ol>
<li>发布&#x2F;订阅机制没有基于任何数据类型实现，所以不具备“数据持久化”的能力，也就是发布&#x2F;订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布&#x2F;订阅机制的数据也会全部丢失。</li>
<li>发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。</li>
<li>当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 <code>client-output-buffer-limit pubsub 32mb 8mb 60</code>。</li>
</ol>
<p>所以，发布&#x2F;订阅机制只适合即时通讯的场景，比如<a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/cluster/sentinel.html#%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%84%E6%88%90%E7%9A%84">构建哨兵集群</a>的场景采用了发布&#x2F;订阅机制。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Redis 后续版本又支持四种数据类型，它们的应用场景如下：</p>
<ul>
<li>BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</li>
<li>HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；</li>
<li>GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；</li>
<li>Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息 ID，支持以消费组形式消费数据。</li>
</ul>
<p>针对 Redis 是否适合做消息队列，关键看你的业务场景：</p>
<ul>
<li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li>
<li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://redis.io/">Redis 官网</a></li>
<li><a target="_blank" rel="noopener" href="http://redis.cn/">Redis 官方文档中文版</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11791607.html">《Redis 实战》</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011957758/article/details/74783347">一看就懂系列之 详解 redis 的 bitmap 在亿级项目中的应用</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-BitMap/">Fast, easy, realtime metrics using Redis BitMap</a></li>
<li><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/data_struct/command.html#string">Redis 常见数据类型和应用场景</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/4de901/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/4de901/" class="post-title-link" itemprop="url">Redis 持久化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-持久化"><a href="#Redis-持久化" class="headerlink" title="Redis 持久化"></a>Redis 持久化</h1><blockquote>
<p>Redis 是内存型数据库，为了保证数据在宕机后不会丢失，需要将内存中的数据持久化到硬盘上。</p>
<p>Redis 支持两种持久化方式：RDB 和 AOF。这两种持久化方式既可以同时使用，也可以单独使用。</p>
<p>关键词：<code>RDB</code>、<code>AOF</code>、<code>SAVE</code>、<code>BGSAVE</code>、<code>appendfsync</code></p>
</blockquote>
<h2 id="RDB-快照"><a href="#RDB-快照" class="headerlink" title="RDB 快照"></a>RDB 快照</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309150718907.png"></p>
<h3 id="RDB-简介"><a href="#RDB-简介" class="headerlink" title="RDB 简介"></a>RDB 简介</h3><p><strong>RDB 即“快照”，它将某时刻的所有 Redis 数据库中的所有键值对数据保存到一个经过压缩的“二进制文件”（RDB 文件）中</strong>。</p>
<p><strong>RDB 持久化即可以“手动”执行，也可以定期“自动”执行</strong>。</p>
<p><strong>RDB 文件的“载入”工作是在服务器“启动”时“自动”执行的</strong>。</p>
<p>对于不同类型的键值对， RDB 文件会使用不同的方式来保存它们。</p>
<p>创建 RDB 后，用户可以对 RDB 进行备份，可以将 RDB 复制到其他服务器从而创建具有相同数据的服务器副本，还可以在重启服务器时使用。一句话来说：<strong>RDB 适用于作为“冷备”</strong>。</p>
<h3 id="RDB-的优点和缺点"><a href="#RDB-的优点和缺点" class="headerlink" title="RDB 的优点和缺点"></a>RDB 的优点和缺点</h3><p><strong>RDB 的优点</strong></p>
<ul>
<li>RDB 文件非常紧凑，<strong>适合作为“冷备”</strong>。比如你可以在每个小时报保存一下过去 24 小时内的数据，同时每天保存过去 30 天的数据，这样即使出了问题你也可以根据需求恢复到不同版本的数据集。</li>
<li>快照在保存 RDB 文件时父进程唯一需要做的就是 fork 出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他 IO 操作，所以快照持久化方式可以最大化 Redis 的性能。</li>
<li><strong>恢复大数据集时，RDB 比 AOF 更快</strong>。</li>
</ul>
<p><strong>RDB 的缺点</strong></p>
<ul>
<li><strong>如果系统发生故障，将会丢失最后一次创建快照之后的数据</strong>。如果你希望在 Redis 意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么 快照不适合你。虽然你可以配置不同的 save 时间点(例如每隔 5 分钟并且对数据集有 100 个写的操作)，是 Redis 要完整的保存整个数据集是一个比较繁重的工作，你通常会每隔 5 分钟或者更久做一次完整的保存，万一在 Redis 意外宕机，你可能会丢失几分钟的数据。</li>
<li><strong>如果数据量很大，保存快照的时间会很长</strong>。快照需要经常 fork 子进程来保存数据集到硬盘上。当数据集比较大的时候，fork 的过程是非常耗时的，可能会导致 Redis 在一些毫秒级内不能响应客户端的请求。如果数据集巨大并且 CPU 性能不是很好的情况下，这种情况会持续 1 秒。AOF 也需要 fork，但是你可以调节重写日志文件的频率来提高数据集的耐久度。</li>
</ul>
<h3 id="RDB-的创建"><a href="#RDB-的创建" class="headerlink" title="RDB 的创建"></a>RDB 的创建</h3><p>有两个 Redis 命令可以用于生成 RDB 文件：<a target="_blank" rel="noopener" href="https://redis.io/commands/save"><strong><code>SAVE</code></strong></a> 和 <a target="_blank" rel="noopener" href="https://redis.io/commands/bgsave"><strong><code>BGSAVE</code></strong></a> 。</p>
<p><a target="_blank" rel="noopener" href="https://redis.io/commands/save"><strong><code>SAVE</code></strong></a> 命令由服务器进程直接执行保存操作，直到 RDB 创建完成为止。所以<strong>该命令“会阻塞”服务器</strong>，在阻塞期间，服务器不能响应任何命令请求。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">SAVE</span></span><br><span class="line">&quot;OK&quot;</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://redis.io/commands/bgsave"><strong><code>BGSAVE</code></strong></a> 命令会<strong>“派生”</strong>（fork）一个子进程，由子进程负责创建 RDB 文件，服务器进程继续处理命令请求，所以<strong>该命令“不会阻塞”服务器</strong>。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309172009198.png" alt="BGSAVE 流程"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">BGSAVE</span></span><br><span class="line">&quot;Background saving started&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>🔔 <strong>【注意】</strong></p>
<p><code>BGSAVE</code> 命令的实现采用的是写时复制技术（Copy-On-Write，缩写为 CoW）。</p>
<p><code>BGSAVE</code> 命令执行期间，<code>SAVE</code>、<code>BGSAVE</code>、<code>BGREWRITEAOF</code> 三个命令会被拒绝，以免与当前的 <code>BGSAVE</code> 操作产生竞态条件，降低性能。</p>
</blockquote>
<p>创建 RDB 的工作由 <code>rdb.c/rdbSave</code> 函数完成。</p>
<h3 id="RDB-的载入"><a href="#RDB-的载入" class="headerlink" title="RDB 的载入"></a>RDB 的载入</h3><p><strong>RDB 文件的“载入”工作是在服务器“启动”时“自动”执行的</strong>。Redis 并没有专门用于载入 RDB 文件的命令。</p>
<p>服务器载入 RDB 文件期间，会一直处于阻塞状态，直到载入完成为止。</p>
<p>载入 RDB 的工作由 <code>rdb.c/rdbLoad</code> 函数完成。</p>
<blockquote>
<p>🔔 <strong>【注意】</strong></p>
<p>因为 AOF 的更新频率通常比 RDB 的更新频率高，所以：</p>
<ul>
<li>如果服务器开了 AOF，则服务器会优先使用 AOF 来还原数据。</li>
<li>只有在 AOF 处于关闭时，服务器才会使用 RDB 来还原数据。</li>
</ul>
</blockquote>
<h3 id="自动间隔保存"><a href="#自动间隔保存" class="headerlink" title="自动间隔保存"></a>自动间隔保存</h3><p>Redis 支持通过在 <code>redis.conf</code> 文件中配置 <code>save</code> 选项，让服务器每隔一段时间自动执行一次 <code>BGSAVE</code> 命令。<code>save</code> 选项可以设置多个保存条件，只要其中任意一个条件被满足，服务器就会执行 <code>BGSAVE</code> 命令。</p>
<p>【示例】<code>redis.conf</code> 中自动保存配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">900 秒内，至少对数据库进行了 1 次修改</span></span><br><span class="line">save 900 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">300 秒内，至少对数据库进行了 10 次修改</span></span><br><span class="line">save 300 10</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">60 秒内，至少对数据库进行了 10000 次修改</span></span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>

<p>只要满足以上任意条件，Redis 服务就会执行 <code>BGSAVE</code> 命令。</p>
<p>自动间隔的保存条件定义在 <code>redis.h/redisServer</code> 中：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line">    <span class="comment">// 记录了保存条件的数组</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">saveparam</span> *<span class="title">saveparams</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自从上次 SAVE 执行以来，数据库被修改的次数</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> dirty;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 上一次完成 SAVE 的时间</span></span><br><span class="line">    <span class="type">time_t</span> lastsave;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 服务器的保存条件（BGSAVE 自动执行的条件）</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">saveparam</span> &#123;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 多少秒之内</span></span><br><span class="line">    <span class="type">time_t</span> seconds;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 发生多少次修改</span></span><br><span class="line">    <span class="type">int</span> changes;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>redisServer 中的 <code>saveparams</code> 数组维护了多个自动间隔保存条件。</p>
<p>服务每次成功执行一个修改命令后，<code>dirty</code> 计数器就会加 1；而 <code>lastsave</code> 则记录了上一次完成 SAVE 的时间。Redis 会通过一个 <code>serverCron</code> 函数周期性检查 <code>save</code> 选项所设条件是否满足，如果满足，则执行 <code>BGSVAE</code> 命令。</p>
<h3 id="RDB-的文件结构"><a href="#RDB-的文件结构" class="headerlink" title="RDB 的文件结构"></a>RDB 的文件结构</h3><p><strong>RDB 文件是一个经过压缩的“二进制文件”</strong>，由多个部分组成。</p>
<p>对于不同类型（STRING、HASH、LIST、SET、SORTED SET）的键值对，RDB 文件会使用不同的方式来保存它们。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309171645336.png" alt="RDB 的文件结构"></p>
<p>Redis 本身提供了一个 RDB 文件检查工具 <code>redis-check-dump</code>。</p>
<h3 id="RDB-的配置"><a href="#RDB-的配置" class="headerlink" title="RDB 的配置"></a>RDB 的配置</h3><p>Redis RDB 默认配置如下：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">save</span> <span class="number">900</span> <span class="number">1</span></span><br><span class="line"><span class="attribute">save</span> <span class="number">300</span> <span class="number">10</span></span><br><span class="line"><span class="attribute">save</span> <span class="number">60</span> <span class="number">10000</span></span><br><span class="line"><span class="attribute">stop</span>-writes-<span class="literal">on</span>-bgsave-error yes</span><br><span class="line"><span class="attribute">rdbcompression</span> yes</span><br><span class="line"><span class="attribute">rdbchecksum</span> yes</span><br><span class="line"><span class="attribute">dbfilename</span> dump.rdb</span><br><span class="line"><span class="attribute">dir</span> ./</span><br></pre></td></tr></table></figure>

<p>Redis 的配置文件 <code>redis.conf</code> 中与 RDB 有关的选项：</p>
<ul>
<li><p><code>save</code> - Redis 会根据 <code>save</code> 选项，让服务器每隔一段时间自动执行一次 <code>BGSAVE</code> 命令</p>
</li>
<li><p><code>stop-writes-on-bgsave-error</code> - 当 <code>BGSAVE</code> 命令出现错误时停止写 RDB 文件</p>
</li>
<li><p><code>rdbcompression</code> - RDB 文件开启压缩功能</p>
</li>
<li><p><code>rdbchecksum</code> - 对 RDB 文件进行校验</p>
</li>
<li><p><code>dbfilename</code> - RDB 文件名</p>
</li>
<li><p><code>dir</code> - RDB 文件和 AOF 文件的存储路径</p>
</li>
</ul>
<h2 id="AOF-日志"><a href="#AOF-日志" class="headerlink" title="AOF 日志"></a>AOF 日志</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309150718055.png"></p>
<h3 id="AOF-简介"><a href="#AOF-简介" class="headerlink" title="AOF 简介"></a>AOF 简介</h3><p><code>AOF(Append Only File)</code> 是将所有写命令追加写入“日志文件”，以此来记录数据的变化。当服务器重启时，会重新载入和执行 AOF 文件中的命令，就可以恢复原始的数据。AOF 适合作为<strong>“热备”</strong>。</p>
<p>AOF 可以通过 <code>appendonly yes</code> 配置选项来开启。</p>
<h3 id="AOF-的优点和缺点"><a href="#AOF-的优点和缺点" class="headerlink" title="AOF 的优点和缺点"></a>AOF 的优点和缺点</h3><p><strong>AOF 的优点</strong></p>
<ul>
<li><strong>如果系统发生故障，AOF 丢失数据比 RDB 少</strong>。你可以使用不同的 fsync 策略：无 fsync；每秒 fsync；每次写的时候 fsync。使用默认的每秒 fsync 策略，Redis 的性能依然很好(fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求)，一旦出现故障，你最多丢失 1 秒的数据。</li>
<li><strong>AOF 文件可修复</strong> - AOF 文件是一个只进行追加的日志文件，所以不需要写入 seek，即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令，你也也可使用 redis-check-aof 工具修复这些问题。</li>
<li><strong>AOF 文件可压缩</strong>。Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li>
<li><strong>AOF 文件可读</strong> - AOF 文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 命令的格式保存。因此 AOF 文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单。举个例子，如果你不小心执行了 FLUSHALL 命令，但只要 AOF 文件未被重写，那么只要停止服务器，移除 AOF 文件末尾的 FLUSHALL 命令，并重启 Redis ，就可以将数据集恢复到 FLUSHALL 执行之前的状态。</li>
</ul>
<p><strong>AOF 的缺点</strong></p>
<ul>
<li><strong>AOF 文件体积一般比 RDB 大</strong> - 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。</li>
<li><strong>恢复大数据集时，AOF 比 RDB 慢。</strong> - 根据所使用的 fsync 策略，AOF 的速度可能会慢于快照。在一般情况下，每秒 fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和快照一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，快照可以提供更有保证的最大延迟时间（latency）。</li>
</ul>
<h3 id="AOF-的创建"><a href="#AOF-的创建" class="headerlink" title="AOF 的创建"></a>AOF 的创建</h3><p><strong>Redis 命令请求会先保存到 AOF 缓冲区，再定期写入并同步到 AOF 文件</strong>。</p>
<p>AOF 的实现可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤。</p>
<ul>
<li><strong>命令追加</strong> - 当 Redis 服务器开启 AOF 功能时，服务器在执行完一个写命令后，会以 Redis 命令协议格式将被执行的写命令追加到 AOF 缓冲区的末尾。</li>
<li><strong>文件写入</strong>和<strong>文件同步</strong><ul>
<li>Redis 的服务器进程就是一个事件循环，这个循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复。而时间事件则负责执行想 <code>serverCron</code> 这样的定时运行的函数。</li>
<li>因为服务器在处理文件事件时可能会执行写命令，这些写命令会被追加到 AOF 缓冲区，服务器每次结束事件循环前，都会根据 <code>appendfsync</code> 选项来判断 AOF 缓冲区内容是否需要写入和同步到 AOF 文件中。</li>
</ul>
</li>
</ul>
<p><code>appendfsync</code> 不同选项决定了不同的持久化行为：</p>
<ul>
<li><strong><code>always</code></strong> - 将 AOF 缓冲区中所有内容写入并同步到 AOF 文件。这种方式是最数据最安全的，但也是性能最差的。</li>
<li><strong><code>no</code></strong> - 将 AOF 缓冲区所有内容写入到 AOF 文件，但并不对 AOF 文件进行同步，何时同步由操作系统决定。这种方式是数据最不安全的，一旦出现故障，未来得及同步的所有数据都会丢失。</li>
<li><strong><code>everysec</code></strong> - <code>appendfsync</code> 默认选项。将 AOF 缓冲区所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟，那么再次对 AOF 文件进行同步，这个同步操作是有一个线程专门负责执行的。这张方式是前面两种的这种方案——性能足够好，且即使出现故障，仅丢失一秒钟内的数据。</li>
</ul>
<p><code>appendfsync</code> 选项的不同值对 AOF 持久化功能的安全性、以及 Redis 服务器的性能有很大的影响。</p>
<h3 id="AOF-的载入"><a href="#AOF-的载入" class="headerlink" title="AOF 的载入"></a>AOF 的载入</h3><p>因为 AOF 文件中包含了重建数据库所需的所有写命令，所以服务器只要载入并执行一遍 AOF 文件中保存的写命令，就可以还原服务器关闭前的数据库状态。</p>
<p>AOF 载入过程如下：</p>
<ol>
<li>服务器启动载入程序。</li>
<li>创建一个伪客户端。因为 Redis 命令只能在客户端上下文中执行，所以需要创建一个伪客户端来载入、执行 AOF 文件中记录的命令。</li>
<li>从 AOF 文件中分析并读取一条写命令。</li>
<li>使用伪客户端执行写命令。</li>
<li>循环执行步骤 3、4，直到所有写命令都被处理完毕为止。</li>
<li>载入完毕。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309171705818.png" alt="AOF 文件载入"></p>
<h3 id="AOF-的重写"><a href="#AOF-的重写" class="headerlink" title="AOF 的重写"></a>AOF 的重写</h3><p>随着 Redis 不断运行，AOF 的体积也会不断增长，这将导致两个问题：</p>
<ul>
<li>AOF 耗尽磁盘可用空间。</li>
<li>Redis 重启后需要执行 AOF 文件记录的所有写命令来还原数据集，如果 AOF 过大，则还原操作执行的时间就会非常长。</li>
</ul>
<p>为了解决 AOF 体积膨胀问题，Redis 提供了 AOF 重写功能，来对 AOF 文件进行压缩。<strong>AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原来的 AOF 文件所保存的数据库状态一致，但体积更小</strong>。</p>
<p>AOF 重写并非读取和分析现有 AOF 文件的内容，而是直接从数据库中读取当前的数据库状态。即<strong>从数据库中读取键的当前值，然后用一条命令去记录该键值对</strong>，以此代替之前可能存在冗余的命令。</p>
<h3 id="AOF-后台重写"><a href="#AOF-后台重写" class="headerlink" title="AOF 后台重写"></a>AOF 后台重写</h3><p>作为一种辅助性功能，显然 Redis 并不想在 AOF 重写时阻塞 Redis 服务接收其他命令。因此，Redis 决定通过 <code>BGREWRITEAOF</code> 命令创建一个子进程，然后由子进程负责对 AOF 文件进行重写，这与 <code>BGSAVE</code> 原理类似。</p>
<ul>
<li>在执行 <code>BGREWRITEAOF</code> 命令时，Redis 服务器会维护一个 AOF 重写缓冲区。当 AOF 重写子进程开始工作后，Redis 每执行完一个写命令，会同时将这个命令发送给 AOF 缓冲区和 AOF 重写缓冲区。</li>
<li>由于彼此不是在同一个进程中工作，AOF 重写不影响 AOF 写入和同步。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。</li>
<li>最后，服务器用新的 AOF 文件替换就的 AOF 文件，以此来完成 AOF 重写操作。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309171957918.png" alt="BGREWRITEAOF 流程"></p>
<blockquote>
<p><code>BGREWRITEAOF</code> 命令的实现采用的是写时复制技术（Copy-On-Write，缩写为 CoW）。</p>
</blockquote>
<p>可以通过设置 <code>auto-aof-rewrite-percentage</code> 和 <code>auto-aof-rewrite-min-size</code>，使得 Redis 在满足条件时，自动执行 <code>BGREWRITEAOF</code>。</p>
<p>假设配置如下：</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span>-aof-rewrite-percentage <span class="number">100</span></span><br><span class="line"><span class="keyword">auto</span>-aof-rewrite-min-size <span class="number">64</span>mb</span><br></pre></td></tr></table></figure>

<p>表明，当 AOF 大于 <code>64MB</code>，且 AOF 体积比上一次重写后的体积大了至少 <code>100%</code> 时，执行 <code>BGREWRITEAOF</code>。</p>
<h3 id="AOF-的配置"><a href="#AOF-的配置" class="headerlink" title="AOF 的配置"></a>AOF 的配置</h3><p>AOF 的默认配置：</p>
<figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">appendonly no</span><br><span class="line">appendfsync everysec</span><br><span class="line">no-appendfsync-on-<span class="built_in">rewrite</span> no</span><br><span class="line"><span class="built_in">auto</span>-aof-<span class="built_in">rewrite</span>-percentage <span class="number">100</span></span><br><span class="line"><span class="built_in">auto</span>-aof-<span class="built_in">rewrite</span>-min-size <span class="number">64</span>mb</span><br></pre></td></tr></table></figure>

<p>AOF 持久化通过在 <code>redis.conf</code> 中的 <code>appendonly yes</code> 配置选项来开启。</p>
<ul>
<li><strong><code>appendonly</code></strong> - 开启 AOF 功能。</li>
<li><strong><code>appendfilename</code></strong> - AOF 文件名。</li>
<li><strong><code>appendfsync</code></strong> - 用于设置同步频率，它有以下可选项：<ul>
<li><strong><code>always</code></strong> - 每个 Redis 写命令都要同步写入硬盘。这样做会严重降低 Redis 的速度。</li>
<li><strong><code>everysec</code></strong> - 每秒执行一次同步，显示地将多个写命令同步到硬盘。为了兼顾数据安全和写入性能，推荐使用 <code>appendfsync everysec</code> 选项。Redis 每秒同步一次 AOF 文件时的性能和不使用任何持久化特性时的性能相差无几。</li>
<li><strong><code>no</code></strong> - 让操作系统来决定应该何时进行同步。</li>
</ul>
</li>
<li><code>no-appendfsync-on-rewrite</code> - AOF 重写时不支持追加命令。</li>
<li><code>auto-aof-rewrite-percentage</code> - AOF 重写百分比。</li>
<li><code>auto-aof-rewrite-min-size</code> - AOF 重写文件的最小大小。</li>
<li><code>dir</code> - RDB 文件和 AOF 文件的存储路径。</li>
</ul>
<h2 id="RDB-和-AOF"><a href="#RDB-和-AOF" class="headerlink" title="RDB 和 AOF"></a>RDB 和 AOF</h2><blockquote>
<p>当 Redis 启动时， 如果 RDB 和 AOF 功能都开启了，那么程序会优先使用 AOF 文件来恢复数据集，因为 AOF 文件所保存的数据通常是最完整的。</p>
</blockquote>
<h3 id="如何选择持久化"><a href="#如何选择持久化" class="headerlink" title="如何选择持久化"></a>如何选择持久化</h3><ul>
<li>如果不关心数据丢失，可以不持久化。</li>
<li>如果可以承受数分钟以内的数据丢失，可以只使用 RDB。</li>
<li>如果不能承受数分钟以内的数据丢失，可以同时使用 RDB 和 AOF。</li>
</ul>
<p>有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份，并且快照恢复数据集的速度也要比 AOF 恢复的速度要快，除此之外，使用快照还可以避免之前提到的 AOF 程序的 bug 。</p>
<h3 id="RDB-切换为-AOF"><a href="#RDB-切换为-AOF" class="headerlink" title="RDB 切换为 AOF"></a>RDB 切换为 AOF</h3><p>在 Redis 2.2 或以上版本，可以在不重启的情况下，从 RDB 切换为 AOF ：</p>
<ul>
<li>为最新的 dump.rdb 文件创建一个备份。</li>
<li>将备份放到一个安全的地方。</li>
<li>执行以下两条命令:</li>
<li>redis-cli config set appendonly yes</li>
<li>redis-cli config set save</li>
<li>确保写命令会被正确地追加到 AOF 文件的末尾。</li>
<li>执行的第一条命令开启了 AOF 功能： Redis 会阻塞直到初始 AOF 文件创建完成为止， 之后 Redis 会继续处理命令请求， 并开始将写入命令追加到 AOF 文件末尾。</li>
</ul>
<p>执行的第二条命令用于关闭快照功能。 这一步是可选的， 如果你愿意的话， 也可以同时使用快照和 AOF 这两种持久化功能。</p>
<blockquote>
<p>🔔 重要：别忘了在 <code>redis.conf</code> 中打开 AOF 功能！否则的话，服务器重启之后，之前通过 CONFIG SET 设置的配置就会被遗忘，程序会按原来的配置来启动服务器。</p>
</blockquote>
<h3 id="AOF-和-RDB-的相互作用"><a href="#AOF-和-RDB-的相互作用" class="headerlink" title="AOF 和 RDB 的相互作用"></a>AOF 和 RDB 的相互作用</h3><p><code>BGSAVE</code> 和 <code>BGREWRITEAOF</code> 命令不可以同时执行。这是为了避免两个 Redis 后台进程同时对磁盘进行大量的 I&#x2F;O 操作。</p>
<p>如果 <code>BGSAVE</code> 正在执行，并且用户显示地调用 <code>BGREWRITEAOF</code> 命令，那么服务器将向用户回复一个 OK 状态，并告知用户，<code>BGREWRITEAOF</code> 已经被预定执行。一旦 <code>BGSAVE</code> 执行完毕， <code>BGREWRITEAOF</code> 就会正式开始。</p>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h3><p>Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p>
<p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p>
<h2 id="Redis-备份"><a href="#Redis-备份" class="headerlink" title="Redis 备份"></a>Redis 备份</h2><p>应该确保 Redis 数据有完整的备份。</p>
<p>备份 Redis 数据建议采用 RDB。</p>
<h3 id="备份过程"><a href="#备份过程" class="headerlink" title="备份过程"></a>备份过程</h3><ol>
<li>创建一个定期任务（cron job），每小时将一个 RDB 文件备份到一个文件夹，并且每天将一个 RDB 文件备份到另一个文件夹。</li>
<li>确保快照的备份都带有相应的日期和时间信息，每次执行定期任务脚本时，使用 find 命令来删除过期的快照：比如说，你可以保留最近 48 小时内的每小时快照，还可以保留最近一两个月的每日快照。</li>
<li>至少每天一次，将 RDB 备份到你的数据中心之外，或者至少是备份到你运行 Redis 服务器的物理机器之外。</li>
</ol>
<h3 id="容灾备份"><a href="#容灾备份" class="headerlink" title="容灾备份"></a>容灾备份</h3><p>Redis 的容灾备份基本上就是对数据进行备份，并将这些备份传送到多个不同的外部数据中心。</p>
<p>容灾备份可以在 Redis 运行并产生快照的主数据中心发生严重的问题时，仍然让数据处于安全状态。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/379cd8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/379cd8/" class="post-title-link" itemprop="url">Redis 复制</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-复制"><a href="#Redis-复制" class="headerlink" title="Redis 复制"></a>Redis 复制</h1><blockquote>
<p>在 Redis 中，<strong>可以通过执行 <code>SLAVEOF</code> 命令或设置 <code>slaveof</code> 选项，让一个服务器去复制（replicate）另一个服务器</strong>，其中，后者叫主服务器（master），前者叫从服务器（slave）。</p>
<p>Redis 2.8 以前的复制不能高效处理断线后重复制的情况，而 Redis 2.8 新添的部分重同步可以解决这个问题。</p>
<p>关键词：<code>SLAVEOF</code>、<code>SYNC</code>、<code>PSYNC</code>、<code>命令传播</code>、<code>心跳</code></p>
</blockquote>
<h2 id="复制简介"><a href="#复制简介" class="headerlink" title="复制简介"></a>复制简介</h2><p>Redis 通过 <code>slaveof host port</code> 命令来让一个服务器成为另一个服务器的从服务器。</p>
<p><strong>一个主服务器可以有多个从服务器</strong>。不仅主服务器可以有从服务器，从服务器也可以有自己的从服务器， 多个从服务器之间可以构成一个主从链。</p>
<p><strong>一个从服务器只能有一个主服务器，并且不支持主主复制</strong>。</p>
<p>可以通过复制功能来让主服务器免于执行持久化操作： 只要关闭主服务器的持久化功能， 然后由从服务器去执行持久化操作即可。</p>
<p>在使用 Redis 复制功能时的设置中，强烈建议在 master 和在 slave 中启用持久化。当不启用时，例如由于非常慢的磁盘性能而导致的延迟问题，<strong>应该配置实例来避免重置后自动重启</strong>。</p>
<p>从 Redis 2.6 开始， 从服务器支持只读模式， 并且该模式为从服务器的默认模式。</p>
<ul>
<li>只读模式由 <code>redis.conf</code> 文件中的 <code>slave-read-only</code> 选项控制， 也可以通过 <a target="_blank" rel="noopener" href="http://redisdoc.com/configure/config_set.html#config-set">CONFIG SET parameter value</a> 命令来开启或关闭这个模式。</li>
<li>只读从服务器会拒绝执行任何写命令， 所以不会出现因为操作失误而将数据不小心写入到了从服务器的情况。</li>
</ul>
<h2 id="旧版复制"><a href="#旧版复制" class="headerlink" title="旧版复制"></a>旧版复制</h2><blockquote>
<p>Redis 2.8 版本以前实现方式：<code>SYNC</code> 命令</p>
</blockquote>
<p>Redis 的复制功能分为同步（sync）和命令传播（command propagate）两个操作：</p>
<ul>
<li><strong><code>同步（sync）</code></strong> - 用于将从服务器的数据库状态更新至主服务器当前的数据库状态。</li>
<li><strong><code>命令传播（command propagate）</code></strong> - 当主服务器的数据库状态被修改，导致主从数据库状态不一致时，让主从服务器的数据库重新回到一致状态。</li>
</ul>
<h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p><code>SYNC</code> 命令的执行步骤：</p>
<ol>
<li>从服务器向主服务器发送 <code>SYNC</code> 命令。</li>
<li>收到 <code>SYNC</code> 命令的主服务器执行 <code>BGSAVE</code> 命令，在后台生成一个 RDB 文件，并使用一个缓冲区记录从现在开始执行的所有写命令。</li>
<li>主服务器执行 <code>BGSAVE</code> 完毕后，主服务器会将生成的 RDB 文件发送给从服务器。从服务器接收并载入 RDB 文件，更新自己的数据库状态。</li>
<li>主服务器将记录在缓冲区中的所有写命令发送给从服务器，从服务器执行这些写命令，更新自己的数据库状态。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309172035716.png"></p>
<h3 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h3><p>同步操作完成后，主从数据库的数据库状态将达到一致。每当主服务器执行客户端发送的写命令时，主从数据库状态不再一致。需要将写命令发送给从服务器执行，使得二者的数据库状态重新达到一致。</p>
<h3 id="旧版复制的缺陷"><a href="#旧版复制的缺陷" class="headerlink" title="旧版复制的缺陷"></a>旧版复制的缺陷</h3><p>从服务器对主服务器的复制存在两种情况：</p>
<ul>
<li><strong>初次复制</strong> - 从服务器以前没有复制过将要复制的主服务器。</li>
<li><strong>断线后重复制</strong> - 处于命令传播阶段的主从服务器因为网络原因而中断了复制，当从服务器通过自动重连重新连上了主服务器后，继续复制主服务器。</li>
</ul>
<p>对于初次复制，旧版复制功能可用很好完成任务；但是<strong>对于断线后重复制，由于每次任然需要生成 RDB 并传输，效率很低</strong>。</p>
<blockquote>
<p>🔔 注意：<strong>SYNC 命令是一个非常耗费资源的操作。</strong></p>
<ul>
<li>主服务器执行 <code>BGSAVE</code> 命令生成 RDB 文件，这个操作会耗费主服务器大量的 CPU、内存和磁盘 I&#x2F;O 资源。</li>
<li>主服务器传输 RDB 文件给从服务器，这个操作会耗费主从服务器大量的网络资源，并对主服务器响应时延产生影响。</li>
<li>从服务器载入 RDB 文件期间，会阻塞其他命令请求。</li>
</ul>
</blockquote>
<h2 id="新版复制"><a href="#新版复制" class="headerlink" title="新版复制"></a>新版复制</h2><blockquote>
<p>Redis 2.8 版本以后的新实现方式：使用 <code>PSYNC</code> 命令替代 <code>SYNC</code> 命令。</p>
</blockquote>
<p><code>PSYNC</code> 命令具有完整重同步和部分重同步两种模式：</p>
<ul>
<li><strong><code>完整重同步（full resychronization）</code></strong> - 用于初次复制。执行步骤与 <code>SYNC</code> 命令基本一致。</li>
<li><strong><code>部分重同步（partial resychronization）</code></strong> - 用于断线后重复制。<strong>如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器</strong>，从服务器只需接收并执行这些写命令，即可将主从服务器的数据库状态保持一致。</li>
</ul>
<h3 id="部分重同步"><a href="#部分重同步" class="headerlink" title="部分重同步"></a>部分重同步</h3><p>部分重同步功能实现由三个部分构成：</p>
<ul>
<li>主从服务器的<strong>复制偏移量（replication offset）</strong></li>
<li>主服务器的<strong>复制积压缓冲区（replication backlog）</strong></li>
<li><strong>服务器的运行 ID</strong></li>
</ul>
<h4 id="复制偏移量"><a href="#复制偏移量" class="headerlink" title="复制偏移量"></a>复制偏移量</h4><p>主服务器和从服务器会分别维护一个复制偏移量。</p>
<ul>
<li>如果主从服务器的复制偏移量相同，则说明二者的数据库状态一致；</li>
<li>反之，则说明二者的数据库状态不一致。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309172031325.png"></p>
<h4 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h4><p><strong>复制积压缓冲区是主服务器维护的一个固定长度的先进先出（FIFO）队列</strong>，默认大小为 <code>1MB</code>。</p>
<p>复制积压缓冲区会保存一部分最近传播的写命令，并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量。</p>
<p>当从服务器断线重连主服务时，从服务器会通过 <code>PSYNC</code> 命令将自己的复制偏移量 offset 发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作。</p>
<ul>
<li>如果 offset 之后的数据仍然在复制积压缓冲区，则主服务器对从服务器执行部分重同步操作。</li>
<li>反之，则主服务器对从服务器执行完整重同步操作。</li>
</ul>
<blockquote>
<p>🔔 注意：<strong>合理调整复制积压缓冲区的大小</strong></p>
<ul>
<li><p>Redis 复制积压缓冲区默认大小为 <code>1MB</code>。</p>
</li>
<li><p>复制积压缓冲区的最小大小可以根据公式 <code>second * write_size_per_second</code> 估算。</p>
</li>
</ul>
</blockquote>
<h4 id="服务器的运行-ID"><a href="#服务器的运行-ID" class="headerlink" title="服务器的运行 ID"></a>服务器的运行 ID</h4><ul>
<li>每个 Redis 服务器，都有运行 ID，用于唯一识别身份。</li>
<li>运行 ID 在服务器启动时自动生成，由 40 个随机的十六进制字符组成。例如：132e358005e29741f8d7b0a42d666aace286edda</li>
</ul>
<p>从服务器对主服务器进行初次复制时，主服务器会将自己的运行 ID 传送给从服务器，从服务器会将这个运行 ID 保存下来。</p>
<p>当从服务器断线重连一个主服务器时，从服务器会发送之前保存的运行 ID：</p>
<ul>
<li>如果保存的运行 ID 和当前主服务器的运行 ID 一致，则说明从服务器断线之前连接的就是这个主服务器，主服务器可以继续尝试执行部分重同步操作；</li>
<li>反之，若运行 ID 不一致，则说明从服务器断线之前连接的不是这个主服务器，主服务器将对从服务器执行完整重同步操作。</li>
</ul>
<h3 id="PSYNC-命令"><a href="#PSYNC-命令" class="headerlink" title="PSYNC 命令"></a>PSYNC 命令</h3><p>了解了部分重同步的实现，PSYNC 的实现就很容易理解了，它的基本工作原理大致如下：</p>
<p>当从服务接收到 <code>SLAVEOF</code> 命令时，先判断从服务器以前是否执行过复制操作。</p>
<ul>
<li>如果没有复制过任何主服务器，向要复制的主服务器<strong>发送 <code>PSYNC ? -1</code> 命令，主动请求进行完整重同步</strong>。</li>
<li>反之，向要复制的主服务器发送 <code>PSYNC &lt;runid&gt; &lt;offset&gt;</code> 命令。<ul>
<li><code>runid</code> 是上一次复制的主服务器的运行 ID。</li>
<li><code>offset</code> 是复制偏移量。</li>
</ul>
</li>
</ul>
<p>接收到 <code>PSYNC &lt;runid&gt; &lt;offset&gt;</code> 命令的主服务会进行分析：</p>
<ul>
<li>假如主从服务器的 <strong>master run id 相同</strong>，并且<strong>指定的偏移量（offset）在内存缓冲区中还有效</strong>，复制就会从上次中断的点开始继续。</li>
<li>如果其中一个条件不满足，就会进行完全重新同步（在 2.8 版本之前就是直接进行完全重新同步）。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309172030499.png"></p>
<h2 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a>心跳检测</h2><p>在<strong>命令传播</strong>阶段，从服务器默认会以<strong>每秒一次</strong>的频率，向主服务器发送命令：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLCONF ACK <span class="tag">&lt;<span class="name">replication_offset</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中，<code>replication_offset</code> 是从服务器当前的复制偏移量。</p>
<p>发送 <code>REPLCONF ACK</code> 命令对于主从服务器有三个作用：</p>
<ul>
<li>检测主从服务器的网络连接状态。</li>
<li>辅助实现 min-slaves 选项。</li>
<li>检测命令丢失。</li>
</ul>
<h3 id="检测主从连接状态"><a href="#检测主从连接状态" class="headerlink" title="检测主从连接状态"></a>检测主从连接状态</h3><p><strong>可以通过发送和接收 <code>REPLCONF ACK</code> 命令来检查主从服务器之间的网络连接</strong>是否正常：如果主服务器超过一秒没有收到从服务器发来的 <code>REPLCONF ACK</code> 命令，那么主服务器就知道主从服务器之间的连接出现问题了。</p>
<p>可以通过向主服务器发送 <code>INFO replication</code> 命令，在列出的从服务器列表的 lag 一栏中，可以看到从服务器向主服务器发送 <code>REPLCONF ACK</code> 命令已经过去多少秒。</p>
<h3 id="辅助实现-min-slaves-选项"><a href="#辅助实现-min-slaves-选项" class="headerlink" title="辅助实现 min-slaves 选项"></a>辅助实现 min-slaves 选项</h3><p>Redis 的 <strong><code>min-slaves-to-write</code> 和 <code>min-slaves-max-lag</code> 两个选项可以防止主服务器在不安全的情况下执行写命令</strong>。</p>
<p>【示例】min-slaves 配置项</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">min</span>-slaves-<span class="built_in">to</span>-<span class="built_in">write</span> <span class="number">3</span></span><br><span class="line"><span class="built_in">min</span>-slaves-<span class="built_in">max</span>-lag <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>以上配置表示：从服务器小于 3 个，或三个从服务器的延迟（lag）都大于等于 10 秒时，主服务器将拒绝执行写命令。</p>
<h3 id="检测命令丢失"><a href="#检测命令丢失" class="headerlink" title="检测命令丢失"></a>检测命令丢失</h3><p>如果因为网络故障，主服务传播给从服务器的写命令丢失，那么从服务器定时向主服务器发送 <code>REPLCONF ACK</code> 命令时，主服务器将发觉从服务器的复制偏移量少于自己的。然后，主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区中找到从服务器缺少的数据，并将这些数据重新发送给从服务器。</p>
<h2 id="复制的流程"><a href="#复制的流程" class="headerlink" title="复制的流程"></a>复制的流程</h2><p>通过向从服务器发送如下 SLAVEOF 命令，可以让一个从服务器去复制一个主服务器。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SLAVEOF <span class="tag">&lt;<span class="name">master_ip</span>&gt;</span> <span class="tag">&lt;<span class="name">master_port</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="步骤-1-设置主从服务器"><a href="#步骤-1-设置主从服务器" class="headerlink" title="步骤 1. 设置主从服务器"></a>步骤 1. 设置主从服务器</h3><p>配置一个从服务器非常简单， 只要在配置文件中增加以下的这一行就可以了：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">slaveof</span> <span class="number">127.0.0.1</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure>

<p>当然， 你需要将代码中的 <code>127.0.0.1</code> 和 <code>6379</code> 替换成你的主服务器的 IP 和端口号。</p>
<p>另外一种方法是调用 <a target="_blank" rel="noopener" href="http://redisdoc.com/replication/slaveof.html#slaveof">SLAVEOF host port</a> 命令， 输入主服务器的 IP 和端口， 然后同步就会开始：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">127</span>.<span class="number">0</span>.<span class="number">0</span>.<span class="number">1</span>:<span class="number">6379</span>&gt; SLAVEOF <span class="number">127.0.0.1</span> <span class="number">10086</span></span><br><span class="line"><span class="attribute">OK</span></span><br></pre></td></tr></table></figure>

<h3 id="步骤-2-主从服务器建立-TCP-连接。"><a href="#步骤-2-主从服务器建立-TCP-连接。" class="headerlink" title="步骤 2. 主从服务器建立 TCP 连接。"></a>步骤 2. 主从服务器建立 TCP 连接。</h3><h3 id="步骤-3-发送-PING-检查通信状态。"><a href="#步骤-3-发送-PING-检查通信状态。" class="headerlink" title="步骤 3. 发送 PING 检查通信状态。"></a>步骤 3. 发送 PING 检查通信状态。</h3><h3 id="步骤-4-身份验证。"><a href="#步骤-4-身份验证。" class="headerlink" title="步骤 4. 身份验证。"></a>步骤 4. 身份验证。</h3><p>如果主服务器没有设置 <code>requirepass</code> ，从服务器没有设置 <code>masterauth</code>，则不进行身份验证；反之，则需要进行身份验证。如果身份验证失败，则放弃执行复制工作。</p>
<p>如果主服务器通过 <code>requirepass</code> 选项设置了密码， 那么为了让从服务器的同步操作可以顺利进行， 我们也必须为从服务器进行相应的身份验证设置。</p>
<p>对于一个正在运行的服务器， 可以使用客户端输入以下命令：</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config set masterauth &lt;password&gt;</span><br></pre></td></tr></table></figure>

<p>要永久地设置这个密码， 那么可以将它加入到配置文件中：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">masterauth <span class="tag">&lt;<span class="name">password</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>另外还有几个选项， 它们和主服务器执行部分重同步时所使用的复制流缓冲区有关， 详细的信息可以参考 Redis 源码中附带的 <code>redis.conf</code> 示例文件。</p>
<h3 id="步骤-5-发送端口信息。"><a href="#步骤-5-发送端口信息。" class="headerlink" title="步骤 5. 发送端口信息。"></a>步骤 5. 发送端口信息。</h3><p>从服务器执行 <code>REPLCONF listening-port &lt;port-number&gt;</code> ，向主服务器发送从服务器的监听端口号。</p>
<h3 id="步骤-6-同步。"><a href="#步骤-6-同步。" class="headerlink" title="步骤 6. 同步。"></a>步骤 6. 同步。</h3><p>前文已介绍，此处不赘述。</p>
<h3 id="步骤-7-命令传播。"><a href="#步骤-7-命令传播。" class="headerlink" title="步骤 7. 命令传播。"></a>步骤 7. 命令传播。</h3><p>在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务发送命令：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLCONF ACK <span class="tag">&lt;<span class="name">replication_coffset</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>命令的作用：</p>
<ul>
<li>检测主从服务器的网络连接状态。</li>
<li>辅助实现 min-slave 选项。</li>
<li>检测命令丢失。</li>
</ul>
<h2 id="复制的配置项"><a href="#复制的配置项" class="headerlink" title="复制的配置项"></a>复制的配置项</h2><p>从 Redis 2.8 开始， 为了保证数据的安全性， 可以通过配置， 让主服务器只在有至少 N 个当前已连接从服务器的情况下， 才执行写命令。</p>
<p>不过， 因为 Redis 使用异步复制， 所以主服务器发送的写数据并不一定会被从服务器接收到， 因此， 数据丢失的可能性仍然是存在的。</p>
<p>以下是这个特性的运作原理：</p>
<ul>
<li>从服务器以每秒一次的频率 PING 主服务器一次， 并报告复制流的处理情况。</li>
<li>主服务器会记录各个从服务器最后一次向它发送 PING 的时间。</li>
<li>用户可以通过配置， 指定网络延迟的最大值 <code>min-slaves-max-lag</code> ， 以及执行写操作所需的至少从服务器数量 <code>min-slaves-to-write</code> 。</li>
</ul>
<p>如果至少有 <code>min-slaves-to-write</code> 个从服务器， 并且这些服务器的延迟值都少于 <code>min-slaves-max-lag</code>秒， 那么主服务器就会执行客户端请求的写操作。</p>
<p>你可以将这个特性看作 CAP 理论中的 C 的条件放宽版本： 尽管不能保证写操作的持久性， 但起码丢失数据的窗口会被严格限制在指定的秒数中。</p>
<p>另一方面， 如果条件达不到 <code>min-slaves-to-write</code> 和 <code>min-slaves-max-lag</code> 所指定的条件， 那么写操作就不会被执行， 主服务器会向请求执行写操作的客户端返回一个错误。</p>
<p>以下是这个特性的两个选项和它们所需的参数：</p>
<ul>
<li><code>min-slaves-to-write &lt;number of slaves&gt;</code></li>
<li><code>min-slaves-max-lag &lt;number of seconds&gt;</code></li>
</ul>
<p>详细的信息可以参考 Redis 源码中附带的 <code>redis.conf</code> 示例文件。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://redis.io/docs/management/replication/">Redis 官方文档之复制</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/615afe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/615afe/" class="post-title-link" itemprop="url">Redis 哨兵</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-哨兵"><a href="#Redis-哨兵" class="headerlink" title="Redis 哨兵"></a>Redis 哨兵</h1><blockquote>
<p>Redis 2.8 版本，新增了哨兵模式，以支持“自动故障转移”，它是 Redis 的 HA 方案。</p>
<p>Redis 哨兵模式由一个或多个 Sentinel 实例组成 Sentinel 集群，可以监控任意多个主服务器，以及这些主服务器的所有从服务器；并在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p>
<p>关键词：<code>高可用</code>、<code>监控</code>、<code>选主</code>、<code>故障转移</code>、<code>Raft</code></p>
</blockquote>
<h2 id="哨兵简介"><a href="#哨兵简介" class="headerlink" title="哨兵简介"></a>哨兵简介</h2><p>Redis 的主从复制模式，虽然提供了一定程度的 <strong>高可用性（High Availability）</strong>。但是，当主节点出现故障时，只能通过手动操作将从节点晋升为主节点，这显然是比较低效的。为了解决这个问题，Redis 2.8 版本提供了哨兵模式（Sentinel）来支持“自动故障转移”。</p>
<p>Redis 哨兵模式由一个或多个 Sentinel 实例组成 Sentinel 集群，可以监控任意多个主服务器，以及这些主服务器的所有从服务器；并在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309190749810.png"></p>
<p>Sentinel 的主要功能如下：</p>
<ul>
<li><strong><code>监控（Monitoring）</code></strong> - Sentinel 不断检查主从服务器是否正常在工作。</li>
<li><strong><code>通知（Notification）</code></strong> - Sentinel 可以通过一个 api 来通知系统管理员或者另外的应用程序，被监控的 Redis 实例有一些问题。</li>
<li><strong><code>自动故障转移（Automatic Failover）</code></strong> - 如果一个主服务器下线，Sentinel 会开始自动故障转移：把一个从节点提升为主节点，并重新配置其他的从节点使用新的主节点，使用 Redis 服务的应用程序在连接的时候也被通知新的地址。</li>
<li><strong><code>配置提供者（Configuration provider）</code></strong> - Sentinel 给客户端的服务发现提供来源：对于一个给定的服务，客户端连接到 Sentinels 来寻找当前主节点的地址。当故障转移发生的时候，Sentinel 将报告新的地址。</li>
</ul>
<h2 id="启动哨兵"><a href="#启动哨兵" class="headerlink" title="启动哨兵"></a>启动哨兵</h2><p>启动一个 Sentinel 可以使用下面任意一条命令，两条命令效果完全相同。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-sentinel /path/to/sentinel.conf</span><br><span class="line">redis-server /path/to/sentinel.conf --sentinel</span><br></pre></td></tr></table></figure>

<p>当一个 Sentinel 启动时，它需要执行以下步骤：</p>
<ol>
<li>初始化服务器。</li>
<li>使用 Sentinel 专用代码。</li>
<li>初始化 Sentinel 状态。</li>
<li>初始化 Sentinel 的主服务器列表。</li>
<li>创建连向被监视的主服务器的网络连接。</li>
</ol>
<p><strong>Sentinel 本质上是一个运行在“特殊模式”下的 Redis 服务器</strong>。Sentinel 模式下 Redis 服务器只支持 <code>PING</code>、<code>SENTINEL</code>、<code>INFO</code>、<code>SUBSCRIBE</code>、<code>UNSUBSCRIBE</code>、<code>PSUBSCRIBE</code>、<code>PUNSUBSCRIBE</code> 七个命令。</p>
<p>创建连向被监视的主服务器的网络连接，Sentinel 将成为主服务器的客户端，它可以向主服务器发送命令，并从命令回复中获取相关的信息。Sentinel 会读入用户指定的配置文件， 为每个要被监视的主服务器创建相应的实例结构， 并创建连向主服务器的命令连接和订阅连接：</p>
<ul>
<li><strong>命令连接</strong> - 专门用于向主服务器发送命令，并接受命令回复。</li>
<li><strong>订阅连接</strong> - 专门用于订阅主服务器的 <code>__sentinel__:hello</code> 频道。</li>
</ul>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><h3 id="获取服务器信息"><a href="#获取服务器信息" class="headerlink" title="获取服务器信息"></a>获取服务器信息</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309190750857.png"></p>
<p>默认情况下， Sentinel 以<strong>“每十秒一次”</strong>的频率向被监视的主服务器和从服务器<strong>发送 <code>INFO</code> 命令</strong>，并通过分析 <code>INFO</code> 命令的回复来获取服务器的当前信息。</p>
<ul>
<li>主服务器 - 可以获取主服务器自身信息，以及其所属从服务器的地址信息。</li>
<li>从服务器 - 从服务器自身信息，以及其主服务器的了解状态和地址。</li>
</ul>
<p><strong>Sentinel 通过向主服务器发送 <code>INFO</code> 命令来获得主服务器属下所有从服务器的地址信息， 并为这些从服务器创建相应的实例结构， 以及连向这些从服务器的“命令连接”和“订阅连接”</strong>。</p>
<p>对于监视同一个主服务器和从服务器的多个 Sentinel 来说， 它们会以“每两秒一次”的频率， 通过向被监视服务器的 <code>__sentinel__:hello</code> 频道发送消息来向其他 Sentinel 宣告自己的存在。Sentinel 只会与主服务器和从服务器创建命令连接和订阅连接， Sentinel 与 Sentinel 之间则只创建命令连接。</p>
<h3 id="判断下线"><a href="#判断下线" class="headerlink" title="判断下线"></a>判断下线</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309190801360.png"></p>
<h4 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h4><p><strong>默认，每个 Sentinel 以“每秒一次”的频率，向它所知的“所有实例”发送一个 <code>PING</code> 命令</strong>。</p>
<ul>
<li>“所知”是指，与 Sentinel 创建了命令连接的实例。</li>
<li>“所有实例”包括了主服务器、从服务器以及其他 Sentinel 实例。</li>
</ul>
<p>如果，<strong>某实例在指定的时长（ <code>down-after-milliseconds</code> 设置的值，单位毫秒）中，未向 Sentinel 发送有效回复， Sentinel 会将该实例判定为“主观下线”</strong>。</p>
<ul>
<li>一个有效的 <code>PING</code> 回复可以是：<code>+PONG</code>、<code>-LOADING</code> 或者 <code>-MASTERDOWN</code>。如果服务器返回除以上三种回复之外的其他回复，又或者在 <strong>指定时间</strong> 内没有回复 <code>PING</code> 命令， 那么 Sentinel 认为服务器返回的回复无效。</li>
<li>“主观下线”适用于所有主节点和从节点。</li>
</ul>
<h4 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h4><p>当一个<strong>“主服务器”</strong>被 Sentinel 标记为<strong>“主观下线”</strong>后，为了确认其是否真的下线，Sentinel 会向同样监听该主服务器的其他 Sentinel 发起询问。如果有<strong>“足够数量”</strong>的 Sentinel 在指定的时间范围内认为主服务器已下线，那么这个<strong>“主服务器”</strong>被标记为<strong>“客观下线”</strong>。</p>
<ul>
<li>Sentinel 节点通过 <code>sentinel is-master-down-by-addr</code> 命令，向其它 Sentinel 节点询问对某主服务器的 <strong>状态判断</strong>。</li>
<li>“足够数量”是指 Sentinel 配置中 <code>quorum</code> 参数所设的值。</li>
<li>客观下线只适用于主节点。</li>
</ul>
<p>注：默认情况下， Sentinel 以<strong>“每十秒一次”</strong>的频率向被监视的主服务器和从服务器<strong>发送 <code>INFO</code> 命令</strong>。当一个主服务器被 Sentinel 标记为<strong>“客观下线”</strong>时，Sentinel 向该主服务器的所有从服务器发送 <code>INFO</code> 命令的频率，会从<strong>“每十秒一次”</strong>改为<strong>“每秒一次”</strong>。</p>
<h2 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h2><blockquote>
<p>Redis Sentinel 采用 <a target="_blank" rel="noopener" href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf">Raft 协议</a> 实现了其 Sentinel 选主流程。Raft 是一种共识性算法，想了解其原理，可以参考 <a target="_blank" rel="noopener" href="https://dunwu.github.io/waterdrop/pages/4907dc/">深入剖析共识性算法 Raft</a>。</p>
</blockquote>
<p><strong>当一个“主服务器”被判断为“客观下线”时，监视该主服务器的各个 Sentinel 会进行“协商”，选举出一个领头的 Sentinel（Leader），并由领头 Sentinel 对下线主服务器执行“故障转移”操作</strong>。</p>
<p>所有在线 Sentinel 都有资格被选为 Leader。</p>
<ol>
<li>当一个 Sentinel 认定某主服务器是“客观下线”后，该 Sentinel 会先看看自己是否投过票。<ul>
<li>如果已投票给其他 Sentinel 了，在 2 倍故障转移的超时时间内，都不能竞选 <strong>Leader</strong>——相当于它是一个 <strong>Follower</strong>。</li>
<li>如果未投票，那么该 Sentinel 可以竞选 <strong>Leader</strong>，转为 <strong>Candidate</strong>。</li>
</ul>
</li>
<li>如 Raft 协议所描述的，<strong>Candidate</strong> 需要完成几件事情：<ol>
<li>更新故障转移状态为 start</li>
<li>将当前纪元（<code>epoch</code>） 加 1，表明开始新一轮的选举——这里的 <code>epoch</code> 相当于 Raft 协议中的 <code>term</code>。</li>
<li>将自身的超时时间设为当前时间加上一个随机值，随机值为 1s 内的随机毫秒数。</li>
<li>向其他节点发送 <code>is-master-down-by-addr</code> 命令，请求其他节点投票支持自己，命令会携带自己的 <code>epoch</code>。</li>
<li>Candidate 会投票给自己。在 Sentinel 中，投票的方式是把自己 <code>master</code> 结构体里的 <code>leader</code> 和 <code>leader_epoch</code> 改成投给的 Sentinel 和它的 <code>epoch</code>。</li>
</ol>
</li>
<li>其他 Sentinel 收到 <strong>Candidate</strong> 的 <code>is-master-down-by-addr</code> 命令后，如果 Sentinel 当前 <code>epoch</code> 和 <strong>Candidate</strong> 传给他的 <code>epoch</code> 一样，说明他已经把自己 <code>master</code> 结构体里的 <code>leader</code> 和 <code>leader_epoch</code> 改成其他 <strong>Candidate</strong>，相当于把票投给了其他 <strong>Candidate</strong>。投票给其他 Sentinel 后，在当前 <code>epoch</code> 内，该 Sentinel 就只能成为 <strong>Follower</strong>。</li>
<li><strong>Candidate</strong> 会不断的统计自己的票数，如果满足“当选投票条件”，则该 <strong>Candidate</strong> 当选 <strong>Leader</strong>：<ol>
<li>票数超过一半（监控主服务器的 Sentinel 的节点数的一半 + 1）</li>
<li>票数超过 Sentinel 配置的 <code>quorum</code> 参数——注：Raft 协议中没有这个限制，这是 Redis Sentinel 所独有的</li>
</ol>
</li>
<li>如果在一个选举周期内（<code>epoch</code>），<strong>Candidate</strong> 没有满足“当选投票条件”（第 4 点描述的），则竞选失败。</li>
<li>如果在一个选举周期内（<code>epoch</code>），没有一个 <strong>Candidate</strong> 满足“当选投票条件”，说明所有 <strong>Candidate</strong> 都竞选失败，本轮选举作废。在等待超过 2 倍故障转移的超时时间后，开始新一轮的选举。</li>
<li>与 Raft 协议不同的是，Leader 并不会把自己成为 <strong>Leader</strong> 的消息发给其他 Sentinel。当 <strong>Leader</strong> 完成故障转移后，其他 Sentinel 检测到新的主服务器正常工作后，就会去掉“客观下线”的标识，从而不需要再发起选举。</li>
</ol>
<h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><p>在选举产生出 Sentinel Leader 后，Sentinel Leader 将对已下线的主服务器执行故障转移操作。操作含以下三个步骤：</p>
<p>（1）<strong>选出新的主服务器</strong></p>
<p>故障转移第一步，是 Sentinel Leader 在已下线主服务属下的所有从服务器中，挑选一个状态良好、数据完整的从服务器。然后，向这个从服务器发送 <code>SLAVEOF no one</code> 命令，将其转换为主服务器。</p>
<p>Sentinel Leader 如何选出新的主服务器：</p>
<ul>
<li>删除列表中所有处于下线或断线状态的从服务器。</li>
<li>删除列表中所有最近五秒没有回复过 Sentinel Leader 的 <code>INFO</code> 命令的从服务器。</li>
<li>删除所有与已下线主服务器连接断开超过 <code>down-after-milliseconds * 10</code> 毫秒的从服务器（<code>down-after-milliseconds</code> 指定了判断主服务器下线所需的时间）。</li>
<li>之后， Sentinel Leader 先选出优先级最高的从服务器；如果优先级一样高，再选择复制偏移量最大的从服务器；如果结果还不唯一，则选出运行 ID 最小的从服务器。</li>
</ul>
<p>（2）<strong>修改从服务器的复制目标</strong></p>
<p>选出新的主服务器后，Sentinel Leader 会向所有从服务器发送 <code>SLAVEOF</code> 命令，让它们去复制新的主服务器。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309190802685.png"></p>
<p>（3）<strong>将旧的主服务器变为从服务器</strong></p>
<p>Sentinel Leader 将旧的主服务器标记为从服务器。当旧的主服务器重新上线，Sentinel 会向它发送 <code>SLAVEOF</code> 命令，让其成为从服务器。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309190803617.png"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
<li><a target="_blank" rel="noopener" href="http://www.web-lovers.com/redis-source-sentinel.html">渐进式解析 Redis 源码 - 哨兵 sentinel</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.im/post/5b7d226a6fb9a01a1e01ff64">深入剖析 Redis 系列(二) - Redis 哨兵模式与高可用集群</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/77dfbe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/77dfbe/" class="post-title-link" itemprop="url">Redis 集群</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h1><blockquote>
<p><strong><a target="_blank" rel="noopener" href="https://redis.io/topics/cluster-tutorial">Redis 集群（Redis Cluster）</a> 是 Redis 官方提供的“分布式数据库”方案</strong>。</p>
<p>Redis Cluster 既然被设计分布式系统，自然需要具备分布式系统的基本特性：伸缩性、高可用、一致性。</p>
<ul>
<li><strong>伸缩性</strong> - Redis Cluster 通过划分虚拟 hash 槽来进行“分区”，以实现集群的伸缩性。</li>
<li><strong>高可用</strong> - Redis Cluster 采用主从架构，支持“复制”和“自动故障转移”，以保证 Redis Cluster 的高可用。</li>
<li><strong>一致性</strong> - 根据 CAP 理论，Consistency、Availability、Partition tolerance 三者不可兼得。而 Redis Cluster 的选择是 AP，即不保证“强一致性”，尽力达到“最终一致性”。</li>
</ul>
<p>Redis Cluster 应用了 <a target="_blank" rel="noopener" href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf">Raft 协议</a> 协议和 Gossip 协议。</p>
<p>关键词：<code>高可用</code>、<code>监控</code>、<code>选主</code>、<code>故障转移</code>、<code>分区</code>、<code>Raft</code>、<code>Gossip</code></p>
</blockquote>
<h2 id="Redis-Cluster-分区"><a href="#Redis-Cluster-分区" class="headerlink" title="Redis Cluster 分区"></a>Redis Cluster 分区</h2><h3 id="集群节点"><a href="#集群节点" class="headerlink" title="集群节点"></a>集群节点</h3><p>Redis Cluster 由多个节点组成，节点刚启动时，彼此是相互独立的。<strong>节点通过握手（ <a target="_blank" rel="noopener" href="https://redis.io/commands/cluster-meet/"><code>CLUSTER MEET</code></a> 命令）来将其他节点添加到自己所处的集群中</strong>。</p>
<p>向一个节点发送 <code>CLUSTER MEET</code> 命令，可以让当前节点与指定 IP、PORT 的节点进行三次握手，握手成功时，当前节点会将指定节点加入所在集群。</p>
<p><strong>集群节点保存键值对以及过期时间的方式与单机 Redis 服务完全相同</strong>。</p>
<p>Redis Cluster 节点分为主节点（master）和从节点（slave）：</p>
<ul>
<li>主节点用于处理槽。</li>
<li>从节点用于复制主节点， 并在主节点下线时， 代替主节点继续处理命令请求。</li>
</ul>
<h3 id="分配-Hash-槽"><a href="#分配-Hash-槽" class="headerlink" title="分配 Hash 槽"></a>分配 Hash 槽</h3><p>分布式存储需要解决的首要问题是把整个数据集按照<strong>“分区规则”</strong> 到<strong>多个节点</strong>，即每个节点负责整体数据的一个 <strong>子集</strong>。</p>
<p><strong>Redis Cluster 将整个数据库规划为 “16384” 个虚拟的哈希槽</strong>，数据库中的每个键都属于其中一个槽。<strong>每个节点都会记录哪些槽指派给了自己， 而哪些槽又被指派给了其他节点</strong>。</p>
<p><strong>如果数据库中有任何一个槽没有得到分配，那么集群处于“下线”状态</strong>。</p>
<p>通过向节点发送 <a target="_blank" rel="noopener" href="https://redis.io/commands/cluster-addslots"><code>CLUSTER ADDSLOTS</code></a> 命令，可以将一个或多个槽指派给节点负责。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">CLUSTER ADDSLOTS 1 2 3</span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>集群中的每个节点负责一部分哈希槽，比如集群中有３个节点，则：</p>
<ul>
<li>节点Ａ存储的哈希槽范围是：0 – 5500</li>
<li>节点Ｂ存储的哈希槽范围是：5501 – 11000</li>
<li>节点Ｃ存储的哈希槽范围是：11001 – 16384</li>
</ul>
<h3 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h3><p>当客户端向节点发送与数据库键有关的命令时，接受命令的节点会<strong>计算出命令要处理的数据库属于哪个槽</strong>，并<strong>检查这个槽是否指派给了自己</strong>：</p>
<ul>
<li>如果键所在的槽正好指派给了当前节点，那么当前节点直接执行命令。</li>
<li>如果键所在的槽没有指派给当前节点，那么节点会向客户端返回一个 <code>MOVED</code> 错误，指引客户端重定向至正确的节点。</li>
</ul>
<h4 id="计算键属于哪个槽"><a href="#计算键属于哪个槽" class="headerlink" title="计算键属于哪个槽"></a>计算键属于哪个槽</h4><p>决定一个 key 应该分配到那个槽的算法是：<strong>计算该 key 的 CRC16 结果再模 16834</strong>。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">HASH_SLOT</span> = CRC16(KEY) mod <span class="number">16384</span></span><br></pre></td></tr></table></figure>

<p>当节点计算出 key 所属的槽为 i 之后，节点会根据以下条件判断槽是否由自己负责：</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clusterState.slots[i] <span class="operator">=</span><span class="operator">=</span> clusterState.myself</span><br></pre></td></tr></table></figure>

<h4 id="MOVED-错误"><a href="#MOVED-错误" class="headerlink" title="MOVED 错误"></a>MOVED 错误</h4><p>节点在接到一个命令请求时，会先检查这个命令请求要处理的键所在的槽是否由自己负责， 如果不是的话， 节点将向客户端返回一个 <code>MOVED</code> 错误， <code>MOVED</code> 错误携带的信息可以指引客户端转向至正在负责相关槽的节点。</p>
<p><code>MOVED</code> 错误的格式为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>提示：<code>MOVED</code> 命令的作用有点类似 HTTP 协议中的重定向。</p>
</blockquote>
<h3 id="重新分区"><a href="#重新分区" class="headerlink" title="重新分区"></a>重新分区</h3><p>对 Redis Cluster 的重新分片工作是由客户端（redis-trib）执行的， <strong>重新分片的关键是将属于某个槽的所有键值对从一个节点转移至另一个节点</strong>。</p>
<p>重新分区操作可以<strong>“在线”</strong>进行，在重新分区的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求。</p>
<p>重新分区的实现原理如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-cluster-trib.png" alt="img"></p>
<h3 id="ASK-错误"><a href="#ASK-错误" class="headerlink" title="ASK 错误"></a>ASK 错误</h3><p>如果节点 A 正在迁移槽 <code>i</code> 至节点 B ， 那么当节点 A 没能在自己的数据库中找到命令指定的数据库键时， 节点 A 会向客户端返回一个 <code>ASK</code> 错误， 指引客户端到节点 B 继续查找指定的数据库键。</p>
<p><code>ASK</code> 错误与 <code>MOVED</code> 的区别在于：</p>
<ul>
<li><code>MOVED</code> 错误表示槽的负责权已经从一个节点转移到了另一个节点；</li>
<li>而 <code>ASK</code> 错误只是两个节点在迁移槽的过程中使用的一种临时措施。</li>
</ul>
<p>判断 ASK 错误的过程如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-ask.png" alt="img"></p>
<h2 id="Redis-Cluster-复制"><a href="#Redis-Cluster-复制" class="headerlink" title="Redis Cluster 复制"></a>Redis Cluster 复制</h2><p>Redis Cluster 中的节点分为主节点和从节点，其中主节点用于处理槽，而从节点则用于复制某个主节点，并在被复制的主节点下线时，代替下线主节点继续处理命令请求。</p>
<p>向一个节点发送命令 <code>CLUSTER REPLICATE &lt;node_id&gt;</code> 可以让接收命令的节点成为 node_id 所指定节点的从节点，并开始对主节点进行复制。</p>
<p>Redis Cluster 节点间的复制是“异步”的。</p>
<h2 id="Redis-Cluster-故障转移"><a href="#Redis-Cluster-故障转移" class="headerlink" title="Redis Cluster 故障转移"></a>Redis Cluster 故障转移</h2><h3 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h3><p><strong>集群中每个节点都会定期向集群中的其他节点发送 <code>PING</code> 消息，以此来检测对方是否在线</strong>。</p>
<p>节点的状态信息可以分为：</p>
<ul>
<li>在线状态；</li>
<li>疑似下线状态（<code>PFAIL</code>） - 即在规定的时间内，没有应答 <code>PING</code> 消息</li>
<li>已下线状态（<code>FAIL</code>） - 半数以上负责处理槽的主节点都将某个主节点视为“疑似下线”，则这个主节点将被标记为“已下线”</li>
</ul>
<h3 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h3><ol>
<li>下线主节点的所有从节点中，会有一个从节点被选中。</li>
<li>被选中的从节点会执行 <code>SLAVEOF no one</code> 命令，成为新的主节点。</li>
<li>新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。</li>
<li>新的主节点向集群广播一条 <code>PONG</code> 消息，告知其他节点这个从节点已变成主节点。</li>
<li>新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</li>
</ol>
<h3 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h3><blockquote>
<p>Redis Sentinel 和 Redis Cluster 的选主流程非常相似，二者都基于<a target="_blank" rel="noopener" href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf">Raft 协议</a> 实现。</p>
</blockquote>
<ol>
<li>从节点发现自己的主节点状态为 <code>FAIL</code>。</li>
<li>从节点将自己记录的纪元（<code>epoch</code>）加 1，并广播消息，要求所有收到消息且有投票权的主节点都为自己投票。——这里的纪元（<code>epoch</code>），相当于 Raft 协议中的选期（<code>term</code>）。因个人习惯，后面统一将纪元描述为选期。</li>
<li>如果某主节点具有投票权（它正在负责处理槽），并且这个主节点尚未投票，那么主节点就返回一条确认消息，表示支持该从节点成为新的主节点。</li>
<li>每个参与选举的从节点都会根据收到的确认消息，统计自己所得的选票。</li>
<li>假设集群中存在 N 个具有投票权的主节点，那么<strong>当某从节点得到“半数以上”（<code>N / 2 + 1</code>）的选票，则该从节点当选为新的主节点</strong>。</li>
<li>由于每个选期中，任意具有投票权的主节点“只能投一票”，所以获得“半数以上”选票的从节点只能有一个。</li>
<li>如果在一个选期中，没有从节点能获得“半数以上”投票，则本次选期作废，开始进入下一个选期，直到选出新的主节点为止。</li>
</ol>
<h2 id="Redis-Cluster-通信"><a href="#Redis-Cluster-通信" class="headerlink" title="Redis Cluster 通信"></a>Redis Cluster 通信</h2><p><strong>集群中的节点通过发送和接收消息来进行通信</strong>。Redis Cluster 各实例之间的通信方式采用 <a target="_blank" rel="noopener" href="http://publicatio.bibl.u-szeged.hu/1529/1/gossip11.pdf">Gossip 协议</a>来实现。</p>
<p>Redis Cluster 采用 Gossip 协议基于两个主要目标：<strong>去中心化</strong>以及<strong>失败检测</strong>。</p>
<p>Redis Cluster 中，每个节点之间都会同步信息，但是每个节点的信息不保证实时的，即无法保证数据强一致性，但是保证<strong>“数据最终一致性”</strong>——当集群中发生节点增减、故障、主从关系变化、槽信息变更等事件时，通过不断的通信，在经过一段时间后，所有的节点都会同步集群全部节点的最新状态。</p>
<p>Redis Cluster 节点发送的消息主要有以下五种：</p>
<ul>
<li><code>MEET</code> - 请求接收方加入发送方所在的集群。</li>
<li><code>PING</code> - 集群中每个节点每隔一段时间（默认为一秒）从已知节点列表中随机选出五个节点，然后对这五个节点中最久没联系的节点发送 <code>PING</code> 消息，以此检测被选中的节点是否在线。</li>
<li><code>PONG</code> - 当接收方收到发送方发来的 <code>MEET</code> 消息或 <code>PING</code> 消息时，会返回一条 <code>PONG</code> 消息作为应答。</li>
<li><code>FAIL</code> - 当一个主节点 A 判断另一个主节点 B 已经进入 <code>FAIL</code> 状态时，节点 A 会向集群广播一条关于节点 B 的 <code>FAIL</code> 消息，所有收到这条消息的节点都会立即将节点 B 标记为已下线。</li>
<li><code>PUBLISH</code> - 当节点收到一个 <code>PUBLISH</code> 命令时，节点会执行这个命令，并向集群广播一条 <code>PUBLISH</code> 消息，所有接受到这条消息的节点都会执行相同的 <code>PUBLISH</code> 命令。</li>
</ul>
<h2 id="Redis-Cluster-应用"><a href="#Redis-Cluster-应用" class="headerlink" title="Redis Cluster 应用"></a>Redis Cluster 应用</h2><h3 id="集群功能限制"><a href="#集群功能限制" class="headerlink" title="集群功能限制"></a>集群功能限制</h3><p>Redis Cluster 相对 <strong>单机</strong>，存在一些功能限制，需要 <strong>开发人员</strong> 提前了解，在使用时做好规避。</p>
<ul>
<li><code>key</code> <strong>批量操作</strong> 支持有限：类似 <code>mset</code>、<code>mget</code> 操作，目前只支持对具有相同 <code>slot</code> 值的 <code>key</code> 执行 <strong>批量操作</strong>。对于 <strong>映射为不同</strong> <code>slot</code> 值的 <code>key</code> 由于执行 <code>mget</code>、<code>mget</code> 等操作可能存在于多个节点上，因此不被支持。</li>
<li><code>key</code> <strong>事务操作</strong> 支持有限：只支持 <strong>多</strong> <code>key</code> 在 <strong>同一节点上</strong> 的 <strong>事务操作</strong>，当多个 <code>key</code> 分布在 <strong>不同</strong> 的节点上时 <strong>无法</strong> 使用事务功能。</li>
<li><code>key</code> 作为 <strong>数据分区</strong> 的最小粒度，不能将一个 <strong>大的键值</strong> 对象如 <code>hash</code>、<code>list</code> 等映射到 <strong>不同的节点</strong>。</li>
<li>不支持 <strong>多数据库空间</strong>：<strong>单机</strong> 下的 Redis 可以支持 <code>16</code> 个数据库（<code>db0 ~ db15</code>），<strong>集群模式</strong> 下只能使用 <strong>一个</strong> 数据库空间，即 <code>db0</code>。</li>
<li><strong>复制结构</strong> 只支持一层：<strong>从节点</strong> 只能复制 <strong>主节点</strong>，不支持 <strong>嵌套树状复制</strong> 结构。</li>
</ul>
<h3 id="集群规模限制"><a href="#集群规模限制" class="headerlink" title="集群规模限制"></a>集群规模限制</h3><p>Redis Cluster 的优点是易于使用。分区、主从复制、弹性扩容这些功能都可以做到自动化，通过简单的部署就可以获得一个大容量、高可靠、高可用的 Redis 集群，并且对于应用来说，近乎于是透明的。</p>
<p>所以，<strong>Redis Cluster 非常适合构建中小规模 Redis 集群</strong>，这里的中小规模指的是，大概几个到几十个节点这样规模的 Redis 集群。</p>
<p>但是 Redis Cluster 不太适合构建超大规模集群，主要原因是，它采用了去中心化的设计。</p>
<p>Redis 的每个节点上，都保存了所有槽和节点的映射关系表，客户端可以访问任意一个节点，再通过重定向命令，找到数据所在的那个节点。那么，这个映射关系表是如何更新的呢？Redis Cluster 采用了一种去中心化的流言 (Gossip) 协议来传播集群配置的变化。</p>
<p>Gossip 协议的优点是去中心化；缺点是传播速度慢，并且是集群规模越大，传播的越慢。</p>
<h3 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h3><p>我们后面会部署一个 Redis Cluster 作为例子，在那之前，先介绍一下集群在 redis.conf 中的参数。</p>
<ul>
<li><strong>cluster-enabled</strong> <code>&lt;yes/no&gt;</code> - 如果配置”yes”则开启集群功能，此 redis 实例作为集群的一个节点，否则，它是一个普通的单一的 redis 实例。</li>
<li><strong>cluster-config-file</strong> <code>&lt;filename&gt;</code> - 注意：虽然此配置的名字叫“集群配置文件”，但是此配置文件不能人工编辑，它是集群节点自动维护的文件，主要用于记录集群中有哪些节点、他们的状态以及一些持久化参数等，方便在重启时恢复这些状态。通常是在收到请求之后这个文件就会被更新。</li>
<li><strong>cluster-node-timeout</strong> <code>&lt;milliseconds&gt;</code> - 这是集群中的节点能够失联的最大时间，超过这个时间，该节点就会被认为故障。如果主节点超过这个时间还是不可达，则用它的从节点将启动故障迁移，升级成主节点。注意，任何一个节点在这个时间之内如果还是没有连上大部分的主节点，则此节点将停止接收任何请求。</li>
<li><strong>cluster-slave-validity-factor</strong> <code>&lt;factor&gt;</code> - 如果设置成０，则无论从节点与主节点失联多久，从节点都会尝试升级成主节点。如果设置成正数，则 cluster-node-timeout 乘以 cluster-slave-validity-factor 得到的时间，是从节点与主节点失联后，此从节点数据有效的最长时间，超过这个时间，从节点不会启动故障迁移。假设 cluster-node-timeout&#x3D;5，cluster-slave-validity-factor&#x3D;10，则如果从节点跟主节点失联超过 50 秒，此从节点不能成为主节点。注意，如果此参数配置为非 0，将可能出现由于某主节点失联却没有从节点能顶上的情况，从而导致集群不能正常工作，在这种情况下，只有等到原来的主节点重新回归到集群，集群才恢复运作。</li>
<li><strong>cluster-migration-barrier</strong> <code>&lt;count&gt;</code> - 主节点需要的最小从节点数，只有达到这个数，主节点失败时，它从节点才会进行迁移。更详细介绍可以看本教程后面关于副本迁移到部分。</li>
<li><strong>cluster-require-full-coverage</strong> <code>&lt;yes/no&gt;</code> - 在部分 key 所在的节点不可用时，如果此参数设置为”yes”(默认值), 则整个集群停止接受操作；如果此参数设置为”no”，则集群依然为可达节点上的 key 提供读操作。</li>
</ul>
<h2 id="其他-Redis-集群方案"><a href="#其他-Redis-集群方案" class="headerlink" title="其他 Redis 集群方案"></a>其他 Redis 集群方案</h2><p>Redis Cluster 不太适合用于大规模集群，所以，如果要构建超大 Redis 集群，需要选择替代方案。一般有三种方案类型：</p>
<ul>
<li>客户端分区方案</li>
<li>代理分区方案</li>
<li>查询路由方案</li>
</ul>
<h3 id="客户端分区方案"><a href="#客户端分区方案" class="headerlink" title="客户端分区方案"></a>客户端分区方案</h3><p><strong>客户端</strong> 就已经决定数据会被 <strong>存储</strong> 到哪个 Redis 节点或者从哪个 Redis 节点 <strong>读取数据</strong>。其主要思想是采用 <strong>哈希算法</strong> 将 Redis 数据的 <code>key</code> 进行散列，通过 <code>hash</code> 函数，特定的 <code>key</code>会 <strong>映射</strong> 到特定的 Redis 节点上。</p>
<p><strong>客户端分区方案</strong> 的代表为 Redis Sharding，Redis Sharding 是 Redis Cluster 出来之前，业界普遍使用的 Redis <strong>多实例集群</strong> 方法。Java 的 Redis 客户端驱动库 <a target="_blank" rel="noopener" href="https://github.com/redis/jedis"><strong>Jedis</strong></a>，支持 Redis Sharding 功能，即 ShardedJedis 以及 <strong>结合缓存池</strong> 的 ShardedJedisPool。</p>
<ul>
<li><strong>优点</strong>：不使用 <strong>第三方中间件</strong>，<strong>分区逻辑</strong> 可控，<strong>配置</strong> 简单，节点之间无关联，容易 <strong>线性扩展</strong>，灵活性强。</li>
<li><strong>缺点</strong>：<strong>客户端</strong> 无法 <strong>动态增删</strong> 服务节点，客户端需要自行维护 <strong>分发逻辑</strong>，客户端之间 <strong>无连接共享</strong>，会造成 <strong>连接浪费</strong>。</li>
</ul>
<h3 id="代理分区方案"><a href="#代理分区方案" class="headerlink" title="代理分区方案"></a>代理分区方案</h3><p><strong>客户端</strong> 发送请求到一个 <strong>代理组件</strong>，<strong>代理</strong> 解析 <strong>客户端</strong> 的数据，并将请求转发至正确的节点，最后将结果回复给客户端。</p>
<ul>
<li><strong>优点</strong>：简化 <strong>客户端</strong> 的分布式逻辑，<strong>客户端</strong> 透明接入，切换成本低，代理的 <strong>转发</strong> 和 <strong>存储</strong> 分离。</li>
<li><strong>缺点</strong>：多了一层 <strong>代理层</strong>，加重了 <strong>架构部署复杂度</strong> 和 <strong>性能损耗</strong>。</li>
</ul>
<p><strong>代理分区</strong> 主流实现的有方案有 <strong><a target="_blank" rel="noopener" href="https://github.com/twitter/twemproxy">Twemproxy</a></strong> 和 <a target="_blank" rel="noopener" href="https://github.com/CodisLabs/codis"><strong>Codis</strong></a>。</p>
<h4 id="Twemproxy"><a href="#Twemproxy" class="headerlink" title="Twemproxy"></a>Twemproxy</h4><p><strong><a target="_blank" rel="noopener" href="https://github.com/twitter/twemproxy">Twemproxy</a></strong> 也叫 <code>nutcraker</code>，是 Twitter 开源的一个 Redis 和 Memcache 的 <strong>中间代理服务器</strong> 程序。</p>
<p><strong><a target="_blank" rel="noopener" href="https://github.com/twitter/twemproxy">Twemproxy</a></strong> 作为 <strong>代理</strong>，可接受来自多个程序的访问，按照 <strong>路由规则</strong>，转发给后台的各个 Redis 服务器，再原路返回。**<a target="_blank" rel="noopener" href="https://github.com/twitter/twemproxy">Twemproxy</a>** 存在 <strong>单点故障</strong> 问题，需要结合 Lvs 和 Keepalived 做 <strong>高可用方案</strong>。</p>
<ul>
<li><strong>优点</strong>：应用范围广，稳定性较高，中间代理层 <strong>高可用</strong>。</li>
<li><strong>缺点</strong>：无法平滑地 <strong>水平扩容&#x2F;缩容</strong>，无 <strong>可视化管理界面</strong>，运维不友好，出现故障，不能 <strong>自动转移</strong>。</li>
</ul>
<h4 id="Codis"><a href="#Codis" class="headerlink" title="Codis"></a>Codis</h4><p><a target="_blank" rel="noopener" href="https://github.com/CodisLabs/codis"><strong>Codis</strong></a> 是一个 <strong>分布式</strong> Redis 解决方案，对于上层应用来说，连接 Codis-Proxy 和直接连接 <strong>原生的</strong> Redis-Server 没有的区别。<a target="_blank" rel="noopener" href="https://github.com/CodisLabs/codis"><strong>Codis</strong></a> 底层会 <strong>处理请求的转发</strong>，不停机的进行 <strong>数据迁移</strong> 等工作。<a target="_blank" rel="noopener" href="https://github.com/CodisLabs/codis"><strong>Codis</strong></a> 采用了无状态的 <strong>代理层</strong>，对于 <strong>客户端</strong> 来说，一切都是透明的。</p>
<ul>
<li><strong>优点</strong>：实现了上层 Proxy 和底层 Redis 的 <strong>高可用</strong>，<strong>数据分区</strong> 和 <strong>自动平衡</strong>，提供 <strong>命令行接口</strong> 和 RESTful API，提供 <strong>监控</strong> 和 <strong>管理</strong> 界面，可以动态 <strong>添加</strong> 和 <strong>删除</strong> Redis 节点。</li>
<li><strong>缺点</strong>：<strong>部署架构</strong> 和 <strong>配置</strong> 复杂，不支持 <strong>跨机房</strong> 和 <strong>多租户</strong>，不支持 <strong>鉴权管理</strong>。</li>
</ul>
<h3 id="查询路由方案"><a href="#查询路由方案" class="headerlink" title="查询路由方案"></a>查询路由方案</h3><p><strong>客户端随机地</strong> 请求任意一个 Redis 实例，然后由 Redis 将请求 <strong>转发</strong> 给 <strong>正确</strong> 的 Redis 节点。Redis Cluster 实现了一种 <strong>混合形式</strong> 的 <strong>查询路由</strong>，但并不是 <strong>直接</strong> 将请求从一个 Redis 节点 <strong>转发</strong> 到另一个 Redis 节点，而是在 <strong>客户端</strong> 的帮助下直接 <strong>重定向</strong>（ <code>redirected</code>）到正确的 Redis 节点。</p>
<ul>
<li><strong>优点</strong>：<strong>去中心化</strong>，数据按照 <strong>槽</strong> 存储分布在多个 Redis 实例上，可以平滑的进行节点 <strong>扩容&#x2F;缩容</strong>，支持 <strong>高可用</strong> 和 <strong>自动故障转移</strong>，运维成本低。</li>
<li><strong>缺点</strong>：重度依赖 Redis-trib 工具，缺乏 <strong>监控管理</strong>，需要依赖 Smart Client (<strong>维护连接</strong>，<strong>缓存路由表</strong>，<code>MultiOp</code> 和 <code>Pipeline</code> 支持)。Failover 节点的 <strong>检测过慢</strong>，不如有 <strong>中心节点</strong> 的集群及时（如 ZooKeeper）。Gossip 消息采用广播方式，集群规模越大，开销越大。无法根据统计区分 <strong>冷热数据</strong>。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.im/post/5b8fc5536fb9a05d2d01fb11">深入剖析 Redis 系列(三) - Redis 集群模式搭建与原理详解</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/537098/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/537098/" class="post-title-link" itemprop="url">Redis 运维</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>18k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-运维"><a href="#Redis-运维" class="headerlink" title="Redis 运维"></a>Redis 运维</h1><blockquote>
<p><strong>Redis</strong> 是一个高性能的 key-value 数据库。</p>
<p>SET 操作每秒钟 110000 次；GET 操作每秒钟 81000 次。</p>
</blockquote>
<h2 id="Redis-安装"><a href="#Redis-安装" class="headerlink" title="Redis 安装"></a>Redis 安装</h2><h3 id="Window-下安装"><a href="#Window-下安装" class="headerlink" title="Window 下安装"></a>Window 下安装</h3><p><strong>下载地址：</strong><a target="_blank" rel="noopener" href="https://github.com/MSOpenTech/redis/releases">https://github.com/MSOpenTech/redis/releases</a>。</p>
<p>Redis 支持 32 位和 64 位。这个需要根据你系统平台的实际情况选择，这里我们下载 <strong>Redis-x64-xxx.zip</strong>压缩包到 C 盘，解压后，将文件夹重新命名为 <strong>redis</strong>。</p>
<p>打开一个 <strong>cmd</strong> 窗口 使用 cd 命令切换目录到 <strong>C:\redis</strong> 运行 <strong>redis-server.exe redis.windows.conf</strong> 。</p>
<p>如果想方便的话，可以把 redis 的路径加到系统的环境变量里，这样就省得再输路径了，后面的那个 redis.windows.conf 可以省略，如果省略，会启用默认的。</p>
<p>这时候另启一个 cmd 窗口，原来的不要关闭，不然就无法访问服务端了。</p>
<p>切换到 redis 目录下运行 <strong>redis-cli.exe -h 127.0.0.1 -p 6379</strong> 。</p>
<h3 id="Linux-下安装"><a href="#Linux-下安装" class="headerlink" title="Linux 下安装"></a>Linux 下安装</h3><p><strong>下载地址：</strong> <a target="_blank" rel="noopener" href="http://redis.io/download%EF%BC%8C%E4%B8%8B%E8%BD%BD%E6%9C%80%E6%96%B0%E6%96%87%E6%A1%A3%E7%89%88%E6%9C%AC%E3%80%82">http://redis.io/download，下载最新文档版本。</a></p>
<p>下载、解压、编译 Redis</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-5.0.4.tar.gz</span><br><span class="line">tar xzf redis-5.0.4.tar.gz</span><br><span class="line">cd redis-5.0.4</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>为了编译 Redis 源码，你需要 gcc-c++和 tcl。如果你的系统是 CentOS，可以直接执行命令：<code>yum install -y gcc-c++ tcl</code> 来安装。</p>
<p>进入到解压后的 <code>src</code> 目录，通过如下命令启动 Redis:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">src/redis-server</span><br></pre></td></tr></table></figure>

<p>您可以使用内置的客户端与 Redis 进行交互:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">src/redis-cli</span></span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash"><span class="built_in">set</span> foo bar</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash">get foo</span></span><br><span class="line">&quot;bar&quot;</span><br></pre></td></tr></table></figure>

<h3 id="Ubuntu-下安装"><a href="#Ubuntu-下安装" class="headerlink" title="Ubuntu 下安装"></a>Ubuntu 下安装</h3><p>在 Ubuntu 系统安装 Redis 可以使用以下命令:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install redis-server</span><br></pre></td></tr></table></figure>

<h3 id="开机启动"><a href="#开机启动" class="headerlink" title="开机启动"></a>开机启动</h3><ul>
<li>开机启动配置：<code>echo &quot;/usr/local/bin/redis-server /etc/redis.conf&quot; &gt;&gt; /etc/rc.local</code></li>
</ul>
<h3 id="开放防火墙端口"><a href="#开放防火墙端口" class="headerlink" title="开放防火墙端口"></a>开放防火墙端口</h3><ul>
<li>添加规则：<code>iptables -I INPUT -p tcp -m tcp --dport 6379 -j ACCEPT</code></li>
<li>保存规则：<code>service iptables save</code></li>
<li>重启 iptables：<code>service iptables restart</code></li>
</ul>
<h3 id="Redis-安装脚本"><a href="#Redis-安装脚本" class="headerlink" title="Redis 安装脚本"></a>Redis 安装脚本</h3><blockquote>
<p>CentOS7 环境安装脚本：<a target="_blank" rel="noopener" href="https://github.com/dunwu/linux-tutorial/tree/master/codes/linux/soft">软件运维配置脚本集合</a></p>
</blockquote>
<p><strong>安装说明</strong></p>
<ul>
<li>采用编译方式安装 Redis, 并将其注册为 systemd 服务</li>
<li>安装路径为：<code>/usr/local/redis</code></li>
<li>默认下载安装 <code>5.0.4</code> 版本，端口号为：<code>6379</code>，密码为空</li>
</ul>
<p><strong>使用方法</strong></p>
<ul>
<li>默认安装 - 执行以下任意命令即可：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -o- https://gitee.com/turnon/linux-tutorial/raw/master/codes/linux/soft/redis-install.sh | bash</span><br><span class="line">wget -qO- https://gitee.com/turnon/linux-tutorial/raw/master/codes/linux/soft/redis-install.sh | bash</span><br></pre></td></tr></table></figure>

<ul>
<li>自定义安装 - 下载脚本到本地，并按照以下格式执行：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh redis-install.sh [version] [port] [password]</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>version</code> - redis 版本号</li>
<li><code>port</code> - redis 服务端口号</li>
<li><code>password</code> - 访问密码</li>
</ul>
<h2 id="Redis-单机使用和配置"><a href="#Redis-单机使用和配置" class="headerlink" title="Redis 单机使用和配置"></a>Redis 单机使用和配置</h2><h3 id="启动-Redis"><a href="#启动-Redis" class="headerlink" title="启动 Redis"></a>启动 Redis</h3><p><strong>启动 redis 服务</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/redis/src</span><br><span class="line">./redis-server</span><br></pre></td></tr></table></figure>

<p><strong>启动 redis 客户端</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/redis/src</span><br><span class="line">./redis-cli</span><br></pre></td></tr></table></figure>

<p><strong>查看 redis 是否启动</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br></pre></td></tr></table></figure>

<p>以上命令将打开以下终端：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis 127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>127.0.0.1 是本机 IP ，6379 是 redis 服务端口。现在我们输入 PING 命令。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis 127.0.0.1:6379&gt; ping</span><br><span class="line">PONG</span><br></pre></td></tr></table></figure>

<p>以上说明我们已经成功启动了 redis。</p>
<h3 id="Redis-常见配置"><a href="#Redis-常见配置" class="headerlink" title="Redis 常见配置"></a>Redis 常见配置</h3><blockquote>
<p>Redis 默认的配置文件是根目录下的 <code>redis.conf</code> 文件。</p>
<p>如果需要指定特定文件作为配置文件，需要使用命令： <code>./redis-server -c xxx.conf</code></p>
<p>每次修改配置后，需要重启才能生效。</p>
<p>Redis 官方默认配置：</p>
<ul>
<li>自描述文档 <a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/antirez/redis/2.8/redis.conf">redis.conf for Redis 2.8</a></li>
<li>自描述文档 <a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/antirez/redis/2.6/redis.conf">redis.conf for Redis 2.6</a>.</li>
<li>自描述文档 <a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/antirez/redis/2.4/redis.conf">redis.conf for Redis 2.4</a>.</li>
</ul>
<p>自 Redis2.6 起就可以直接通过命令行传递 Redis 配置参数。这种方法可以用于测试。自 Redis2.6 起就可以直接通过命令行传递 Redis 配置参数。这种方法可以用于测试。</p>
</blockquote>
<h3 id="设为守护进程"><a href="#设为守护进程" class="headerlink" title="设为守护进程"></a>设为守护进程</h3><p>Redis 默认以非守护进程方式启动，而通常我们会将 Redis 设为守护进程启动方式，配置：<code>daemonize yes</code></p>
<h4 id="远程访问"><a href="#远程访问" class="headerlink" title="远程访问"></a>远程访问</h4><p>Redis 默认绑定 127.0.0.1，这样就只能本机才能访问，若要 Redis 允许远程访问，需要配置：<code>bind 0.0.0.0</code></p>
<h4 id="设置密码"><a href="#设置密码" class="headerlink" title="设置密码"></a>设置密码</h4><p>Redis 默认访问不需要密码，如果需要设置密码，需要如下配置：</p>
<ul>
<li><code>protected-mode yes</code></li>
<li><code>requirepass &lt;密码&gt;</code></li>
</ul>
<h4 id="配置参数表"><a href="#配置参数表" class="headerlink" title="配置参数表"></a>配置参数表</h4><table>
<thead>
<tr>
<th align="left">配置项</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>daemonize no</code></td>
<td align="left">Redis 默认不是以守护进程的方式运行，可以通过该配置项修改，使用 yes 启用守护进程（Windows 不支持守护线程的配置为 no ）</td>
</tr>
<tr>
<td align="left"><code>pidfile /var/run/redis.pid</code></td>
<td align="left">当 Redis 以守护进程方式运行时，Redis 默认会把 pid 写入 &#x2F;var&#x2F;run&#x2F;redis.pid 文件，可以通过 pidfile 指定</td>
</tr>
<tr>
<td align="left"><code>port 6379</code></td>
<td align="left">指定 Redis 监听端口，默认端口为 6379，作者在自己的一篇博文中解释了为什么选用 6379 作为默认端口，因为 6379 在手机按键上 MERZ 对应的号码，而 MERZ 取自意大利歌女 Alessia Merz 的名字</td>
</tr>
<tr>
<td align="left"><code>bind 127.0.0.1</code></td>
<td align="left">绑定的主机地址</td>
</tr>
<tr>
<td align="left"><code>timeout 300</code></td>
<td align="left">当客户端闲置多长时间后关闭连接，如果指定为 0，表示关闭该功能</td>
</tr>
<tr>
<td align="left"><code>loglevel notice</code></td>
<td align="left">指定日志记录级别，Redis 总共支持四个级别：debug、verbose、notice、warning，默认为 notice</td>
</tr>
<tr>
<td align="left"><code>logfile stdout</code></td>
<td align="left">日志记录方式，默认为标准输出，如果配置 Redis 为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给 &#x2F;dev&#x2F;null</td>
</tr>
<tr>
<td align="left"><code>databases 16</code></td>
<td align="left">设置数据库的数量，默认数据库为 0，可以使用 SELECT 命令在连接上指定数据库 id</td>
</tr>
<tr>
<td align="left"><code>save &lt;seconds&gt; &lt;changes&gt;</code> Redis 默认配置文件中提供了三个条件：<strong>save 900 1</strong>、<strong>save 300 10</strong>、<strong>save 60 10000</strong> 分别表示 900 秒（15 分钟）内有 1 个更改，300 秒（5 分钟）内有 10 个更改以及 60 秒内有 10000 个更改。</td>
<td align="left">指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合</td>
</tr>
<tr>
<td align="left"><code>rdbcompression yes</code></td>
<td align="left">指定存储至本地数据库时是否压缩数据，默认为 yes，Redis 采用 LZF 压缩，如果为了节省 CPU 时间，可以关闭该选项，但会导致数据库文件变的巨大</td>
</tr>
<tr>
<td align="left"><code>dbfilename dump.rdb</code></td>
<td align="left">指定本地数据库文件名，默认值为 dump.rdb</td>
</tr>
<tr>
<td align="left"><code>dir ./</code></td>
<td align="left">指定本地数据库存放目录</td>
</tr>
<tr>
<td align="left"><code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></td>
<td align="left">设置当本机为 slav 服务时，设置 master 服务的 IP 地址及端口，在 Redis 启动时，它会自动从 master 进行数据同步</td>
</tr>
<tr>
<td align="left"><code>masterauth &lt;master-password&gt;</code></td>
<td align="left">当 master 服务设置了密码保护时，slav 服务连接 master 的密码</td>
</tr>
<tr>
<td align="left"><code>requirepass foobared</code></td>
<td align="left">设置 Redis 连接密码，如果配置了连接密码，客户端在连接 Redis 时需要通过 <code>AUTH &lt;password&gt;</code> 命令提供密码，默认关闭</td>
</tr>
<tr>
<td align="left"><code>maxclients 128</code></td>
<td align="left">设置同一时间最大客户端连接数，默认无限制，Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息</td>
</tr>
<tr>
<td align="left"><code>maxmemory &lt;bytes&gt;</code></td>
<td align="left">指定 Redis 最大内存限制，Redis 在启动时会把数据加载到内存中，达到最大内存后，Redis 会先尝试清除已到期或即将到期的 Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis 新的 vm 机制，会把 Key 存放内存，Value 会存放在 swap 区</td>
</tr>
<tr>
<td align="left"><code>appendonly no</code></td>
<td align="left">指定是否在每次更新操作后进行日志记录，Redis 在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis 本身同步数据文件是按上面 save 条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为 no</td>
</tr>
<tr>
<td align="left"><code>appendfilename appendonly.aof</code></td>
<td align="left">指定更新日志文件名，默认为 appendonly.aof</td>
</tr>
<tr>
<td align="left"><code>appendfsync everysec</code></td>
<td align="left">指定更新日志条件，共有 3 个可选值：<strong>no</strong>：表示等操作系统进行数据缓存同步到磁盘（快）<strong>always</strong>：表示每次更新操作后手动调用 fsync() 将数据写到磁盘（慢，安全）<strong>everysec</strong>：表示每秒同步一次（折中，默认值）</td>
</tr>
<tr>
<td align="left"><code>vm-enabled no</code></td>
<td align="left">指定是否启用虚拟内存机制，默认值为 no，简单的介绍一下，VM 机制将数据分页存放，由 Redis 将访问量较少的页即冷数据 swap 到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析 Redis 的 VM 机制）</td>
</tr>
<tr>
<td align="left"><code>vm-swap-file /tmp/redis.swap</code></td>
<td align="left">虚拟内存文件路径，默认值为 &#x2F;tmp&#x2F;redis.swap，不可多个 Redis 实例共享</td>
</tr>
<tr>
<td align="left"><code>vm-max-memory 0</code></td>
<td align="left">将所有大于 vm-max-memory 的数据存入虚拟内存，无论 vm-max-memory 设置多小，所有索引数据都是内存存储的(Redis 的索引数据 就是 keys)，也就是说，当 vm-max-memory 设置为 0 的时候，其实是所有 value 都存在于磁盘。默认值为 0</td>
</tr>
<tr>
<td align="left"><code>vm-page-size 32</code></td>
<td align="left">Redis swap 文件分成了很多的 page，一个对象可以保存在多个 page 上面，但一个 page 上不能被多个对象共享，vm-page-size 是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page 大小最好设置为 32 或者 64bytes；如果存储很大大对象，则可以使用更大的 page，如果不确定，就使用默认值</td>
</tr>
<tr>
<td align="left"><code>vm-pages 134217728</code></td>
<td align="left">设置 swap 文件中的 page 数量，由于页表（一种表示页面空闲或使用的 bitmap）是在放在内存中的，，在磁盘上每 8 个 pages 将消耗 1byte 的内存。</td>
</tr>
<tr>
<td align="left"><code>vm-max-threads 4</code></td>
<td align="left">设置访问 swap 文件的线程数,最好不要超过机器的核数,如果设置为 0,那么所有对 swap 文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为 4</td>
</tr>
<tr>
<td align="left"><code>glueoutputbuf yes</code></td>
<td align="left">设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启</td>
</tr>
<tr>
<td align="left"><code>hash-max-zipmap-entries 64 hash-max-zipmap-value 512</code></td>
<td align="left">指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法</td>
</tr>
<tr>
<td align="left"><code>activerehashing yes</code></td>
<td align="left">指定是否激活重置哈希，默认为开启（后面在介绍 Redis 的哈希算法时具体介绍）</td>
</tr>
<tr>
<td align="left"><code>include /path/to/local.conf</code></td>
<td align="left">指定包含其它的配置文件，可以在同一主机上多个 Redis 实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件</td>
</tr>
</tbody></table>
<h3 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h3><blockquote>
<p>参考官方文档：<a target="_blank" rel="noopener" href="https://redis.io/topics/benchmarks">How fast is Redis?</a></p>
</blockquote>
<p>Redis 自带了一个性能测试工具：<code>redis-benchmark</code></p>
<p><strong>（1）基本测试</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-benchmark -q -n 100000</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-q</code> 表示静默（quiet）执行</li>
<li><code>-n 100000</code> 请求 10 万次</li>
</ul>
<p><strong>（2）测试指定读写指令</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">redis-benchmark -t <span class="built_in">set</span>,lpush -n 100000 -q</span></span><br><span class="line">SET: 74239.05 requests per second</span><br><span class="line">LPUSH: 79239.30 requests per second</span><br></pre></td></tr></table></figure>

<p><strong>（3）测试 pipeline 模式下指定读写指令</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-benchmark -n 1000000 -t set,get -P 16 -q</span><br><span class="line">SET: 403063.28 requests per second</span><br><span class="line">GET: 508388.41 requests per second</span><br></pre></td></tr></table></figure>

<h2 id="Redis-集群使用和配置"><a href="#Redis-集群使用和配置" class="headerlink" title="Redis 集群使用和配置"></a>Redis 集群使用和配置</h2><p>Redis 3.0 后支持集群模式。</p>
<h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><p><code>Redis</code> 集群一般由 <strong>多个节点</strong> 组成，节点数量至少为 <code>6</code> 个，才能保证组成 <strong>完整高可用</strong> 的集群。</p>
<p><img src="https://user-gold-cdn.xitu.io/2019/10/10/16db5250b0d1c392?w=1467&h=803&f=png&s=43428" alt="img"></p>
<p>理想情况当然是所有节点各自在不同的机器上，首先于资源，本人在部署 Redis 集群时，只得到 3 台服务器。所以，我计划每台服务器部署 2 个 Redis 节点。</p>
<p>【示例】最简高可用 Redis 集群规划</p>
<p>机器配置：16G 内存 + 8 核 CPU + 1T 磁盘</p>
<p>Redis 进程分配 10 G 内存。一般线上生产环境，Redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p>
<p>集群拓扑：三主三从；三哨兵，每个哨兵监听所有主节点。</p>
<p>估算性能：</p>
<ul>
<li>容量：三主，占用 30 G 内存，所以最大存储容量为 30 G。假设每条数据记录平均 大小为 10 K，则最大能存储 300 万条数据。</li>
<li>吞吐量：单机一般 TPS&#x2F;QPS 为 五万到八万左右。假设为五万，那么三主三从架构理论上能达到 TPS 15 万，QPS 30 万。</li>
</ul>
<h3 id="部署集群"><a href="#部署集群" class="headerlink" title="部署集群"></a>部署集群</h3><blockquote>
<p>Redis 集群节点的安装与单节点服务相同，差异仅在于部署方式。</p>
<p>注意：为了演示方便，本示例将所有 Redis 集群节点都部署在一台机器上，实际生产环境中，基本都会将节点部署在不同机器上。要求更高的，可能还要考虑多机房部署。</p>
</blockquote>
<p>（1）创建节点目录</p>
<p>我个人偏好将软件放在 <code>/opt</code> 目录下，在我的机器中，Redis 都安装在 <code>/usr/local/redis</code> 目录下。所以，下面的命令和配置都假设 Redis 安装目录为 <code>/usr/local/redis</code> 。</p>
<p>确保机器上已经安装了 Redis 后，执行以下命令，创建 Redis 集群节点实例目录：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /usr/local/redis/conf/7001</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/7002</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/7003</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/7004</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/7005</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/7006</span><br></pre></td></tr></table></figure>

<p>（2）配置集群节点</p>
<p>每个实例目录下，新建 <code>redis.conf</code> 配置文件。</p>
<p>实例配置模板以 7001 节点为例（其他节点，完全替换配置中的端口号 7001 即可），如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">端口号</span></span><br><span class="line">port 7001</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">绑定的主机端口（0.0.0.0 表示允许远程访问）</span></span><br><span class="line">bind 0.0.0.0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以守护进程方式启动</span></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开启集群模式</span></span><br><span class="line">cluster-enabled yes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">集群的配置，配置文件首次启动自动生成</span></span><br><span class="line">cluster-config-file /usr/local/redis/conf/7001/7001.conf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">请求超时时间，设置 10 秒</span></span><br><span class="line">cluster-node-timeout 10000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开启 AOF 持久化</span></span><br><span class="line">appendonly yes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">数据存放目录</span></span><br><span class="line">dir /usr/local/redis/conf/7001</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进程文件</span></span><br><span class="line">pidfile /usr/local/redis/conf/7001/7001.pid</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">日志文件</span></span><br><span class="line">logfile /usr/local/redis/conf/7001/7001.log</span><br></pre></td></tr></table></figure>

<p>（3）批量启动 Redis 节点</p>
<p>Redis 的 utils&#x2F;create-cluster 目录下自带了一个名为 create-cluster 的脚本工具，可以利用它来新建、启动、停止、重启 Redis 节点。</p>
<p>脚本中有几个关键参数：</p>
<ul>
<li><code>PORT</code>&#x3D;30000 - 初始端口号</li>
<li><code>TIMEOUT</code>&#x3D;2000 - 超时时间</li>
<li><code>NODES</code>&#x3D;6 - 节点数</li>
<li><code>REPLICAS</code>&#x3D;1 - 备份数</li>
</ul>
<p>脚本中的每个命令项会根据初始端口号，以及设置的节点数，遍历的去执行操作。</p>
<p>由于前面的规划中，节点端口是从 7001 ~ 7006，所以需要将 PORT 变量设为 7000。</p>
<p>脚本中启动每个 Redis 节点是通过指定命令行参数来配置属性。所以，我们需要改一下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PORT=7000</span><br><span class="line">TIMEOUT=2000</span><br><span class="line">NODES=6</span><br><span class="line">ENDPORT=$((PORT+NODES))</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">...</span></span><br><span class="line"></span><br><span class="line">if [ &quot;$1&quot; == &quot;start&quot; ]</span><br><span class="line">then</span><br><span class="line">    while [ $((PORT &lt; ENDPORT)) != &quot;0&quot; ]; do</span><br><span class="line">        PORT=$((PORT+1))</span><br><span class="line">        echo &quot;Starting $PORT&quot;</span><br><span class="line">        /usr/local/redis/src/redis-server /usr/local/redis/conf/$&#123;PORT&#125;/redis.conf</span><br><span class="line">    done</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>好了，在每台服务器上，都执行 <code>./create-cluster start</code> 来启动节点。</p>
<p>然后，通过 ps 命令来确认 Redis 进程是否已经工作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">root @ dbClusterDev01 <span class="keyword">in</span> /usr/local/redis/conf [11:07:55]</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -ef | grep redis</span></span><br><span class="line">root      4604     1  0 11:07 ?        00:00:00 /opt/redis/src/redis-server 0.0.0.0:7001 [cluster]</span><br><span class="line">root      4609     1  0 11:07 ?        00:00:00 /opt/redis/src/redis-server 0.0.0.0:7002 [cluster]</span><br><span class="line">root      4614     1  0 11:07 ?        00:00:00 /opt/redis/src/redis-server 0.0.0.0:7003 [cluster]</span><br><span class="line">root      4619     1  0 11:07 ?        00:00:00 /opt/redis/src/redis-server 0.0.0.0:7004 [cluster]</span><br><span class="line">root      4624     1  0 11:07 ?        00:00:00 /opt/redis/src/redis-server 0.0.0.0:7005 [cluster]</span><br><span class="line">root      4629     1  0 11:07 ?        00:00:00 /opt/redis/src/redis-server 0.0.0.0:7006 [cluster]</span><br></pre></td></tr></table></figure>

<p>（4）启动集群</p>
<p>通过 <code>redis-cli --cluster create</code> 命令可以自动配置集群，如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-cli --cluster create 127.0.0.1:7001 127.0.0.1:7002 127.0.0.2:7003 127.0.0.2:7004 127.0.0.3:7005 127.0.0.3:7006 --cluster-replicas 1</span><br></pre></td></tr></table></figure>

<p>redis-cluster 会根据设置的节点数和副本数自动分片（分配 Hash 虚拟槽 slot），如果满意，输入 yes ，直接开始分片。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 127.0.0.2:7004 to 127.0.0.1:7001</span><br><span class="line">Adding replica 127.0.0.3:7006 to 127.0.0.2:7003</span><br><span class="line">Adding replica 127.0.0.1:7002 to 127.0.0.3:7005</span><br><span class="line">M: b721235997deb6b9a7a2be690b5b9663db8057c6 127.0.0.1:7001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">S: bda9b7036df0bbefe601bda4ce45d3787a2e9bd9 127.0.0.1:7002</span><br><span class="line">   replicates 3623fff69b5243ed18c02a2fbb6f53069b0f1505</span><br><span class="line">M: 91523c0391a044da6cc9f53bb965aabe89502187 127.0.0.2:7003</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">S: 9d899cbe49dead7b8c4f769920cdb75714a441ae 127.0.0.2:7004</span><br><span class="line">   replicates b721235997deb6b9a7a2be690b5b9663db8057c6</span><br><span class="line">M: 3623fff69b5243ed18c02a2fbb6f53069b0f1505 127.0.0.3:7005</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: a2869dc153ea4977ca790b76483574a5d56cb40e 127.0.0.3:7006</span><br><span class="line">   replicates 91523c0391a044da6cc9f53bb965aabe89502187</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Sending CLUSTER MEET messages to <span class="built_in">join</span> the cluster</span></span><br><span class="line">Waiting for the cluster to join</span><br><span class="line">....</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7001)</span></span><br><span class="line">M: b721235997deb6b9a7a2be690b5b9663db8057c6 127.0.0.1:7001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: a2869dc153ea4977ca790b76483574a5d56cb40e 127.0.0.1:7006</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 91523c0391a044da6cc9f53bb965aabe89502187</span><br><span class="line">M: 91523c0391a044da6cc9f53bb965aabe89502187 127.0.0.1:7003</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 3623fff69b5243ed18c02a2fbb6f53069b0f1505 127.0.0.1:7005</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 9d899cbe49dead7b8c4f769920cdb75714a441ae 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates b721235997deb6b9a7a2be690b5b9663db8057c6</span><br><span class="line">S: bda9b7036df0bbefe601bda4ce45d3787a2e9bd9 127.0.0.1:7002</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 3623fff69b5243ed18c02a2fbb6f53069b0f1505</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure>

<p>（5）日常维护操作</p>
<ul>
<li>关闭集群 - <code>./create-cluster stop</code></li>
<li>检查集群是否健康（指定任意节点即可）：<code>./redis-cli --cluster check &lt;ip:port&gt;</code></li>
<li>尝试修复集群节点：<code>./redis-cli --cluster fix &lt;ip:port&gt;</code></li>
</ul>
<h3 id="部署哨兵"><a href="#部署哨兵" class="headerlink" title="部署哨兵"></a>部署哨兵</h3><p>redis-cluster 实现了 Redis 的分片、复制。</p>
<p>但 redis-cluster 没有解决故障转移问题，一旦任意分片的 Master 节点宕机、网络不通，就会导致 redis-cluster 的集群不能工作。为了解决高可用的问题，Redis 提供了 Redis 哨兵来监控 Redis 节点状态，并且会在 Master 宕机时，发起选举，将这个 Master 的一个 Slave 节点选举为 Master。</p>
<p>（1）创建节点目录</p>
<p>我个人偏好将软件放在 <code>/opt</code> 目录下，在我的机器中，Redis 都安装在 <code>/usr/local/redis</code> 目录下。所以，下面的命令和配置都假设 Redis 安装目录为 <code>/usr/local/redis</code> 。</p>
<p>确保机器上已经安装了 Redis 后，执行以下命令，创建 Redis 集群节点实例目录：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /usr/local/redis/conf/27001</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/27002</span><br><span class="line">sudo mkdir -p /usr/local/redis/conf/27003</span><br></pre></td></tr></table></figure>

<p>（2）配置集群节点</p>
<p>每个实例目录下，新建 <code>redis.conf</code> 配置文件。</p>
<p>实例配置模板以 7001 节点为例（其他节点，完全替换配置中的端口号 7001 即可），如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">port 27001</span><br><span class="line">daemonize yes</span><br><span class="line">sentinel monitor redis-master 172.22.6.3 7001 2</span><br><span class="line">sentinel down-after-milliseconds redis-master 5000</span><br><span class="line">sentinel failover-timeout redis-master 900000</span><br><span class="line">sentinel parallel-syncs redis-master 1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">sentinel auth-pass redis-master 123456</span></span><br><span class="line">logfile /usr/local/redis/conf/27001/27001.log</span><br></pre></td></tr></table></figure>

<p>（3）批量启动哨兵节点</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/opt/</span>redis<span class="regexp">/src/</span>redis-sentinel <span class="regexp">/usr/</span>local<span class="regexp">/redis/</span>conf<span class="regexp">/27001/</span>sentinel.conf</span><br><span class="line"><span class="regexp">/opt/</span>redis<span class="regexp">/src/</span>redis-sentinel <span class="regexp">/usr/</span>local<span class="regexp">/redis/</span>conf<span class="regexp">/27002/</span>sentinel.conf</span><br><span class="line"><span class="regexp">/opt/</span>redis<span class="regexp">/src/</span>redis-sentinel <span class="regexp">/usr/</span>local<span class="regexp">/redis/</span>conf<span class="regexp">/27003/</span>sentinel.conf</span><br></pre></td></tr></table></figure>

<h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>（1）查看信息</p>
<p>进入任意节点</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-<span class="keyword">cli</span> -h <span class="number">172.22</span><span class="number">.6</span><span class="number">.3</span> -p <span class="number">7001</span></span><br></pre></td></tr></table></figure>

<p>cluster info 查看集群节点状态</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">172</span>.<span class="number">22</span>.<span class="number">6</span>.<span class="number">3</span>:<span class="number">7001</span>&gt; cluster nodes</span><br><span class="line"><span class="attribute">f158bf70bb2767cac271ce4efcfc14ba0b7ca98b</span> <span class="number">172.22.6.3:7006</span>@<span class="number">17006</span> slave e7aa182e756b76ec85b471797db9b66e4b2da725 <span class="number">0</span> <span class="number">1594528179000</span> <span class="number">6</span> connected</span><br><span class="line"><span class="attribute">f348e67648460c7a800120d69b4977bf2e4524cb</span> <span class="number">172.22.6.3:7001</span>@<span class="number">17001</span> myself,master - <span class="number">0</span> <span class="number">1594528179000</span> <span class="number">1</span> connected <span class="number">0</span>-<span class="number">5460</span></span><br><span class="line"><span class="attribute">52601e2d4af0e64b83f4cc6d20e8316d0ac38b99</span> <span class="number">172.22.6.3:7004</span>@<span class="number">17004</span> slave <span class="number">4802</span>fafe897160c46392c6e569d6f5e466cca696 <span class="number">0</span> <span class="number">1594528178000</span> <span class="number">4</span> connected</span><br><span class="line"><span class="attribute">c6c6a68674ae8aac3c6ec792c8af4dc1228c6c31</span> <span class="number">172.22.6.3:7005</span>@<span class="number">17005</span> slave f348e67648460c7a800120d69b4977bf2e4524cb <span class="number">0</span> <span class="number">1594528179852</span> <span class="number">5</span> connected</span><br><span class="line"><span class="attribute">e7aa182e756b76ec85b471797db9b66e4b2da725</span> <span class="number">172.22.6.3:7002</span>@<span class="number">17002</span> master - <span class="number">0</span> <span class="number">1594528178000</span> <span class="number">2</span> connected <span class="number">5461</span>-<span class="number">10922</span></span><br><span class="line"><span class="attribute">4802fafe897160c46392c6e569d6f5e466cca696</span> <span class="number">172.22.6.3:7003</span>@<span class="number">17003</span> master - <span class="number">0</span> <span class="number">1594528178000</span> <span class="number">3</span> connected <span class="number">10923</span>-<span class="number">16383</span></span><br></pre></td></tr></table></figure>

<p>cluster info 查看集群信息</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">172</span>.<span class="number">22</span>.<span class="number">6</span>.<span class="number">3</span>:<span class="number">7001</span>&gt; cluster info</span><br><span class="line"><span class="attribute">cluster_state</span>:ok</span><br><span class="line"><span class="attribute">cluster_slots_assigned</span>:<span class="number">16384</span></span><br><span class="line"><span class="attribute">cluster_slots_ok</span>:<span class="number">16384</span></span><br><span class="line"><span class="attribute">cluster_slots_pfail</span>:<span class="number">0</span></span><br><span class="line"><span class="attribute">cluster_slots_fail</span>:<span class="number">0</span></span><br><span class="line"><span class="attribute">cluster_known_nodes</span>:<span class="number">6</span></span><br><span class="line"><span class="attribute">cluster_size</span>:<span class="number">3</span></span><br><span class="line"><span class="attribute">cluster_current_epoch</span>:<span class="number">6</span></span><br><span class="line"><span class="attribute">cluster_my_epoch</span>:<span class="number">1</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_ping_sent</span>:<span class="number">3406</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_pong_sent</span>:<span class="number">3569</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_publish_sent</span>:<span class="number">5035</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_sent</span>:<span class="number">12010</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_ping_received</span>:<span class="number">3564</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_pong_received</span>:<span class="number">3406</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_meet_received</span>:<span class="number">5</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_publish_received</span>:<span class="number">5033</span></span><br><span class="line"><span class="attribute">cluster_stats_messages_received</span>:<span class="number">12008</span></span><br></pre></td></tr></table></figure>

<p>（2）添加节点到集群</p>
<p>将已启动的节点实例添加到集群中</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster<span class="built_in"> add-node </span>127.0.0.1:7007 127.0.0.1:7008</span><br></pre></td></tr></table></figure>

<p><strong>添加主节点</strong></p>
<p>添加一组主节点</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">.</span>/redis-cli --cluster<span class="built_in"> add-node </span>172.22.6.3:7007 172.22.6.3:7001</span><br><span class="line"><span class="keyword">.</span>/redis-cli --cluster<span class="built_in"> add-node </span>172.22.6.3:7008 172.22.6.3:7001</span><br><span class="line"><span class="keyword">.</span>/redis-cli --cluster<span class="built_in"> add-node </span>172.22.6.3:7009 172.22.6.3:7001</span><br></pre></td></tr></table></figure>

<p>查看节点状态</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">172</span>.<span class="number">22</span>.<span class="number">6</span>.<span class="number">3</span>:<span class="number">7001</span>&gt; cluster nodes</span><br><span class="line"><span class="attribute">f158bf70bb2767cac271ce4efcfc14ba0b7ca98b</span> <span class="number">172.22.6.3:7006</span>@<span class="number">17006</span> slave e7aa182e756b76ec85b471797db9b66e4b2da725 <span class="number">0</span> <span class="number">1594529342575</span> <span class="number">6</span> connected</span><br><span class="line"><span class="attribute">f348e67648460c7a800120d69b4977bf2e4524cb</span> <span class="number">172.22.6.3:7001</span>@<span class="number">17001</span> myself,master - <span class="number">0</span> <span class="number">1594529340000</span> <span class="number">1</span> connected <span class="number">0</span>-<span class="number">5460</span></span><br><span class="line"><span class="attribute">55cacf121662833a4a19dbeb4a5df712cfedf77f</span> <span class="number">172.22.6.3:7009</span>@<span class="number">17009</span> master - <span class="number">0</span> <span class="number">1594529342000</span> <span class="number">0</span> connected</span><br><span class="line"><span class="attribute">c6c6a68674ae8aac3c6ec792c8af4dc1228c6c31</span> <span class="number">172.22.6.3:7005</span>@<span class="number">17005</span> slave f348e67648460c7a800120d69b4977bf2e4524cb <span class="number">0</span> <span class="number">1594529341573</span> <span class="number">5</span> connected</span><br><span class="line"><span class="attribute">4802fafe897160c46392c6e569d6f5e466cca696</span> <span class="number">172.22.6.3:7003</span>@<span class="number">17003</span> master - <span class="number">0</span> <span class="number">1594529343577</span> <span class="number">3</span> connected <span class="number">10923</span>-<span class="number">16383</span></span><br><span class="line"><span class="attribute">e7aa182e756b76ec85b471797db9b66e4b2da725</span> <span class="number">172.22.6.3:7002</span>@<span class="number">17002</span> master - <span class="number">0</span> <span class="number">1594529342000</span> <span class="number">2</span> connected <span class="number">5461</span>-<span class="number">10922</span></span><br><span class="line"><span class="attribute">e5ba78fe629115977a74fbbe1478caf8868d6d55</span> <span class="number">172.22.6.3:7007</span>@<span class="number">17007</span> master - <span class="number">0</span> <span class="number">1594529341000</span> <span class="number">0</span> connected</span><br><span class="line"><span class="attribute">52601e2d4af0e64b83f4cc6d20e8316d0ac38b99</span> <span class="number">172.22.6.3:7004</span>@<span class="number">17004</span> slave <span class="number">4802</span>fafe897160c46392c6e569d6f5e466cca696 <span class="number">0</span> <span class="number">1594529340000</span> <span class="number">4</span> connected</span><br><span class="line"><span class="attribute">79d4fffc2cec210556c3b4c44e63ab506e87eda3</span> <span class="number">172.22.6.3:7008</span>@<span class="number">17008</span> master - <span class="number">0</span> <span class="number">1594529340000</span> <span class="number">7</span> connected</span><br></pre></td></tr></table></figure>

<p>可以发现，新加入的三个主节点，还没有分配哈希槽，所以，暂时还无法访问。</p>
<p><strong>添加从节点</strong></p>
<p>–slave：设置该参数，则新节点以 slave 的角色加入集群<br>–master-id：这个参数需要设置了–slave 才能生效，–master-id 用来指定新节点的 master 节点。如果不设置该参数，则会随机为节点选择 master 节点。</p>
<p>语法</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster<span class="built_in"> add-node </span> 新节点IP地址：端口    存在节点IP：端口 --cluster-slave （从节点） --cluster-master-id （master节点的ID）</span><br><span class="line">redis-cli --cluster<span class="built_in"> add-node </span>  10.42.141.119:6379  10.42.166.105:6379  --cluster-slave   --cluster-master-id  dfa238fff8a7a49230cff7eb74f573f5645c8ec5</span><br></pre></td></tr></table></figure>

<p>示例</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">.</span>/redis-cli --cluster<span class="built_in"> add-node </span>172.22.6.3:7010 172.22.6.3:7007 --cluster-slave</span><br><span class="line"><span class="keyword">.</span>/redis-cli --cluster<span class="built_in"> add-node </span>172.22.6.3:7011 172.22.6.3:7008 --cluster-slave</span><br><span class="line"><span class="keyword">.</span>/redis-cli --cluster<span class="built_in"> add-node </span>172.22.6.3:7012 172.22.6.3:7009 --cluster-slave</span><br></pre></td></tr></table></figure>

<p>查看状态</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">172</span>.<span class="number">22</span>.<span class="number">6</span>.<span class="number">3</span>:<span class="number">7001</span>&gt; cluster nodes</span><br><span class="line"><span class="attribute">ef5c1b9ce4cc795dc12b2c1e8736a572647b4c3e</span> <span class="number">172.22.6.3:7011</span>@<span class="number">17011</span> slave <span class="number">79</span>d4fffc2cec210556c3b4c44e63ab506e87eda3 <span class="number">0</span> <span class="number">1594529492043</span> <span class="number">7</span> connected</span><br><span class="line"><span class="attribute">f158bf70bb2767cac271ce4efcfc14ba0b7ca98b</span> <span class="number">172.22.6.3:7006</span>@<span class="number">17006</span> slave e7aa182e756b76ec85b471797db9b66e4b2da725 <span class="number">0</span> <span class="number">1594529491943</span> <span class="number">6</span> connected</span><br><span class="line"><span class="attribute">f348e67648460c7a800120d69b4977bf2e4524cb</span> <span class="number">172.22.6.3:7001</span>@<span class="number">17001</span> myself,master - <span class="number">0</span> <span class="number">1594529488000</span> <span class="number">1</span> connected <span class="number">0</span>-<span class="number">5460</span></span><br><span class="line"><span class="attribute">5140d1129ed850df59c51cf818c4eb74545d9959</span> <span class="number">172.22.6.3:7010</span>@<span class="number">17010</span> slave e5ba78fe629115977a74fbbe1478caf8868d6d55 <span class="number">0</span> <span class="number">1594529488000</span> <span class="number">0</span> connected</span><br><span class="line"><span class="attribute">55cacf121662833a4a19dbeb4a5df712cfedf77f</span> <span class="number">172.22.6.3:7009</span>@<span class="number">17009</span> master - <span class="number">0</span> <span class="number">1594529488000</span> <span class="number">8</span> connected</span><br><span class="line"><span class="attribute">c6c6a68674ae8aac3c6ec792c8af4dc1228c6c31</span> <span class="number">172.22.6.3:7005</span>@<span class="number">17005</span> slave f348e67648460c7a800120d69b4977bf2e4524cb <span class="number">0</span> <span class="number">1594529490000</span> <span class="number">5</span> connected</span><br><span class="line"><span class="attribute">4802fafe897160c46392c6e569d6f5e466cca696</span> <span class="number">172.22.6.3:7003</span>@<span class="number">17003</span> master - <span class="number">0</span> <span class="number">1594529489939</span> <span class="number">3</span> connected <span class="number">10923</span>-<span class="number">16383</span></span><br><span class="line"><span class="attribute">e7aa182e756b76ec85b471797db9b66e4b2da725</span> <span class="number">172.22.6.3:7002</span>@<span class="number">17002</span> master - <span class="number">0</span> <span class="number">1594529491000</span> <span class="number">2</span> connected <span class="number">5461</span>-<span class="number">10922</span></span><br><span class="line"><span class="attribute">e5ba78fe629115977a74fbbe1478caf8868d6d55</span> <span class="number">172.22.6.3:7007</span>@<span class="number">17007</span> master - <span class="number">0</span> <span class="number">1594529490942</span> <span class="number">0</span> connected</span><br><span class="line"><span class="attribute">52601e2d4af0e64b83f4cc6d20e8316d0ac38b99</span> <span class="number">172.22.6.3:7004</span>@<span class="number">17004</span> slave <span class="number">4802</span>fafe897160c46392c6e569d6f5e466cca696 <span class="number">0</span> <span class="number">1594529491000</span> <span class="number">4</span> connected</span><br><span class="line"><span class="attribute">02e9f57b5b45c350dc57acf1c8efa8db136db7b7</span> <span class="number">172.22.6.3:7012</span>@<span class="number">17012</span> master - <span class="number">0</span> <span class="number">1594529489000</span> <span class="number">0</span> connected</span><br><span class="line"><span class="attribute">79d4fffc2cec210556c3b4c44e63ab506e87eda3</span> <span class="number">172.22.6.3:7008</span>@<span class="number">17008</span> master - <span class="number">0</span> <span class="number">1594529489000</span> <span class="number">7</span> connected</span><br></pre></td></tr></table></figure>

<p>分配哈希槽</p>
<p>执行 <code>./redis-cli --cluster rebalance 172.22.6.3:7001 --cluster-threshold 1 --cluster-use-empty-masters</code></p>
<p>参数说明：</p>
<p>rebalance：表明让 Redis 自动根据节点数进行均衡哈希槽分配。</p>
<p>–cluster-use-empty-masters：表明</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200712125827.png" alt="img"></p>
<p>执行结束后，查看状态：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200712130234.png" alt="img"></p>
<h2 id="Redis-命令"><a href="#Redis-命令" class="headerlink" title="Redis 命令"></a>Redis 命令</h2><h3 id="通用命令"><a href="#通用命令" class="headerlink" title="通用命令"></a>通用命令</h3><blockquote>
<p>命令详细用法，请参考 <a target="_blank" rel="noopener" href="https://redis.io/commands"><strong>Redis 命令官方文档</strong></a></p>
<p>搬迁两张 cheat sheet 图，原址：<a target="_blank" rel="noopener" href="https://www.cheatography.com/tasjaevan/cheat-sheets/redis/">https://www.cheatography.com/tasjaevan/cheat-sheets/redis/</a></p>
</blockquote>
<p><img src="https://user-gold-cdn.xitu.io/2019/10/10/16db5250b0b8ea57?w=2230&h=2914&f=png&s=246433" alt="img"></p>
<p><img src="https://user-gold-cdn.xitu.io/2019/10/10/16db5250b0e9ba3c?w=2229&h=2890&f=png&s=192997" alt="img"></p>
<h3 id="集群命令"><a href="#集群命令" class="headerlink" title="集群命令"></a>集群命令</h3><ul>
<li><strong>集群</strong><ul>
<li><code>cluster info</code> - 打印集群的信息</li>
<li><code>cluster nodes</code> - 列出集群当前已知的所有节点（ node），以及这些节点的相关信息。</li>
</ul>
</li>
<li><strong>节点</strong><ul>
<li><code>cluster meet &lt;ip&gt; &lt;port&gt;</code> - 将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。</li>
<li><code>cluster forget &lt;node_id&gt;</code> - 从集群中移除 node_id 指定的节点。</li>
<li><code>cluster replicate &lt;node_id&gt;</code> - 将当前节点设置为 node_id 指定的节点的从节点。</li>
<li><code>cluster saveconfig</code> - 将节点的配置文件保存到硬盘里面。</li>
</ul>
</li>
<li><strong>槽(slot)</strong><ul>
<li><code>cluster addslots &lt;slot&gt; [slot ...]</code> - 将一个或多个槽（ slot）指派（ assign）给当前节点。</li>
<li><code>cluster delslots &lt;slot&gt; [slot ...]</code> - 移除一个或多个槽对当前节点的指派。</li>
<li><code>cluster flushslots</code> - 移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。</li>
<li><code>cluster setslot &lt;slot&gt; node &lt;node_id&gt;</code> - 将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽&gt;，然后再进行指派。</li>
<li><code>cluster setslot &lt;slot&gt; migrating &lt;node_id&gt;</code> - 将本节点的槽 slot 迁移到 node_id 指定的节点中。</li>
<li><code>cluster setslot &lt;slot&gt; importing &lt;node_id&gt;</code> - 从 node_id 指定的节点中导入槽 slot 到本节点。</li>
<li><code>cluster setslot &lt;slot&gt; stable</code> - 取消对槽 slot 的导入（ import）或者迁移（ migrate）。</li>
</ul>
</li>
<li><strong>键</strong><ul>
<li><code>cluster keyslot &lt;key&gt;</code> - 计算键 key 应该被放置在哪个槽上。</li>
<li><code>cluster countkeysinslot &lt;slot&gt;</code> - 返回槽 slot 目前包含的键值对数量。</li>
<li><code>cluster getkeysinslot &lt;slot&gt; &lt;count&gt;</code> - 返回 count 个 slot 槽中的键。</li>
</ul>
</li>
</ul>
<h3 id="重新分片"><a href="#重新分片" class="headerlink" title="重新分片"></a>重新分片</h3><p>添加节点：.&#x2F;redis-cli –cluster add-node 192.168.1.136:7007 192.168.1.136:7001 –cluster-slave</p>
<p>redis-cli –cluster reshard 172.22.6.3 7001</p>
<h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>推荐使用 <a target="_blank" rel="noopener" href="https://github.com/uglide/RedisDesktopManager"><strong>RedisDesktopManager</strong></a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><strong>官网</strong><ul>
<li><a target="_blank" rel="noopener" href="https://redis.io/">Redis 官网</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/antirez/redis">Redis Github</a></li>
<li><a target="_blank" rel="noopener" href="http://redis.cn/">Redis 官方文档中文版</a></li>
</ul>
</li>
<li><strong>书籍</strong><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11791607.html">《Redis 实战》</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
</ul>
</li>
<li><strong>教程</strong><ul>
<li><a target="_blank" rel="noopener" href="http://redisdoc.com/">Redis 命令参考</a></li>
</ul>
</li>
<li><strong>文章</strong><ul>
<li><a target="_blank" rel="noopener" href="https://juejin.im/post/5b8fc5536fb9a05d2d01fb11">深入剖析 Redis 系列(三) - Redis 集群模式搭建与原理详解</a></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/1fc9c4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/1fc9c4/" class="post-title-link" itemprop="url">Redis 实战</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-24 10:45:38" itemprop="dateCreated datePublished" datetime="2020-06-24T10:45:38+08:00">2020-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">KV数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/KV%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>10k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Redis-实战"><a href="#Redis-实战" class="headerlink" title="Redis 实战"></a>Redis 实战</h1><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存是 Redis 最常见的应用场景。</p>
<p>Redis 有多种数据类型，以及丰富的操作命令，并且有着高性能、高可用的特性，非常适合用于分布式缓存。</p>
<blockquote>
<p>缓存应用的基本原理，请参考 <a target="_blank" rel="noopener" href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.html"><strong>缓存基本原理</strong></a> 第四 ~ 第六节内容。</p>
</blockquote>
<h2 id="BitMap-和-BloomFilter"><a href="#BitMap-和-BloomFilter" class="headerlink" title="BitMap 和 BloomFilter"></a>BitMap 和 BloomFilter</h2><p>Redis 除了 5 种基本数据类型外，还支持 BitMap 和 BloomFilter（即布隆过滤器，可以通过 Redis Module 支持）。</p>
<p>BitMap 和 BloomFilter 都可以用于解决缓存穿透问题。要点在于：过滤一些不可能存在的数据。</p>
<blockquote>
<p>什么是缓存穿透，可以参考：<a target="_blank" rel="noopener" href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.html"><strong>缓存基本原理</strong></a></p>
</blockquote>
<p>小数据量可以用 BitMap，大数据量可以用布隆过滤器。</p>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>使用 Redis 作为分布式锁，基本要点如下：</p>
<ul>
<li><strong>互斥性</strong> - 使用 <code>setnx</code> 抢占锁。</li>
<li><strong>避免永远不释放锁</strong> - 使用 <code>expire</code> 加一个过期时间，避免一直不释放锁，导致阻塞。</li>
<li><strong>原子性</strong> - setnx 和 expire 必须合并为一个原子指令，避免 setnx 后，机器崩溃，没来得及设置 expire，从而导致锁永不释放。</li>
</ul>
<blockquote>
<p>更多分布式锁的实现方式及细节，请参考：<a target="_blank" rel="noopener" href="https://dunwu.github.io/waterdrop/pages/40ac64/">分布式锁基本原理</a></p>
</blockquote>
<p>根据 Redis 的特性，在实际应用中，存在一些应用小技巧。</p>
<h2 id="keys-和-scan"><a href="#keys-和-scan" class="headerlink" title="keys 和 scan"></a>keys 和 scan</h2><p>使用 <code>keys</code> 指令可以扫出指定模式的 key 列表。</p>
<p>如果这个 redis 正在给线上的业务提供服务，那使用 <code>keys</code> 指令会有什么问题？</p>
<p>首先，Redis 是单线程的。<code>keys</code> 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。</p>
<p>这个时候可以使用 <code>scan</code> 指令，<code>scan</code> 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 <code>keys</code> 指令长。</p>
<p>不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 <code>SMEMBERS</code> 命令可以返回集合键当前包含的所有元素， 但是对于 <code>SCAN</code> 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。</p>
<h2 id="大-Key-如何处理"><a href="#大-Key-如何处理" class="headerlink" title="大 Key 如何处理"></a>大 Key 如何处理</h2><blockquote>
<p>什么是 Redis 大 key？</p>
</blockquote>
<p>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p>
<p>一般而言，下面这两种情况被称为大 key：</p>
<ul>
<li>String 类型的值大于 10 KB；</li>
<li>Hash、List、Set、ZSet 类型的元素的个数超过 5000 个；</li>
</ul>
<blockquote>
<p>大 key 会造成什么问题？</p>
</blockquote>
<p>大 key 会带来以下四种影响：</p>
<ul>
<li><strong>客户端超时阻塞</strong>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li><strong>引发网络阻塞</strong>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li><strong>阻塞工作线程</strong>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li><strong>内存分布不均</strong>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
<blockquote>
<p>如何找到大 key ？</p>
</blockquote>
<p><strong><em>1、redis-cli –bigkeys 查找大 key</em></strong></p>
<p>可以通过 redis-cli –bigkeys 命令查找大 key：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6379 -a &quot;password&quot; -- bigkeys</span><br></pre></td></tr></table></figure>

<p>使用的时候注意事项：</p>
<ul>
<li>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；</li>
<li>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li>
</ul>
<p>该方式的不足之处：</p>
<ul>
<li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；</li>
<li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</li>
</ul>
<p><strong><em>2、使用 SCAN 命令查找大 key</em></strong></p>
<p>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。</p>
<p>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。</p>
<p>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p>
<ul>
<li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：<code>LLEN</code> 命令；Hash 类型：<code>HLEN</code> 命令；Set 类型：<code>SCARD</code> 命令；Sorted Set 类型：<code>ZCARD</code> 命令；</li>
<li>如果不能提前知道写入集合的元素大小，可以使用 <code>MEMORY USAGE</code> 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</li>
</ul>
<p><strong><em>3、使用 RdbTools 工具查找大 key</em></strong></p>
<p>使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。</p>
<p>比如，下面这条命令，将大于 10 kb 的 key 输出到一个表格文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdb dump.rdb -c memory --bytes 10240 -f redis.csv</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如何删除大 key？</p>
</blockquote>
<p>删除操作的本质是要释放键值对占用的内存空间，不要小瞧内存的释放过程。</p>
<p>释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。</p>
<p>所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。</p>
<p>因此，删除大 key 这一个动作，我们要小心。具体要怎么做呢？这里给出两种方法：</p>
<ul>
<li>分批次删除</li>
<li>异步删除（Redis 4.0 版本以上）</li>
</ul>
<p><strong><em>1、分批次删除</em></strong></p>
<p>对于<strong>删除大 Hash</strong>，使用 <code>hscan</code> 命令，每次获取 100 个字段，再用 <code>hdel</code> 命令，每次删除 1 个字段。</p>
<p>Python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_hash</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;redis-host1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">    large_hash_key =<span class="string">&quot;xxx&quot;</span> <span class="comment">#要删除的大hash键名</span></span><br><span class="line">    cursor = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    <span class="keyword">while</span> cursor != <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 使用 hscan 命令，每次获取 100 个字段</span></span><br><span class="line">        cursor, data = r.hscan(large_hash_key, cursor=cursor, count=<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data.items():</span><br><span class="line">                <span class="comment"># 再用 hdel 命令，每次删除1个字段</span></span><br><span class="line">                r.hdel(large_hash_key, item[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p>对于<strong>删除大 List</strong>，通过 <code>ltrim</code> 命令，每次删除少量元素。</p>
<p>Python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_list</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;redis-host1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">  large_list_key = <span class="string">&#x27;xxx&#x27;</span>  <span class="comment">#要删除的大list的键名</span></span><br><span class="line">  <span class="keyword">while</span> r.llen(large_list_key)&gt;<span class="number">0</span>:</span><br><span class="line">      <span class="comment">#每次只删除最右100个元素</span></span><br><span class="line">      r.ltrim(large_list_key, <span class="number">0</span>, -<span class="number">101</span>)</span><br></pre></td></tr></table></figure>

<p>对于<strong>删除大 Set</strong>，使用 <code>sscan</code> 命令，每次扫描集合中 100 个元素，再用 <code>srem</code> 命令每次删除一个键。</p>
<p>Python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_set</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;redis-host1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">  large_set_key = <span class="string">&#x27;xxx&#x27;</span>   <span class="comment"># 要删除的大set的键名</span></span><br><span class="line">  cursor = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">  <span class="keyword">while</span> cursor != <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 使用 sscan 命令，每次扫描集合中 100 个元素</span></span><br><span class="line">    cursor, data = r.sscan(large_set_key, cursor=cursor, count=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">      <span class="comment"># 再用 srem 命令每次删除一个键</span></span><br><span class="line">      r.srem(large_size_key, item)</span><br></pre></td></tr></table></figure>

<p>对于<strong>删除大 ZSet</strong>，使用 <code>zremrangebyrank</code> 命令，每次删除 top 100 个元素。</p>
<p>Python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_sortedset</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;large_sortedset_key&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">  large_sortedset_key=<span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">  <span class="keyword">while</span> r.zcard(large_sortedset_key)&gt;<span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 使用 zremrangebyrank 命令，每次删除 top 100个元素</span></span><br><span class="line">    r.zremrangebyrank(large_sortedset_key,<span class="number">0</span>,<span class="number">99</span>)</span><br></pre></td></tr></table></figure>

<p><strong><em>2、异步删除</em></strong></p>
<p>从 Redis 4.0 版本开始，可以采用<strong>异步删除</strong>法，<strong>用 unlink 命令代替 del 来删除</strong>。</p>
<p>这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。</p>
<p>除了主动调用 unlink 命令实现异步删除之外，我们还可以通过配置参数，达到某些条件的时候自动进行异步删除。</p>
<p>主要有 4 种场景，默认都是关闭的：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lazyfree-lazy-eviction no</span><br><span class="line">lazyfree-lazy-expire no</span><br><span class="line">lazyfree-lazy-server-del</span><br><span class="line">noslave-lazy-flush no</span><br></pre></td></tr></table></figure>

<p>它们代表的含义如下：</p>
<ul>
<li>lazyfree-lazy-eviction：表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除；</li>
<li>lazyfree-lazy-expire：表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除；</li>
<li>lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除；</li>
<li>slave-lazy-flush：针对 slave (从节点) 进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除。</li>
</ul>
<p>建议开启其中的 lazyfree-lazy-eviction、lazyfree-lazy-expire、lazyfree-lazy-server-del 等配置，这样就可以有效的提高主线程的执行效率。</p>
<h2 id="最受欢迎文章"><a href="#最受欢迎文章" class="headerlink" title="最受欢迎文章"></a>最受欢迎文章</h2><p>选出最受欢迎文章，需要支持对文章进行评分。</p>
<h3 id="对文章进行投票"><a href="#对文章进行投票" class="headerlink" title="对文章进行投票"></a>对文章进行投票</h3><p>（1）使用 HASH 存储文章</p>
<p>使用 <code>HASH</code> 类型存储文章信息。其中：key 是文章 ID；field 是文章的属性 key；value 是属性对应值。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200225143038.jpg" alt="img"></p>
<p>操作：</p>
<ul>
<li>存储文章信息 - 使用 <code>HSET</code> 或 <code>HMGET</code> 命令</li>
<li>查询文章信息 - 使用 <code>HGETALL</code> 命令</li>
<li>添加投票 - 使用 <code>HINCRBY</code> 命令</li>
</ul>
<p>（2）使用 <code>ZSET</code> 针对不同维度集合排序</p>
<p>使用 <code>ZSET</code> 类型分别存储按照时间排序和按照评分排序的文章 ID 集合。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200225145742.jpg" alt="img"></p>
<p>操作：</p>
<ul>
<li>添加记录 - 使用 <code>ZADD</code> 命令</li>
<li>添加分数 - 使用 <code>ZINCRBY</code> 命令</li>
<li>取出多篇文章 - 使用 <code>ZREVRANGE</code> 命令</li>
</ul>
<p>（3）为了防止重复投票，使用 <code>SET</code> 类型记录每篇文章 ID 对应的投票集合。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200225150105.jpg" alt="img"></p>
<p>操作：</p>
<ul>
<li>添加投票者 - 使用 <code>SADD</code> 命令</li>
<li>设置有效期 - 使用 <code>EXPIRE</code> 命令</li>
</ul>
<p>（4）假设 user:115423 给 article:100408 投票，分别需要高更新评分排序集合以及投票集合。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200225150138.jpg" alt="img"></p>
<p>当需要对一篇文章投票时，程序需要用 ZSCORE 命令检查记录文章发布时间的有序集合，判断文章的发布时间是否超过投票有效期（比如：一星期）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">articleVote</span><span class="params">(Jedis conn, String user, String article)</span> &#123;</span><br><span class="line">    <span class="comment">// 计算文章的投票截止时间。</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">cutoff</span> <span class="operator">=</span> (System.currentTimeMillis() / <span class="number">1000</span>) - ONE_WEEK_IN_SECONDS;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否还可以对文章进行投票</span></span><br><span class="line">    <span class="comment">// （虽然使用散列也可以获取文章的发布时间，</span></span><br><span class="line">    <span class="comment">// 但有序集合返回的文章发布时间为浮点数，</span></span><br><span class="line">    <span class="comment">// 可以不进行转换直接使用）。</span></span><br><span class="line">    <span class="keyword">if</span> (conn.zscore(<span class="string">&quot;time:&quot;</span>, article) &lt; cutoff) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从article:id标识符（identifier）里面取出文章的ID。</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">articleId</span> <span class="operator">=</span> article.substring(article.indexOf(<span class="string">&#x27;:&#x27;</span>) + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果用户是第一次为这篇文章投票，那么增加这篇文章的投票数量和评分。</span></span><br><span class="line">    <span class="keyword">if</span> (conn.sadd(<span class="string">&quot;voted:&quot;</span> + articleId, user) == <span class="number">1</span>) &#123;</span><br><span class="line">        conn.zincrby(<span class="string">&quot;score:&quot;</span>, VOTE_SCORE, article);</span><br><span class="line">        conn.hincrBy(article, <span class="string">&quot;votes&quot;</span>, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="发布并获取文章"><a href="#发布并获取文章" class="headerlink" title="发布并获取文章"></a>发布并获取文章</h3><p>发布文章：</p>
<ul>
<li>添加文章 - 使用 <code>INCR</code> 命令计算新的文章 ID，填充文章信息，然后用 <code>HSET</code> 命令或 <code>HMSET</code> 命令写入到 <code>HASH</code> 结构中。</li>
<li>将文章作者 ID 添加到投票名单 - 使用 <code>SADD</code> 命令添加到代表投票名单的 <code>SET</code> 结构中。</li>
<li>设置投票有效期 - 使用 <code>EXPIRE</code> 命令设置投票有效期。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">postArticle</span><span class="params">(Jedis conn, String user, String title, String link)</span> &#123;</span><br><span class="line">    <span class="comment">// 生成一个新的文章ID。</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">articleId</span> <span class="operator">=</span> String.valueOf(conn.incr(<span class="string">&quot;article:&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="type">String</span> <span class="variable">voted</span> <span class="operator">=</span> <span class="string">&quot;voted:&quot;</span> + articleId;</span><br><span class="line">    <span class="comment">// 将发布文章的用户添加到文章的已投票用户名单里面，</span></span><br><span class="line">    conn.sadd(voted, user);</span><br><span class="line">    <span class="comment">// 然后将这个名单的过期时间设置为一周（第3章将对过期时间作更详细的介绍）。</span></span><br><span class="line">    conn.expire(voted, ONE_WEEK_IN_SECONDS);</span><br><span class="line"></span><br><span class="line">    <span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> System.currentTimeMillis() / <span class="number">1000</span>;</span><br><span class="line">    <span class="type">String</span> <span class="variable">article</span> <span class="operator">=</span> <span class="string">&quot;article:&quot;</span> + articleId;</span><br><span class="line">    <span class="comment">// 将文章信息存储到一个散列里面。</span></span><br><span class="line">    HashMap&lt;String, String&gt; articleData = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;();</span><br><span class="line">    articleData.put(<span class="string">&quot;title&quot;</span>, title);</span><br><span class="line">    articleData.put(<span class="string">&quot;link&quot;</span>, link);</span><br><span class="line">    articleData.put(<span class="string">&quot;user&quot;</span>, user);</span><br><span class="line">    articleData.put(<span class="string">&quot;now&quot;</span>, String.valueOf(now));</span><br><span class="line">    articleData.put(<span class="string">&quot;votes&quot;</span>, <span class="string">&quot;1&quot;</span>);</span><br><span class="line">    conn.hmset(article, articleData);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将文章添加到根据发布时间排序的有序集合和根据评分排序的有序集合里面。</span></span><br><span class="line">    conn.zadd(<span class="string">&quot;score:&quot;</span>, now + VOTE_SCORE, article);</span><br><span class="line">    conn.zadd(<span class="string">&quot;time:&quot;</span>, now, article);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> articleId;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分页查询最受欢迎文章：</p>
<p>使用 <code>ZINTERSTORE</code> 命令根据页码、每页记录数、排序号，根据评分值从大到小分页查出文章 ID 列表。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;Map&lt;String, String&gt;&gt; <span class="title function_">getArticles</span><span class="params">(Jedis conn, <span class="type">int</span> page, String order)</span> &#123;</span><br><span class="line">    <span class="comment">// 设置获取文章的起始索引和结束索引。</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">start</span> <span class="operator">=</span> (page - <span class="number">1</span>) * ARTICLES_PER_PAGE;</span><br><span class="line">    <span class="type">int</span> <span class="variable">end</span> <span class="operator">=</span> start + ARTICLES_PER_PAGE - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取多个文章ID。</span></span><br><span class="line">    Set&lt;String&gt; ids = conn.zrevrange(order, start, end);</span><br><span class="line">    List&lt;Map&lt;String, String&gt;&gt; articles = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="comment">// 根据文章ID获取文章的详细信息。</span></span><br><span class="line">    <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">        Map&lt;String, String&gt; articleData = conn.hgetAll(id);</span><br><span class="line">        articleData.put(<span class="string">&quot;id&quot;</span>, id);</span><br><span class="line">        articles.add(articleData);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> articles;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="对文章进行分组"><a href="#对文章进行分组" class="headerlink" title="对文章进行分组"></a>对文章进行分组</h3><p>如果文章需要分组，功能需要分为两块：</p>
<ul>
<li>记录文章属于哪个群组</li>
<li>负责取出群组里的文章</li>
</ul>
<p>将文章添加、删除群组：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addRemoveGroups</span><span class="params">(Jedis conn, String articleId, String[] toAdd, String[] toRemove)</span> &#123;</span><br><span class="line">    <span class="comment">// 构建存储文章信息的键名。</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">article</span> <span class="operator">=</span> <span class="string">&quot;article:&quot;</span> + articleId;</span><br><span class="line">    <span class="comment">// 将文章添加到它所属的群组里面。</span></span><br><span class="line">    <span class="keyword">for</span> (String group : toAdd) &#123;</span><br><span class="line">        conn.sadd(<span class="string">&quot;group:&quot;</span> + group, article);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 从群组里面移除文章。</span></span><br><span class="line">    <span class="keyword">for</span> (String group : toRemove) &#123;</span><br><span class="line">        conn.srem(<span class="string">&quot;group:&quot;</span> + group, article);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>取出群组里的文章：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200225214210.jpg" alt="img"></p>
<ul>
<li>通过对存储群组文章的集合和存储文章评分的有序集合执行 <code>ZINTERSTORE</code> 命令，可以得到按照文章评分排序的群组文章。</li>
<li>通过对存储群组文章的集合和存储文章发布时间的有序集合执行 <code>ZINTERSTORE</code> 命令，可以得到按照文章发布时间排序的群组文章。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;Map&lt;String, String&gt;&gt; <span class="title function_">getGroupArticles</span><span class="params">(Jedis conn, String group, <span class="type">int</span> page, String order)</span> &#123;</span><br><span class="line">    <span class="comment">// 为每个群组的每种排列顺序都创建一个键。</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> order + group;</span><br><span class="line">    <span class="comment">// 检查是否有已缓存的排序结果，如果没有的话就现在进行排序。</span></span><br><span class="line">    <span class="keyword">if</span> (!conn.exists(key)) &#123;</span><br><span class="line">        <span class="comment">// 根据评分或者发布时间，对群组文章进行排序。</span></span><br><span class="line">        <span class="type">ZParams</span> <span class="variable">params</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZParams</span>().aggregate(ZParams.Aggregate.MAX);</span><br><span class="line">        conn.zinterstore(key, params, <span class="string">&quot;group:&quot;</span> + group, order);</span><br><span class="line">        <span class="comment">// 让Redis在60秒钟之后自动删除这个有序集合。</span></span><br><span class="line">        conn.expire(key, <span class="number">60</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 调用之前定义的getArticles函数来进行分页并获取文章数据。</span></span><br><span class="line">    <span class="keyword">return</span> getArticles(conn, page, key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="管理令牌"><a href="#管理令牌" class="headerlink" title="管理令牌"></a>管理令牌</h2><p>网站一般会以 Cookie、Session、令牌这类信息存储用户身份信息。</p>
<p>可以将 Cookie&#x2F;Session&#x2F;令牌 和用户的映射关系存储在 <code>HASH</code> 结构。</p>
<p>下面以令牌来举例。</p>
<h3 id="查询令牌"><a href="#查询令牌" class="headerlink" title="查询令牌"></a>查询令牌</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String <span class="title function_">checkToken</span><span class="params">(Jedis conn, String token)</span> &#123;</span><br><span class="line">    <span class="comment">// 尝试获取并返回令牌对应的用户。</span></span><br><span class="line">    <span class="keyword">return</span> conn.hget(<span class="string">&quot;login:&quot;</span>, token);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="更新令牌"><a href="#更新令牌" class="headerlink" title="更新令牌"></a>更新令牌</h3><ul>
<li>用户每次访问页面，可以记录下令牌和当前时间戳的映射关系，存入一个 <code>ZSET</code> 结构中，以便分析用户是否活跃，继而可以周期性清理最老的令牌，统计当前在线用户数等行为。</li>
<li>用户如果正在浏览商品，可以记录到用户最近浏览过的商品有序集合中（集合可以限定数量，超过数量进行裁剪），存入到一个 <code>ZSET</code> 结构中，以便分析用户最近可能感兴趣的商品，以便推荐商品。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">updateToken</span><span class="params">(Jedis conn, String token, String user, String item)</span> &#123;</span><br><span class="line">    <span class="comment">// 获取当前时间戳。</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">timestamp</span> <span class="operator">=</span> System.currentTimeMillis() / <span class="number">1000</span>;</span><br><span class="line">    <span class="comment">// 维持令牌与已登录用户之间的映射。</span></span><br><span class="line">    conn.hset(<span class="string">&quot;login:&quot;</span>, token, user);</span><br><span class="line">    <span class="comment">// 记录令牌最后一次出现的时间。</span></span><br><span class="line">    conn.zadd(<span class="string">&quot;recent:&quot;</span>, timestamp, token);</span><br><span class="line">    <span class="keyword">if</span> (item != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 记录用户浏览过的商品。</span></span><br><span class="line">        conn.zadd(<span class="string">&quot;viewed:&quot;</span> + token, timestamp, item);</span><br><span class="line">        <span class="comment">// 移除旧的记录，只保留用户最近浏览过的25个商品。</span></span><br><span class="line">        conn.zremrangeByRank(<span class="string">&quot;viewed:&quot;</span> + token, <span class="number">0</span>, -<span class="number">26</span>);</span><br><span class="line">        conn.zincrby(<span class="string">&quot;viewed:&quot;</span>, -<span class="number">1</span>, item);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="清理令牌"><a href="#清理令牌" class="headerlink" title="清理令牌"></a>清理令牌</h3><p>上一节提到，更新令牌时，将令牌和当前时间戳的映射关系，存入一个 <code>ZSET</code> 结构中。所以可以通过排序得知哪些令牌最老。如果没有清理操作，更新令牌占用的内存会不断膨胀，直到导致机器宕机。</p>
<p>比如：最多允许存储 1000 万条令牌信息，周期性检查，一旦发现记录数超出 1000 万条，将 ZSET 从新到老排序，将超出 1000 万条的记录清除。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">CleanSessionsThread</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Jedis conn;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> limit;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">boolean</span> quit;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">CleanSessionsThread</span><span class="params">(<span class="type">int</span> limit)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.conn = <span class="keyword">new</span> <span class="title class_">Jedis</span>(<span class="string">&quot;localhost&quot;</span>);</span><br><span class="line">        <span class="built_in">this</span>.conn.select(<span class="number">15</span>);</span><br><span class="line">        <span class="built_in">this</span>.limit = limit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">quit</span><span class="params">()</span> &#123;</span><br><span class="line">        quit = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (!quit) &#123;</span><br><span class="line">            <span class="comment">// 找出目前已有令牌的数量。</span></span><br><span class="line">            <span class="type">long</span> <span class="variable">size</span> <span class="operator">=</span> conn.zcard(<span class="string">&quot;recent:&quot;</span>);</span><br><span class="line">            <span class="comment">// 令牌数量未超过限制，休眠并在之后重新检查。</span></span><br><span class="line">            <span class="keyword">if</span> (size &lt;= limit) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    sleep(<span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">                    Thread.currentThread().interrupt();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 获取需要移除的令牌ID。</span></span><br><span class="line">            <span class="type">long</span> <span class="variable">endIndex</span> <span class="operator">=</span> Math.min(size - limit, <span class="number">100</span>);</span><br><span class="line">            Set&lt;String&gt; tokenSet = conn.zrange(<span class="string">&quot;recent:&quot;</span>, <span class="number">0</span>, endIndex - <span class="number">1</span>);</span><br><span class="line">            String[] tokens = tokenSet.toArray(<span class="keyword">new</span> <span class="title class_">String</span>[tokenSet.size()]);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 为那些将要被删除的令牌构建键名。</span></span><br><span class="line">            ArrayList&lt;String&gt; sessionKeys = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;String&gt;();</span><br><span class="line">            <span class="keyword">for</span> (String token : tokens) &#123;</span><br><span class="line">                sessionKeys.add(<span class="string">&quot;viewed:&quot;</span> + token);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 移除最旧的那些令牌。</span></span><br><span class="line">            conn.del(sessionKeys.toArray(<span class="keyword">new</span> <span class="title class_">String</span>[sessionKeys.size()]));</span><br><span class="line">            conn.hdel(<span class="string">&quot;login:&quot;</span>, tokens);</span><br><span class="line">            conn.zrem(<span class="string">&quot;recent:&quot;</span>, tokens);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11791607.html">《Redis 实战》</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11486101.html">《Redis 设计与实现》</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/7644aa/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/7644aa/" class="post-title-link" itemprop="url">MapReduce</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-22 00:22:25" itemprop="dateCreated datePublished" datetime="2020-06-22T00:22:25+08:00">2020-06-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/" itemprop="url" rel="index"><span itemprop="name">hadoop</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="MapReduce-简介"><a href="#MapReduce-简介" class="headerlink" title="MapReduce 简介"></a>MapReduce 简介</h2><blockquote>
<p>Hadoop MapReduce 是一个分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到 Hadoop 集群上用于并行处理大规模的数据集。</p>
</blockquote>
<p>MapReduce 的设计思路是：</p>
<ul>
<li>分而治之，并行计算</li>
<li>移动计算，而非移动数据</li>
</ul>
<p>MapReduce 作业通过将输入的数据集拆分为独立的块，这些块由 <code>map</code> 以并行的方式处理，框架对 <code>map</code> 的输出进行排序，然后输入到 <code>reduce</code> 中。MapReduce 框架专门用于 <code>&lt;key，value&gt;</code> 键值对处理，它将作业的输入视为一组 <code>&lt;key，value&gt;</code> 对，并生成一组 <code>&lt;key，value&gt;</code> 对作为输出。输出和输出的 <code>key</code> 和 <code>value</code> 都必须实现<a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/Writable.html">Writable</a> 接口。</p>
<figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="function"><span class="title">input</span>) &lt;k1, v1&gt; -&gt;</span> <span class="function"><span class="title">map</span> -&gt;</span> &lt;<span class="function"><span class="title">k2</span>, v2&gt; -&gt;</span> <span class="function"><span class="title">combine</span> -&gt;</span> &lt;<span class="function"><span class="title">k2</span>, v2&gt; -&gt;</span> <span class="function"><span class="title">reduce</span> -&gt;</span> &lt;k3, v3&gt; (output)</span><br></pre></td></tr></table></figure>

<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>计算跟着数据走</li>
<li>良好的扩展性：计算能力随着节点数增加，近似线性递增</li>
<li>高容错</li>
<li>状态监控</li>
<li>适合海量数据的离线批处理</li>
<li>降低了分布式编程的门槛</li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>适用场景：</p>
<ul>
<li>数据统计，如：网站的 PV、UV 统计</li>
<li>搜索引擎构建索引</li>
<li>海量数据查询</li>
</ul>
<p>不适用场景：</p>
<ul>
<li>OLAP<ul>
<li>要求毫秒或秒级返回结果</li>
</ul>
</li>
<li>流计算<ul>
<li>流计算的输入数据集是动态的，而 MapReduce 是静态的</li>
</ul>
</li>
<li>DAG 计算<ul>
<li>多个作业存在依赖关系，后一个的输入是前一个的输出，构成有向无环图 DAG</li>
<li>每个 MapReduce 作业的输出结果都会落盘，造成大量磁盘 IO，导致性能非常低下</li>
</ul>
</li>
</ul>
<h2 id="MapReduce-编程模型"><a href="#MapReduce-编程模型" class="headerlink" title="MapReduce 编程模型"></a>MapReduce 编程模型</h2><p>MapReduce 编程模型：MapReduce 程序被分为 Map（映射）阶段和 Reduce（化简）阶段。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601162305.png" alt="img"></p>
<ol>
<li><strong>input</strong> : 读取文本文件；</li>
<li><strong>splitting</strong> : 将文件按照行进行拆分，此时得到的 <code>K1</code> 行数，<code>V1</code> 表示对应行的文本内容；</li>
<li><strong>mapping</strong> : 并行将每一行按照空格进行拆分，拆分得到的 <code>List(K2,V2)</code>，其中 <code>K2</code> 代表每一个单词，由于是做词频统计，所以 <code>V2</code> 的值为 1，代表出现 1 次；</li>
<li><strong>shuffling</strong>：由于 <code>Mapping</code> 操作可能是在不同的机器上并行处理的，所以需要通过 <code>shuffling</code> 将相同 <code>key</code> 值的数据分发到同一个节点上去合并，这样才能统计出最终的结果，此时得到 <code>K2</code> 为每一个单词，<code>List(V2)</code> 为可迭代集合，<code>V2</code> 就是 Mapping 中的 V2；</li>
<li><strong>Reducing</strong> : 这里的案例是统计单词出现的总次数，所以 <code>Reducing</code> 对 <code>List(V2)</code> 进行归约求和操作，最终输出。</li>
</ol>
<p>MapReduce 编程模型中 <code>splitting</code> 和 <code>shuffing</code> 操作都是由框架实现的，需要我们自己编程实现的只有 <code>mapping</code> 和 <code>reducing</code>，这也就是 MapReduce 这个称呼的来源。</p>
<h2 id="combiner-partitioner"><a href="#combiner-partitioner" class="headerlink" title="combiner &amp; partitioner"></a>combiner &amp; partitioner</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601163846.png" alt="img"></p>
<h3 id="InputFormat-RecordReaders"><a href="#InputFormat-RecordReaders" class="headerlink" title="InputFormat &amp; RecordReaders"></a>InputFormat &amp; RecordReaders</h3><p><code>InputFormat</code> 将输出文件拆分为多个 <code>InputSplit</code>，并由 <code>RecordReaders</code> 将 <code>InputSplit</code> 转换为标准的&lt;key，value&gt;键值对，作为 map 的输出。这一步的意义在于只有先进行逻辑拆分并转为标准的键值对格式后，才能为多个 <code>map</code> 提供输入，以便进行并行处理。</p>
<h3 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h3><p><code>combiner</code> 是 <code>map</code> 运算后的可选操作，它实际上是一个本地化的 <code>reduce</code> 操作，它主要是在 <code>map</code> 计算出中间文件后做一个简单的合并重复 <code>key</code> 值的操作。这里以词频统计为例：</p>
<p><code>map</code> 在遇到一个 hadoop 的单词时就会记录为 1，但是这篇文章里 hadoop 可能会出现 n 多次，那么 <code>map</code> 输出文件冗余就会很多，因此在 <code>reduce</code> 计算前对相同的 key 做一个合并操作，那么需要传输的数据量就会减少，传输效率就可以得到提升。</p>
<p>但并非所有场景都适合使用 <code>combiner</code>，使用它的原则是 <code>combiner</code> 的输出不会影响到 <code>reduce</code> 计算的最终输入，例如：求总数，最大值，最小值时都可以使用 <code>combiner</code>，但是做平均值计算则不能使用 <code>combiner</code>。</p>
<p>不使用 combiner 的情况：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601164709.png" alt="img"></p>
<p>使用 combiner 的情况：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601164804.png" alt="img"></p>
<p>可以看到使用 combiner 的时候，需要传输到 reducer 中的数据由 12keys，降低到 10keys。降低的幅度取决于你 keys 的重复率，下文词频统计案例会演示用 combiner 降低数百倍的传输量。</p>
<h2 id="MapReduce-词频统计案例"><a href="#MapReduce-词频统计案例" class="headerlink" title="MapReduce 词频统计案例"></a>MapReduce 词频统计案例</h2><h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p>这里给出一个经典的词频统计的案例：统计如下样本数据中每个单词出现的次数。</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Spark	HBase</span></span><br><span class="line"><span class="attribute">Hive	Flink	Storm	Hadoop	HBase	Spark</span></span><br><span class="line"><span class="attribute">Flink</span></span><br><span class="line"><span class="attribute">HBase	Storm</span></span><br><span class="line"><span class="attribute">HBase	Hadoop	Hive	Flink</span></span><br><span class="line"><span class="attribute">HBase	Flink	Hive	Storm</span></span><br><span class="line"><span class="attribute">Hive	Flink	Hadoop</span></span><br><span class="line"><span class="attribute">HBase	Hive</span></span><br><span class="line"><span class="attribute">Hadoop	Spark	HBase	Storm</span></span><br><span class="line"><span class="attribute">HBase	Hadoop	Hive	Flink</span></span><br><span class="line"><span class="attribute">HBase	Flink	Hive	Storm</span></span><br><span class="line"><span class="attribute">Hive	Flink	Hadoop</span></span><br><span class="line"><span class="attribute">HBase	Hive</span></span><br></pre></td></tr></table></figure>

<p>为方便大家开发，我在项目源码中放置了一个工具类 <code>WordCountDataUtils</code>，用于模拟产生词频统计的样本，生成的文件支持输出到本地或者直接写到 HDFS 上。</p>
<blockquote>
<p>项目完整源码下载地址：<a target="_blank" rel="noopener" href="https://github.com/heibaiying/BigData-Notes/tree/master/code/Hadoop/hadoop-word-count">hadoop-word-count</a></p>
</blockquote>
<h3 id="项目依赖"><a href="#项目依赖" class="headerlink" title="项目依赖"></a>项目依赖</h3><p>想要进行 MapReduce 编程，需要导入 <code>hadoop-client</code> 依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="WordCountMapper"><a href="#WordCountMapper" class="headerlink" title="WordCountMapper"></a>WordCountMapper</h3><p>将每行数据按照指定分隔符进行拆分。这里需要注意在 MapReduce 中必须使用 Hadoop 定义的类型，因为 Hadoop 预定义的类型都是可序列化，可比较的，所有类型均实现了 <code>WritableComparable</code> 接口。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException,</span><br><span class="line">                                                                      InterruptedException &#123;</span><br><span class="line">        String[] words = value.toString().split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(word), <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>WordCountMapper</code> 对应下图的 Mapping 操作：</p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/fcf3ac016579c1fbb050d97309660aaa3b9550cc/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d636f64652d6d617070696e672e706e67"><img src="https://camo.githubusercontent.com/fcf3ac016579c1fbb050d97309660aaa3b9550cc/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d636f64652d6d617070696e672e706e67" alt="img"></a></p>
<p><code>WordCountMapper</code> 继承自 <code>Mappe</code> 类，这是一个泛型类，定义如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WordCountMapper <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Mapper</span>&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt; &#123;</span><br><span class="line">   ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>KEYIN</strong> : <code>mapping</code> 输入 key 的类型，即每行的偏移量 (每行第一个字符在整个文本中的位置)，<code>Long</code> 类型，对应 Hadoop 中的 <code>LongWritable</code> 类型；</li>
<li><strong>VALUEIN</strong> : <code>mapping</code> 输入 value 的类型，即每行数据；<code>String</code> 类型，对应 Hadoop 中 <code>Text</code> 类型；</li>
<li><strong>KEYOUT</strong> ：<code>mapping</code> 输出的 key 的类型，即每个单词；<code>String</code> 类型，对应 Hadoop 中 <code>Text</code> 类型；</li>
<li><strong>VALUEOUT</strong>：<code>mapping</code> 输出 value 的类型，即每个单词出现的次数；这里用 <code>int</code> 类型，对应 <code>IntWritable</code> 类型。</li>
</ul>
<h3 id="WordCountReducer"><a href="#WordCountReducer" class="headerlink" title="WordCountReducer"></a>WordCountReducer</h3><p>在 Reduce 中进行单词出现次数的统计：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException,</span><br><span class="line">                                                                                  InterruptedException &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            count += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如下图，<code>shuffling</code> 的输出是 reduce 的输入。这里的 key 是每个单词，values 是一个可迭代的数据类型，类似 <code>(1,1,1,...)</code>。</p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/bf6ad9c970812b1db6f6f86d12d783db75eaa9fb/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d636f64652d726564756365722e706e67"><img src="https://camo.githubusercontent.com/bf6ad9c970812b1db6f6f86d12d783db75eaa9fb/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d636f64652d726564756365722e706e67" alt="img"></a></p>
<h3 id="WordCountApp"><a href="#WordCountApp" class="headerlink" title="WordCountApp"></a>WordCountApp</h3><p>组装 MapReduce 作业，并提交到服务器运行，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 组装作业 并提交到集群运行</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountApp</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里为了直观显示参数 使用了硬编码，实际开发中可以通过外部传参</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">HDFS_URL</span> <span class="operator">=</span> <span class="string">&quot;hdfs://192.168.0.107:8020&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">HADOOP_USER_NAME</span> <span class="operator">=</span> <span class="string">&quot;root&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//  文件输入路径和输出路径由外部传参指定</span></span><br><span class="line">        <span class="keyword">if</span> (args.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Input and output paths are necessary!&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 需要指明 hadoop 用户名，否则在 HDFS 上创建目录时可能会抛出权限不足的异常</span></span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>, HADOOP_USER_NAME);</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 指明 HDFS 的地址</span></span><br><span class="line">        configuration.set(<span class="string">&quot;fs.defaultFS&quot;</span>, HDFS_URL);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建一个 Job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置运行的主类</span></span><br><span class="line">        job.setJarByClass(WordCountApp.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 Mapper 和 Reducer</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 Mapper 输出 key 和 value 的类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 Reducer 输出 key 和 value 的类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果输出目录已经存在，则必须先删除，否则重复运行程序时会抛出异常</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(HDFS_URL), configuration, HADOOP_USER_NAME);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">if</span> (fileSystem.exists(outputPath)) &#123;</span><br><span class="line">            fileSystem.delete(outputPath, <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置作业输入文件和输出文件的路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, outputPath);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将作业提交到群集并等待它完成，参数设置为 true 代表打印显示对应的进度</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关闭之前创建的 fileSystem</span></span><br><span class="line">        fileSystem.close();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据作业结果,终止当前运行的 Java 虚拟机,退出程序</span></span><br><span class="line">        System.exit(result ? <span class="number">0</span> : -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意的是：如果不设置 <code>Mapper</code> 操作的输出类型，则程序默认它和 <code>Reducer</code> 操作输出的类型相同。</p>
<h3 id="提交到服务器运行"><a href="#提交到服务器运行" class="headerlink" title="提交到服务器运行"></a>提交到服务器运行</h3><p>在实际开发中，可以在本机配置 hadoop 开发环境，直接在 IDE 中启动进行测试。这里主要介绍一下打包提交到服务器运行。由于本项目没有使用除 Hadoop 外的第三方依赖，直接打包即可：</p>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># mvn clean package</span></span><br></pre></td></tr></table></figure>

<p>使用以下命令提交作业：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/appjar/hadoop-word-count-<span class="number">1.0</span><span class="selector-class">.jar</span> \</span><br><span class="line">com<span class="selector-class">.heibaiying</span><span class="selector-class">.WordCountApp</span> \</span><br><span class="line">/wordcount/<span class="selector-tag">input</span><span class="selector-class">.txt</span> /wordcount/output/WordCountApp</span><br></pre></td></tr></table></figure>

<p>作业完成后查看 HDFS 上生成目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看目录</span></span><br><span class="line">hadoop fs -<span class="built_in">ls</span> /wordcount/output/WordCountApp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看统计结果</span></span><br><span class="line">hadoop fs -<span class="built_in">cat</span> /wordcount/output/WordCountApp/part-r-00000</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/cecb00eef3b951794fbf92b8308d8b6601faf5a0/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d776f7264636f756e746170702e706e67"><img src="https://camo.githubusercontent.com/cecb00eef3b951794fbf92b8308d8b6601faf5a0/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d776f7264636f756e746170702e706e67" alt="img"></a></p>
<h2 id="词频统计案例进阶之-Combiner"><a href="#词频统计案例进阶之-Combiner" class="headerlink" title="词频统计案例进阶之 Combiner"></a>词频统计案例进阶之 Combiner</h2><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>想要使用 <code>combiner</code> 功能只要在组装作业时，添加下面一行代码即可：</p>
<figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 Combiner</span></span><br><span class="line"><span class="keyword">job</span>.setCombinerClass(WordCountReducer.<span class="keyword">class</span>)<span class="comment">;</span></span><br></pre></td></tr></table></figure>

<h3 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h3><p>加入 <code>combiner</code> 后统计结果是不会有变化的，但是可以从打印的日志看出 <code>combiner</code> 的效果：</p>
<p>没有加入 <code>combiner</code> 的打印日志：</p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/e4849556db34d3a02b82b546af7296154920dfff/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d6e6f2d636f6d62696e65722e706e67"><img src="https://camo.githubusercontent.com/e4849556db34d3a02b82b546af7296154920dfff/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d6e6f2d636f6d62696e65722e706e67" alt="img"></a></p>
<p>加入 <code>combiner</code> 后的打印日志如下：</p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/17f20f481bc4bd01252bc3ccb3b2aceb7d0eca63/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d636f6d62696e65722e706e67"><img src="https://camo.githubusercontent.com/17f20f481bc4bd01252bc3ccb3b2aceb7d0eca63/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d636f6d62696e65722e706e67" alt="img"></a></p>
<p>这里我们只有一个输入文件并且小于 128M，所以只有一个 Map 进行处理。可以看到经过 combiner 后，records 由 <code>3519</code> 降低为 <code>6</code>(样本中单词种类就只有 6 种)，在这个用例中 combiner 就能极大地降低需要传输的数据量。</p>
<h2 id="词频统计案例进阶之-Partitioner"><a href="#词频统计案例进阶之-Partitioner" class="headerlink" title="词频统计案例进阶之 Partitioner"></a>词频统计案例进阶之 Partitioner</h2><h3 id="默认的-Partitioner"><a href="#默认的-Partitioner" class="headerlink" title="默认的 Partitioner"></a>默认的 Partitioner</h3><p>这里假设有个需求：将不同单词的统计结果输出到不同文件。这种需求实际上比较常见，比如统计产品的销量时，需要将结果按照产品种类进行拆分。要实现这个功能，就需要用到自定义 <code>Partitioner</code>。</p>
<p>这里先介绍下 MapReduce 默认的分类规则：在构建 job 时候，如果不指定，默认的使用的是 <code>HashPartitioner</code>：对 key 值进行哈希散列并对 <code>numReduceTasks</code> 取余。其实现如下：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="symbol">HashPartitioner</span>&lt;<span class="symbol">K, <span class="symbol">V</span></span>&gt; <span class="symbol">extends</span> <span class="symbol">Partitioner</span>&lt;<span class="symbol">K, <span class="symbol">V</span></span>&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="built_in">int</span> getPartition(K key, V value,</span><br><span class="line">                          <span class="built_in">int</span> numReduceTasks) &#123;</span><br><span class="line">    <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="自定义-Partitioner"><a href="#自定义-Partitioner" class="headerlink" title="自定义 Partitioner"></a>自定义 Partitioner</h3><p>这里我们继承 <code>Partitioner</code> 自定义分类规则，这里按照单词进行分类：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="symbol">CustomPartitioner</span> <span class="symbol">extends</span> <span class="symbol">Partitioner</span>&lt;<span class="symbol">Text, <span class="symbol">IntWritable</span></span>&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">int</span> getPartition(Text text, IntWritable <span class="built_in">int</span>Writable, <span class="built_in">int</span> numPartitions) &#123;</span><br><span class="line">        <span class="keyword">return</span> WordCountDataUtils.WORD_LIST.indexOf(text.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在构建 <code>job</code> 时候指定使用我们自己的分类规则，并设置 <code>reduce</code> 的个数：</p>
<figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置自定义分区规则</span></span><br><span class="line"><span class="keyword">job</span>.setPartitionerClass(CustomPartitioner.<span class="keyword">class</span>)<span class="comment">;</span></span><br><span class="line"><span class="comment">// 设置 reduce 个数</span></span><br><span class="line"><span class="keyword">job</span>.setNumReduceTasks(WordCountDataUtils.WORD_LIST.size())<span class="comment">;</span></span><br></pre></td></tr></table></figure>

<h3 id="执行结果-1"><a href="#执行结果-1" class="headerlink" title="执行结果"></a>执行结果</h3><p>执行结果如下，分别生成 6 个文件，每个文件中为对应单词的统计结果：</p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/202b1eb7065e18a513db5b2a50b22ab62a7d6692/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d776f7264636f756e74636f6d62696e6572706172746974696f6e2e706e67"><img src="https://camo.githubusercontent.com/202b1eb7065e18a513db5b2a50b22ab62a7d6692/68747470733a2f2f67697465652e636f6d2f68656962616979696e672f426967446174612d4e6f7465732f7261772f6d61737465722f70696374757265732f6861646f6f702d776f7264636f756e74636f6d62696e6572706172746974696f6e2e706e67" alt="img"></a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-MapReduce.md">分布式计算框架——MapReduce</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/23/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><span class="page-number current">24</span><a class="page-number" href="/page/25/">25</a><span class="space">&hellip;</span><a class="page-number" href="/page/47/">47</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/25/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备2021160229号 </a>
  </div>
  <div class="copyright">
    &copy; 2015 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">李狗蛋</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">3.5m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">53:28</span>
  </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/yiyirushi/" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  




<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
