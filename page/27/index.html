<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/uploads/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/uploads/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.ligoudan.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="天气不错哇，你看这大冰雹下得">
<meta property="og:type" content="website">
<meta property="og:title" content="LIGOUDAN">
<meta property="og:url" content="https://www.ligoudan.cn/page/27/index.html">
<meta property="og:site_name" content="LIGOUDAN">
<meta property="og:description" content="天气不错哇，你看这大冰雹下得">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="李狗蛋">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.ligoudan.cn/page/27/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/27/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LIGOUDAN</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LIGOUDAN</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">好好学习，天天向上</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">326</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">137</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">461</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="李狗蛋"
      src="/uploads/ligoudan.png">
  <p class="site-author-name" itemprop="name">李狗蛋</p>
  <div class="site-description" itemprop="description">天气不错哇，你看这大冰雹下得</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">461</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">137</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">326</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yiyirushi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yiyirushi" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yuanhaohoo@163.com" title="E-Mail → mailto:yuanhaohoo@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/21011e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/21011e/" class="post-title-link" itemprop="url">Kafka 运维</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-03 09:55:35" itemprop="dateCreated datePublished" datetime="2020-06-03T09:55:35+08:00">2020-06-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/" itemprop="url" rel="index"><span itemprop="name">分布式通信</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/MQ/" itemprop="url" rel="index"><span itemprop="name">MQ</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/MQ/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Kafka-运维"><a href="#Kafka-运维" class="headerlink" title="Kafka 运维"></a>Kafka 运维</h1><blockquote>
<p>环境要求：</p>
<ul>
<li>JDK8</li>
<li>ZooKeeper</li>
</ul>
</blockquote>
<h2 id="Kafka-单点部署"><a href="#Kafka-单点部署" class="headerlink" title="Kafka 单点部署"></a>Kafka 单点部署</h2><h3 id="下载解压"><a href="#下载解压" class="headerlink" title="下载解压"></a>下载解压</h3><p>进入官方下载地址：<a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads%EF%BC%8C%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%89%88%E6%9C%AC%E3%80%82">http://kafka.apache.org/downloads，选择合适版本。</a></p>
<p>解压到本地：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -xzf kafka_2.11-1.1.0.tgz</span><br><span class="line">cd kafka_2.11-1.1.0</span><br></pre></td></tr></table></figure>

<p>现在您已经在您的机器上下载了最新版本的 Kafka。</p>
<h3 id="启动服务器"><a href="#启动服务器" class="headerlink" title="启动服务器"></a>启动服务器</h3><p>由于 Kafka 依赖于 ZooKeeper，所以运行前需要先启动 ZooKeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/zookeeper-server-start.sh config/zookeeper.properties</span></span><br><span class="line">[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>然后，启动 Kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-server-start.sh config/server.properties</span></span><br><span class="line">[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)</span><br><span class="line">[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="停止服务器"><a href="#停止服务器" class="headerlink" title="停止服务器"></a>停止服务器</h3><p>执行所有操作后，可以使用以下命令停止服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-stop.sh config/server.properties</span><br></pre></td></tr></table></figure>

<h2 id="Kafka-集群部署"><a href="#Kafka-集群部署" class="headerlink" title="Kafka 集群部署"></a>Kafka 集群部署</h2><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>复制配置为多份（Windows 使用 copy 命令代理）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp config/server.properties config/server-1.properties</span><br><span class="line">cp config/server.properties config/server-2.properties</span><br></pre></td></tr></table></figure>

<p>修改配置：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">config/server-1.properties</span>:<span class="string"></span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">listeners</span>=<span class="string">PLAINTEXT://:9093</span></span><br><span class="line"><span class="attr">log.dir</span>=<span class="string">/tmp/kafka-logs-1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">config/server-2.properties</span>:<span class="string"></span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">2</span></span><br><span class="line"><span class="attr">listeners</span>=<span class="string">PLAINTEXT://:9094</span></span><br><span class="line"><span class="attr">log.dir</span>=<span class="string">/tmp/kafka-logs-2</span></span><br></pre></td></tr></table></figure>

<p>其中，broker.id 这个参数必须是唯一的。</p>
<p>端口故意配置的不一致，是为了可以在一台机器启动多个应用节点。</p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>根据这两份配置启动三个服务器节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-server-start.sh config/server.properties &amp;</span></span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-server-start.sh config/server-1.properties &amp;</span></span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-server-start.sh config/server-2.properties &amp;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>创建一个新的 Topic 使用 三个备份：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic</span><br></pre></td></tr></table></figure>

<p>查看主题：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic</span></span><br><span class="line">Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:</span><br><span class="line">    Topic: my-replicated-topic  Partition: 0    Leader: 1   Replicas: 1,2,0 Isr: 1,2,0</span><br></pre></td></tr></table></figure>

<ul>
<li>leader - 负责指定分区的所有读取和写入的节点。每个节点将成为随机选择的分区部分的领导者。</li>
<li>replicas - 是复制此分区日志的节点列表，无论它们是否为领导者，或者即使它们当前处于活动状态。</li>
<li>isr - 是“同步”复制品的集合。这是副本列表的子集，该列表当前处于活跃状态并且已经被领导者捕获。</li>
</ul>
<h2 id="Kafka-命令"><a href="#Kafka-命令" class="headerlink" title="Kafka 命令"></a>Kafka 命令</h2><h3 id="主题（Topic）"><a href="#主题（Topic）" class="headerlink" title="主题（Topic）"></a>主题（Topic）</h3><h4 id="创建-Topic"><a href="#创建-Topic" class="headerlink" title="创建 Topic"></a>创建 Topic</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic my-topic</span><br></pre></td></tr></table></figure>

<h4 id="查看-Topic-列表"><a href="#查看-Topic-列表" class="headerlink" title="查看 Topic 列表"></a>查看 Topic 列表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure>

<h4 id="添加-Partition"><a href="#添加-Partition" class="headerlink" title="添加 Partition"></a>添加 Partition</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --zookeeper localhost:2181 --alter --topic my-topic --partitions 16</span><br></pre></td></tr></table></figure>

<h4 id="删除-Topic"><a href="#删除-Topic" class="headerlink" title="删除 Topic"></a>删除 Topic</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --zookeeper localhost:2181 --delete --topic my-topic</span><br></pre></td></tr></table></figure>

<h4 id="查看-Topic-详细信息"><a href="#查看-Topic-详细信息" class="headerlink" title="查看 Topic 详细信息"></a>查看 Topic 详细信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --zookeeper localhost:2181/kafka-cluster --describe</span><br></pre></td></tr></table></figure>

<h4 id="查看备份分区"><a href="#查看备份分区" class="headerlink" title="查看备份分区"></a>查看备份分区</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --zookeeper localhost:2181/kafka-cluster --describe --under-replicated-partitions</span><br></pre></td></tr></table></figure>

<h3 id="生产者（Producers）"><a href="#生产者（Producers）" class="headerlink" title="生产者（Producers）"></a>生产者（Producers）</h3><h4 id="通过控制台输入生产消息"><a href="#通过控制台输入生产消息" class="headerlink" title="通过控制台输入生产消息"></a>通过控制台输入生产消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer --broker-list localhost:9092 --topic my-topic</span><br></pre></td></tr></table></figure>

<h4 id="通过文件输入生产消息"><a href="#通过文件输入生产消息" class="headerlink" title="通过文件输入生产消息"></a>通过文件输入生产消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer --broker-list localhost:9092 --topic test &lt; messages.txt</span><br></pre></td></tr></table></figure>

<h4 id="通过控制台输入-Avro-生产消息"><a href="#通过控制台输入-Avro-生产消息" class="headerlink" title="通过控制台输入 Avro 生产消息"></a>通过控制台输入 Avro 生产消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-avro-console-producer --broker-list localhost:9092 --topic my.Topic --property value.schema=&#x27;&#123;&quot;type&quot;:&quot;record&quot;,&quot;name&quot;:&quot;myrecord&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;f1&quot;,&quot;type&quot;:&quot;string&quot;&#125;]&#125;&#x27; --property schema.registry.url=http://localhost:8081</span><br></pre></td></tr></table></figure>

<p>然后，可以选择输入部分 json key：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span> <span class="attr">&quot;f1&quot;</span><span class="punctuation">:</span> <span class="string">&quot;value1&quot;</span> <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="生成消息性能测试"><a href="#生成消息性能测试" class="headerlink" title="生成消息性能测试"></a>生成消息性能测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-producer-perf-test --topic position-reports --throughput 10000 --record-size 300 --num-records 20000 --producer-props bootstrap.servers=&quot;localhost:9092&quot;</span><br></pre></td></tr></table></figure>

<h3 id="消费者（Consumers）"><a href="#消费者（Consumers）" class="headerlink" title="消费者（Consumers）"></a>消费者（Consumers）</h3><h4 id="消费所有未消费的消息"><a href="#消费所有未消费的消息" class="headerlink" title="消费所有未消费的消息"></a>消费所有未消费的消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --topic my-topic --from-beginning</span><br></pre></td></tr></table></figure>

<h4 id="消费一条消息"><a href="#消费一条消息" class="headerlink" title="消费一条消息"></a>消费一条消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --topic my-topic  --max-messages 1</span><br></pre></td></tr></table></figure>

<h4 id="从指定的-offset-消费一条消息"><a href="#从指定的-offset-消费一条消息" class="headerlink" title="从指定的 offset 消费一条消息"></a>从指定的 offset 消费一条消息</h4><p>从指定的 offset <code>__consumer_offsets</code> 消费一条消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --topic __consumer_offsets --formatter &#x27;kafka.coordinator.GroupMetadataManager$OffsetsMessageFormatter&#x27; --max-messages 1</span><br></pre></td></tr></table></figure>

<h4 id="从指定-Group-消费消息"><a href="#从指定-Group-消费消息" class="headerlink" title="从指定 Group 消费消息"></a>从指定 Group 消费消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer --topic my-topic --new-consumer --bootstrap-server localhost:9092 --consumer-property group.id=my-group</span><br></pre></td></tr></table></figure>

<h4 id="消费-avro-消息"><a href="#消费-avro-消息" class="headerlink" title="消费 avro 消息"></a>消费 avro 消息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-avro-console-consumer --topic position-reports --new-consumer --bootstrap-server localhost:9092 --from-beginning --property schema.registry.url=localhost:8081 --max-messages 10</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-avro-console-consumer --topic position-reports --new-consumer --bootstrap-server localhost:9092 --from-beginning --property schema.registry.url=localhost:8081</span><br></pre></td></tr></table></figure>

<h4 id="查看消费者-Group-列表"><a href="#查看消费者-Group-列表" class="headerlink" title="查看消费者 Group 列表"></a>查看消费者 Group 列表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-consumer-groups --new-consumer --list --bootstrap-server localhost:9092</span><br></pre></td></tr></table></figure>

<h4 id="查看消费者-Group-详细信息"><a href="#查看消费者-Group-详细信息" class="headerlink" title="查看消费者 Group 详细信息"></a>查看消费者 Group 详细信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group testgroup</span><br></pre></td></tr></table></figure>

<h3 id="配置（Config）"><a href="#配置（Config）" class="headerlink" title="配置（Config）"></a>配置（Config）</h3><h4 id="设置-Topic-的保留时间"><a href="#设置-Topic-的保留时间" class="headerlink" title="设置 Topic 的保留时间"></a>设置 Topic 的保留时间</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-configs --zookeeper localhost:2181 --alter --entity-type topics --entity-name my-topic --add-config retention.ms=3600000</span><br></pre></td></tr></table></figure>

<h4 id="查看-Topic-的所有配置"><a href="#查看-Topic-的所有配置" class="headerlink" title="查看 Topic 的所有配置"></a>查看 Topic 的所有配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-configs --zookeeper localhost:2181 --describe --entity-type topics --entity-name my-topic</span><br></pre></td></tr></table></figure>

<h4 id="修改-Topic-的配置"><a href="#修改-Topic-的配置" class="headerlink" title="修改 Topic 的配置"></a>修改 Topic 的配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-configs --zookeeper localhost:2181 --alter --entity-type topics --entity-name my-topic --delete-config retention.ms</span><br></pre></td></tr></table></figure>

<h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><h4 id="查看指定-Topic-的-ACL"><a href="#查看指定-Topic-的-ACL" class="headerlink" title="查看指定 Topic 的 ACL"></a>查看指定 Topic 的 ACL</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --list --topic topicA</span><br></pre></td></tr></table></figure>

<h4 id="添加-ACL"><a href="#添加-ACL" class="headerlink" title="添加 ACL"></a>添加 ACL</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --consumer --topic topicA --group groupA</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --producer --topic topicA</span><br></pre></td></tr></table></figure>

<h3 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zookeeper-shell localhost:2182 ls /</span><br></pre></td></tr></table></figure>

<h2 id="Kafka-工具"><a href="#Kafka-工具" class="headerlink" title="Kafka 工具"></a>Kafka 工具</h2><ul>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/yahoo/kafka-manager">kafka-manager</a></strong></li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/quantifind/KafkaOffsetMonitor">KafkaOffsetMonitor</a></strong></li>
</ul>
<h2 id="Kafka-核心配置"><a href="#Kafka-核心配置" class="headerlink" title="Kafka 核心配置"></a>Kafka 核心配置</h2><h3 id="Broker-级别配置"><a href="#Broker-级别配置" class="headerlink" title="Broker 级别配置"></a>Broker 级别配置</h3><h4 id="存储配置"><a href="#存储配置" class="headerlink" title="存储配置"></a>存储配置</h4><p>首先 Broker 是需要配置存储信息的，即 Broker 使用哪些磁盘。那么针对存储信息的重要参数有以下这么几个：</p>
<ul>
<li><code>log.dirs</code>：指定了 Broker 需要使用的若干个文件目录路径。这个参数是没有默认值的，必须由使用者亲自指定。</li>
<li><code>log.dir</code>：注意这是 dir，结尾没有 s，说明它只能表示单个路径，它是补充上一个参数用的。</li>
</ul>
<p><code>log.dirs</code> 具体格式是一个 CSV 格式，也就是用逗号分隔的多个路径，比如<code>/home/kafka1,/home/kafka2,/home/kafka3</code>这样。如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上。这样做有两个好处：</p>
<ul>
<li>提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。</li>
<li>能够实现故障转移：即 Failover。这是 Kafka 1.1 版本新引入的强大功能。要知道在以前，只要 Kafka Broker 使用的任何一块磁盘挂掉了，整个 Broker 进程都会关闭。但是自 1.1 开始，这种情况被修正了，坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且 Broker 还能正常工作。</li>
</ul>
<h4 id="zookeeper-配置"><a href="#zookeeper-配置" class="headerlink" title="zookeeper 配置"></a>zookeeper 配置</h4><p>Kafka 与 ZooKeeper 相关的最重要的参数当属 <code>zookeeper.connect</code>。这也是一个 CSV 格式的参数，比如我可以指定它的值为<code>zk1:2181,zk2:2181,zk3:2181</code>。2181 是 ZooKeeper 的默认端口。</p>
<p>现在问题来了，如果我让多个 Kafka 集群使用同一套 ZooKeeper 集群，那么这个参数应该怎么设置呢？这时候 chroot 就派上用场了。这个 chroot 是 ZooKeeper 的概念，类似于别名。</p>
<p>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的<code>zookeeper.connect</code>参数可以这样指定：<code>zk1:2181,zk2:2181,zk3:2181/kafka1</code>和<code>zk1:2181,zk2:2181,zk3:2181/kafka2</code>。切记 chroot 只需要写一次，而且是加到最后的。我经常碰到有人这样指定：<code>zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3</code>，这样的格式是不对的。</p>
<h4 id="Broker-连接配置"><a href="#Broker-连接配置" class="headerlink" title="Broker 连接配置"></a>Broker 连接配置</h4><ul>
<li><code>listeners</code>：告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。</li>
<li><code>advertised.listeners</code>：和 listeners 相比多了个 advertised。Advertised 的含义表示宣称的、公布的，就是说这组监听器是 Broker 用于对外发布的。</li>
<li><code>host.name/port</code>：列出这两个参数就是想说你把它们忘掉吧，压根不要为它们指定值，毕竟都是过期的参数了。</li>
</ul>
<p>我们具体说说监听器的概念，从构成上来说，它是若干个逗号分隔的三元组，每个三元组的格式为<code>&lt;协议名称，主机名，端口号&gt;</code>。这里的协议名称可能是标准的名字，比如 PLAINTEXT 表示明文传输、SSL 表示使用 SSL 或 TLS 加密传输等；也可能是你自己定义的协议名字，比如<code>CONTROLLER: //localhost:9092</code>。</p>
<p><strong>最好全部使用主机名，即 Broker 端和 Client 端应用配置中全部填写主机名。</strong></p>
<h4 id="Topic-管理"><a href="#Topic-管理" class="headerlink" title="Topic 管理"></a>Topic 管理</h4><ul>
<li><code>auto.create.topics.enable</code>：是否允许自动创建 Topic。一般设为 false，由运维把控创建 Topic。</li>
<li><code>unclean.leader.election.enable</code>：是否允许 Unclean Leader 选举。</li>
<li><code>auto.leader.rebalance.enable</code>：是否允许定期进行 Leader 选举。</li>
</ul>
<p>第二个参数<code>unclean.leader.election.enable</code>是关闭 Unclean Leader 选举的。何谓 Unclean？还记得 Kafka 有多个副本这件事吗？每个分区都有多个副本来提供高可用。在这些副本中只能有一个副本对外提供服务，即所谓的 Leader 副本。</p>
<p>那么问题来了，这些副本都有资格竞争 Leader 吗？显然不是，只有保存数据比较多的那些副本才有资格竞选，那些落后进度太多的副本没资格做这件事。</p>
<p>好了，现在出现这种情况了：假设那些保存数据比较多的副本都挂了怎么办？我们还要不要进行 Leader 选举了？此时这个参数就派上用场了。</p>
<p>如果设置成 false，那么就坚持之前的原则，坚决不能让那些落后太多的副本竞选 Leader。这样做的后果是这个分区就不可用了，因为没有 Leader 了。反之如果是 true，那么 Kafka 允许你从那些“跑得慢”的副本中选一个出来当 Leader。这样做的后果是数据有可能就丢失了，因为这些副本保存的数据本来就不全，当了 Leader 之后它本人就变得膨胀了，认为自己的数据才是权威的。</p>
<p>这个参数在最新版的 Kafka 中默认就是 false，本来不需要我特意提的，但是比较搞笑的是社区对这个参数的默认值来来回回改了好几版了，鉴于我不知道你用的是哪个版本的 Kafka，所以建议你还是显式地把它设置成 false 吧。</p>
<p>第三个参数<code>auto.leader.rebalance.enable</code>的影响貌似没什么人提，但其实对生产环境影响非常大。设置它的值为 true 表示允许 Kafka 定期地对一些 Topic 分区进行 Leader 重选举，当然这个重选举不是无脑进行的，它要满足一定的条件才会发生。严格来说它与上一个参数中 Leader 选举的最大不同在于，它不是选 Leader，而是换 Leader！比如 Leader A 一直表现得很好，但若<code>auto.leader.rebalance.enable=true</code>，那么有可能一段时间后 Leader A 就要被强行卸任换成 Leader B。</p>
<p>你要知道换一次 Leader 代价很高的，原本向 A 发送请求的所有客户端都要切换成向 B 发送请求，而且这种换 Leader 本质上没有任何性能收益，因此我建议你在生产环境中把这个参数设置成 false。</p>
<h4 id="数据留存"><a href="#数据留存" class="headerlink" title="数据留存"></a>数据留存</h4><ul>
<li><code>log.retention.&#123;hour|minutes|ms&#125;</code>：都是控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hour 最低。通常情况下我们还是设置 hour 级别的多一些，比如<code>log.retention.hour=168</code>表示默认保存 7 天的数据，自动删除 7 天前的数据。很多公司把 Kafka 当做存储来使用，那么这个值就要相应地调大。</li>
<li><code>log.retention.bytes</code>：这是指定 Broker 为消息保存的总磁盘容量大小。这个值默认是 -1，表明你想在这台 Broker 上保存多少数据都可以，至少在容量方面 Broker 绝对为你开绿灯，不会做任何阻拦。这个参数真正发挥作用的场景其实是在云上构建多租户的 Kafka 集群：设想你要做一个云上的 Kafka 服务，每个租户只能使用 100GB 的磁盘空间，为了避免有个“恶意”租户使用过多的磁盘空间，设置这个参数就显得至关重要了。</li>
<li><code>message.max.bytes</code>：控制 Broker 能够接收的最大消息大小。默认的 1000012 太少了，还不到 1MB。实际场景中突破 1MB 的消息都是屡见不鲜的，因此在线上环境中设置一个比较大的值还是比较保险的做法。毕竟它只是一个标尺而已，仅仅衡量 Broker 能够处理的最大消息大小，即使设置大一点也不会耗费什么磁盘空间的。</li>
</ul>
<h3 id="Topic-级别配置"><a href="#Topic-级别配置" class="headerlink" title="Topic 级别配置"></a>Topic 级别配置</h3><ul>
<li><code>retention.ms</code>：规定了该 Topic 消息被保存的时长。默认是 7 天，即该 Topic 只保存最近 7 天的消息。一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。</li>
<li><code>retention.bytes</code>：规定了要为该 Topic 预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的 Kafka 集群中会有用武之地。当前默认值是 -1，表示可以无限使用磁盘空间。</li>
</ul>
<h3 id="操作系统参数"><a href="#操作系统参数" class="headerlink" title="操作系统参数"></a>操作系统参数</h3><ul>
<li>文件描述符限制</li>
<li>文件系统类型</li>
<li>Swappiness</li>
<li>提交时间</li>
</ul>
<p>文件描述符系统资源并不像我们想象的那样昂贵，你不用太担心调大此值会有什么不利的影响。通常情况下将它设置成一个超大的值是合理的做法，比如<code>ulimit -n 1000000</code>。其实设置这个参数一点都不重要，但不设置的话后果很严重，比如你会经常看到“Too many open files”的错误。</p>
<p>其次是文件系统类型的选择。这里所说的文件系统指的是如 ext3、ext4 或 XFS 这样的日志型文件系统。根据官网的测试报告，XFS 的性能要强于 ext4，所以生产环境最好还是使用 XFS。对了，最近有个 Kafka 使用 ZFS 的<a target="_blank" rel="noopener" href="https://www.confluent.io/kafka-summit-sf18/kafka-on-zfs">数据报告</a>，貌似性能更加强劲，有条件的话不妨一试。</p>
<p>第三是 swap 的调优。网上很多文章都提到设置其为 0，将 swap 完全禁掉以防止 Kafka 进程使用 swap 空间。我个人反倒觉得还是不要设置成 0 比较好，我们可以设置成一个较小的值。为什么呢？因为一旦设置成 0，当物理内存耗尽时，操作系统会触发 OOM killer 这个组件，它会随机挑选一个进程然后 kill 掉，即根本不给用户任何的预警。但如果设置成一个比较小的值，当开始使用 swap 空间时，你至少能够观测到 Broker 性能开始出现急剧下降，从而给你进一步调优和诊断问题的时间。基于这个考虑，我个人建议将 swappniess 配置成一个接近 0 但不为 0 的值，比如 1。</p>
<p>最后是提交时间或者说是 Flush 落盘时间。向 Kafka 发送数据并不是真要等数据被写入磁盘才会认为成功，而是只要数据被写入到操作系统的页缓存（Page Cache）上就可以了，随后操作系统根据 LRU 算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。这个定期就是由提交时间来确定的，默认是 5 秒。一般情况下我们会认为这个时间太频繁了，可以适当地增加提交间隔来降低物理磁盘的写操作。当然你可能会有这样的疑问：如果在页缓存中的数据在写入到磁盘前机器宕机了，那岂不是数据就丢失了。的确，这种情况数据确实就丢失了，但鉴于 Kafka 在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。</p>
<h2 id="Kafka-集群规划"><a href="#Kafka-集群规划" class="headerlink" title="Kafka 集群规划"></a>Kafka 集群规划</h2><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><p>部署生产环境的 Kafka，强烈建议操作系统选用 Linux。</p>
<p><strong>在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的快速数据传输特性。</strong></p>
<p><strong>Windows 平台上部署 Kafka 只适合于个人测试或用于功能验证，千万不要应用于生产环境。</strong></p>
<h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><p>Kafka 集群部署选择普通的机械磁盘还是固态硬盘？前者成本低且容量大，但易损坏；后者性能优势大，不过单价高。</p>
<p>结论是：<strong>使用普通机械硬盘即可</strong>。</p>
<p>Kafka 采用顺序读写操作，一定程度上规避了机械磁盘最大的劣势，即随机读写操作慢。从这一点上来说，使用 SSD 似乎并没有太大的性能优势，毕竟从性价比上来说，机械磁盘物美价廉，而它因易损坏而造成的可靠性差等缺陷，又由 Kafka 在软件层面提供机制来保证，故使用普通机械磁盘是很划算的。</p>
<h3 id="带宽"><a href="#带宽" class="headerlink" title="带宽"></a>带宽</h3><p>大部分公司使用普通的以太网络，千兆网络（1Gbps）应该是网络的标准配置。</p>
<p>通常情况下你只能假设 Kafka 会用到 70% 的带宽资源，因为总要为其他应用或进程留一些资源。此外，通常要再额外预留出 2&#x2F;3 的资源，因为不能让带宽资源总是保持在峰值。</p>
<p>基于以上原因，一个 Kafka 集群数量的大致推算公式如下：</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka 机器数 <span class="operator">=</span> 单位时间需要处理的总数据量 / 单机所占用带宽</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><strong>官方</strong><ul>
<li><a target="_blank" rel="noopener" href="http://kafka.apache.org/">Kafka 官网</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/apache/kafka">Kafka Github</a></li>
<li><a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/">Kafka 官方文档</a></li>
</ul>
</li>
<li><strong>书籍</strong><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/12270295.html">《Kafka 权威指南》</a></li>
</ul>
</li>
<li><strong>教程</strong><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/apachecn/kafka-doc-zh">Kafka 中文文档</a></li>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100029201">Kafka 核心技术与实战</a></li>
</ul>
</li>
<li><strong>文章</strong><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/lensesio/kafka-cheat-sheet">kafka-cheat-sheet</a></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/f9ff40/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/f9ff40/" class="post-title-link" itemprop="url">ZooKeeper原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-02 22:28:54" itemprop="dateCreated datePublished" datetime="2020-06-02T22:28:54+08:00">2020-06-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C/" itemprop="url" rel="index"><span itemprop="name">分布式协同</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C/ZooKeeper/" itemprop="url" rel="index"><span itemprop="name">ZooKeeper</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ZooKeeper-原理"><a href="#ZooKeeper-原理" class="headerlink" title="ZooKeeper 原理"></a>ZooKeeper 原理</h1><blockquote>
<p>ZooKeeper 是 Apache 的顶级项目。<strong>ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议</strong>。</p>
<p>ZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来<strong>维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理</strong>。</p>
<p>很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。</p>
<p>ZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。</p>
</blockquote>
<h2 id="ZooKeeper-简介"><a href="#ZooKeeper-简介" class="headerlink" title="ZooKeeper 简介"></a>ZooKeeper 简介</h2><h3 id="ZooKeeper-是什么"><a href="#ZooKeeper-是什么" class="headerlink" title="ZooKeeper 是什么"></a>ZooKeeper 是什么</h3><p>ZooKeeper 是 Apache 的顶级项目。<strong>ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议</strong>。</p>
<p>ZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来<strong>维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理</strong>。</p>
<p>很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。</p>
<h3 id="ZooKeeper-的应用场景"><a href="#ZooKeeper-的应用场景" class="headerlink" title="ZooKeeper 的应用场景"></a>ZooKeeper 的应用场景</h3><ul>
<li>配置管理<ul>
<li>集群节点可以通过中心源获取启动配置</li>
<li>更简单的部署</li>
</ul>
</li>
<li>分布式集群管理<ul>
<li>节点加入&#x2F;离开</li>
<li>节点的实时状态</li>
</ul>
</li>
<li>命名服务，如：DNS</li>
<li>分布式同步：如锁、栅栏、队列</li>
<li>分布式系统的选主</li>
<li>中心化和高可靠的数据注册</li>
</ul>
<h3 id="ZooKeeper-的特性"><a href="#ZooKeeper-的特性" class="headerlink" title="ZooKeeper 的特性"></a>ZooKeeper 的特性</h3><p>ZooKeeper 具有以下特性：</p>
<ul>
<li><strong>顺序一致性</strong>：所有客户端看到的服务端数据模型都是一致的；从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：<a href="#%E5%8E%9F%E5%AD%90%E5%B9%BF%E6%92%AD">原子广播</a></li>
<li><strong>原子性</strong> - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：<a href="#%E4%BA%8B%E5%8A%A1">事务</a></li>
<li><strong>单一视图</strong> - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。</li>
<li><strong>高性能</strong> - ZooKeeper 将<strong>数据全量存储在内存中</strong>，所以其性能很高。需要注意的是：由于 <strong>ZooKeeper 的所有更新和删除都是基于事务的</strong>，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，<strong>如果写操作频繁，性能会大大下滑</strong>。</li>
<li><strong>高可用</strong> - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：<a href="#%E9%80%89%E4%B8%BE-Leader">选举 Leader</a></li>
</ul>
<h3 id="ZooKeeper-的设计目标"><a href="#ZooKeeper-的设计目标" class="headerlink" title="ZooKeeper 的设计目标"></a>ZooKeeper 的设计目标</h3><ul>
<li>简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 **<code>znode</code>**。</li>
<li>可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。</li>
<li>顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。</li>
<li>高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。</li>
</ul>
<h2 id="ZooKeeper-核心概念"><a href="#ZooKeeper-核心概念" class="headerlink" title="ZooKeeper 核心概念"></a>ZooKeeper 核心概念</h2><h3 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h3><p>Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。</p>
<p>客户端只会连接一个 ZooKeeper 服务器节点，并维持 TCP 连接。</p>
<h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><p><strong>ZooKeeper 的数据模型是一个树形结构的文件系统</strong>。</p>
<p>树中的节点被称为 <strong><code>znode</code><strong>，其中根节点为 <code>/</code>，每个节点上都会保存自己的数据和节点信息。znode 可以用于存储数据，并且有一个与之相关联的 ACL（详情可见 <a href="#ACL">ACL</a>）。ZooKeeper 的设计目标是实现协调服务，而不是真的作为一个文件存储，因此 znode 存储数据的</strong>大小被限制在 1MB 以内</strong>。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_1.png" alt="img"></p>
<p><strong>ZooKeeper 的数据访问具有原子性</strong>。其读写操作都是要么全部成功，要么全部失败。</p>
<p>znode 通过路径被引用。<strong>znode 节点路径必须是绝对路径</strong>。</p>
<p>znode 有两种类型：</p>
<ul>
<li><strong>临时的（ <code>EPHEMERAL</code> ）</strong> - 户端会话结束时，ZooKeeper 就会删除临时的 znode。不允许有子节点。</li>
<li><strong>持久的（<code>PERSISTENT</code> ）</strong> - 除非客户端主动执行删除操作，否则 ZooKeeper 不会删除持久的 znode。</li>
</ul>
<h3 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h3><p>znode 上有一个<strong>顺序标志（ <code>SEQUENTIAL</code> ）</strong>。如果在创建 znode 时，设置了<strong>顺序标志（ <code>SEQUENTIAL</code> ）</strong>，那么 ZooKeeper 会使用计数器为 znode 添加一个单调递增的数值，即 <code>zxid</code>。ZooKeeper 正是利用 zxid 实现了严格的顺序访问控制能力。</p>
<p>每个 znode 节点在存储数据的同时，都会维护一个叫做 <code>Stat</code> 的数据结构，里面存储了关于该节点的全部状态信息。如下：</p>
<table>
<thead>
<tr>
<th><strong>状态属性</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>czxid</td>
<td>数据节点创建时的事务 ID</td>
</tr>
<tr>
<td>ctime</td>
<td>数据节点创建时的时间</td>
</tr>
<tr>
<td>mzxid</td>
<td>数据节点最后一次更新时的事务 ID</td>
</tr>
<tr>
<td><code>mtime</code></td>
<td>数据节点最后一次更新时的时间</td>
</tr>
<tr>
<td>pzxid</td>
<td>数据节点的子节点最后一次被修改时的事务 ID</td>
</tr>
<tr>
<td>cversion</td>
<td>子节点的更改次数</td>
</tr>
<tr>
<td>version</td>
<td>节点数据的更改次数</td>
</tr>
<tr>
<td>aversion</td>
<td>节点的 ACL 的更改次数</td>
</tr>
<tr>
<td>ephemeralOwner</td>
<td>如果节点是临时节点，则表示创建该节点的会话的 SessionID；如果节点是持久节点，则该属性值为 0</td>
</tr>
<tr>
<td>dataLength</td>
<td>数据内容的长度</td>
</tr>
<tr>
<td>numChildren</td>
<td>数据节点当前的子节点个数</td>
</tr>
</tbody></table>
<h3 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h3><p>Zookeeper 集群是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。此外，每个服务器节点承担如下三种角色中的一种：</p>
<ul>
<li><strong>Leader</strong> - 它负责 <strong>发起并维护与各 Follwer 及 Observer 间的心跳。所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器</strong>。一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader。</li>
<li><strong>Follower</strong> - 它会<strong>响应 Leader 的心跳。Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票</strong>。一个 Zookeeper 集群可能同时存在多个 Follower。</li>
<li><strong>Observer</strong> - 角色与 Follower 类似，但是无投票权。</li>
</ul>
<p>客户端可以从任意 ZooKeeper 服务器节点读取数据，但只能通过 Leader 服务写数据并需要半数以上 Follower 的 ACK，才算写入成功。记住这个重要的知识点，下文会详细讲述。</p>
<h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><p><strong>ZooKeeper 采用 ACL（Access Control Lists）策略来进行权限控制</strong>。</p>
<p>每个 znode 创建时都会带有一个 ACL 列表，用于决定谁可以对它执行何种操作。</p>
<p>ACL 依赖于 ZooKeeper 的客户端认证机制。ZooKeeper 提供了以下几种认证方式：</p>
<ul>
<li><strong>digest</strong> - 用户名和密码 来识别客户端</li>
<li><strong>sasl</strong> - 通过 kerberos 来识别客户端</li>
<li><strong>ip</strong> - 通过 IP 来识别客户端</li>
</ul>
<p>ZooKeeper 定义了如下五种权限：</p>
<ul>
<li><strong>CREATE</strong> - 允许创建子节点；</li>
<li><strong>READ</strong> - 允许从节点获取数据并列出其子节点；</li>
<li><strong>WRITE</strong> - 允许为节点设置数据；</li>
<li><strong>DELETE</strong> - 允许删除子节点；</li>
<li><strong>ADMIN</strong> - 允许为节点设置权限。</li>
</ul>
<h2 id="ZooKeeper-工作原理"><a href="#ZooKeeper-工作原理" class="headerlink" title="ZooKeeper 工作原理"></a>ZooKeeper 工作原理</h2><h3 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h3><p><strong>Leader&#x2F;Follower&#x2F;Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可</strong>。</p>
<p>由于处理读请求不需要服务器之间的交互，<strong>Follower&#x2F;Observer 越多，整体系统的读请求吞吐量越大</strong>，也即读性能越好。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_3.png" alt="img"></p>
<h3 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h3><p>所有的写请求实际上都要交给 Leader 处理。Leader 将写请求以事务形式发给所有 Follower 并等待 ACK，一旦收到半数以上 Follower 的 ACK，即认为写操作成功。</p>
<h4 id="写-Leader"><a href="#写-Leader" class="headerlink" title="写 Leader"></a>写 Leader</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_4.png" alt="img"></p>
<p>由上图可见，通过 Leader 进行写操作，主要分为五步：</p>
<ol>
<li>客户端向 Leader 发起写请求</li>
<li>Leader 将写请求以事务 Proposal 的形式发给所有 Follower 并等待 ACK</li>
<li>Follower 收到 Leader 的事务 Proposal 后返回 ACK</li>
<li>Leader 得到过半数的 ACK（Leader 对自己默认有一个 ACK）后向所有的 Follower 和 Observer 发送 Commmit</li>
<li>Leader 将处理结果返回给客户端</li>
</ol>
<blockquote>
<p>注意</p>
<ul>
<li>Leader 不需要得到 Observer 的 ACK，即 Observer 无投票权。</li>
<li>Leader 不需要得到所有 Follower 的 ACK，只要收到过半的 ACK 即可，同时 Leader 本身对自己有一个 ACK。上图中有 4 个 Follower，只需其中两个返回 ACK 即可，因为 $$(2+1) &#x2F; (4+1) &gt; 1&#x2F;2$$ 。</li>
<li>Observer 虽然无投票权，但仍须同步 Leader 的数据从而在处理读请求时可以返回尽可能新的数据。</li>
</ul>
</blockquote>
<h4 id="写-Follower-Observer"><a href="#写-Follower-Observer" class="headerlink" title="写 Follower&#x2F;Observer"></a>写 Follower&#x2F;Observer</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_5.png" alt="img"></p>
<ul>
<li>Follower&#x2F;Observer 均可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理。</li>
<li>除了多了一步请求转发，其它流程与直接写 Leader 无任何区别。</li>
</ul>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>对于来自客户端的每个更新请求，ZooKeeper 具备严格的顺序访问控制能力。</p>
<p><strong>为了保证事务的顺序一致性，ZooKeeper 采用了递增的事务 id 号（zxid）来标识事务</strong>。</p>
<p><strong>Leader 服务会为每一个 Follower 服务器分配一个单独的队列，然后将事务 Proposal 依次放入队列中，并根据 FIFO(先进先出) 的策略进行消息发送</strong>。Follower 服务在接收到 Proposal 后，会将其以事务日志的形式写入本地磁盘中，并在写入成功后反馈给 Leader 一个 Ack 响应。<strong>当 Leader 接收到超过半数 Follower 的 Ack 响应后，就会广播一个 Commit 消息给所有的 Follower 以通知其进行事务提交</strong>，之后 Leader 自身也会完成对事务的提交。而每一个 Follower 则在接收到 Commit 消息后，完成事务的提交。</p>
<p>所有的提议（**<code>proposal</code>**）都在被提出的时候加上了 zxid。zxid 是一个 64 位的数字，它的高 32 位是 <strong><code>epoch</code></strong> 用来标识 Leader 关系是否改变，每次一个 Leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增计数。</p>
<p>详细过程如下：</p>
<ol>
<li>Leader 等待 Server 连接；</li>
<li>Follower 连接 Leader，将最大的 zxid 发送给 Leader；</li>
<li>Leader 根据 Follower 的 zxid 确定同步点；</li>
<li>完成同步后通知 follower 已经成为 uptodate 状态；</li>
<li>Follower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了。</li>
</ol>
<h3 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h3><p><strong>ZooKeeper 允许客户端监听它关心的 znode，当 znode 状态发生变化（数据变化、子节点增减变化）时，ZooKeeper 服务会通知客户端</strong>。</p>
<p>客户端和服务端保持连接一般有两种形式：</p>
<ul>
<li><strong>客户端向服务端不断轮询</strong></li>
<li><strong>服务端向客户端推送状态</strong></li>
</ul>
<p>Zookeeper 的选择是服务端主动推送状态，也就是观察机制（ <code>Watch</code> ）。</p>
<p>ZooKeeper 的观察机制允许用户在指定节点上针对感兴趣的事件注册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。</p>
<ul>
<li>监听器实时触发</li>
<li>监听器总是有序的</li>
<li>创建新的 znode 数据前，客户端就能收到监听事件。</li>
</ul>
<p>客户端使用 <code>getData</code> 等接口获取 znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">byte</span>[] getData(<span class="keyword">final</span> String path, Watcher watcher, Stat stat)</span><br></pre></td></tr></table></figure>

<p>从这个方法中传入的 <code>Watcher</code> 对象实现了相应的 <code>process</code> 方法，每次对应节点出现了状态的改变，<code>WatchManager</code> 都会通过以下的方式调用传入 <code>Watcher</code> 的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Set&lt;Watcher&gt; <span class="title function_">triggerWatch</span><span class="params">(String path, EventType type, Set&lt;Watcher&gt; supress)</span> &#123;</span><br><span class="line">    <span class="type">WatchedEvent</span> <span class="variable">e</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WatchedEvent</span>(type, KeeperState.SyncConnected, path);</span><br><span class="line">    Set&lt;Watcher&gt; watchers;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">        watchers = watchTable.remove(path);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (Watcher w : watchers) &#123;</span><br><span class="line">        w.process(e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> watchers;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Zookeeper 中的所有数据其实都是由一个名为 <code>DataTree</code> 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 <code>Watcher</code> 注册一个回调函数，而写请求就可能会触发相应的回调，由 <code>WatchManager</code> 通知客户端数据的变化。</p>
<p>通知机制的实现其实还是比较简单的，通过读请求设置 <code>Watcher</code> 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。</p>
<h3 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h3><p><strong>ZooKeeper 客户端通过 TCP 长连接连接到 ZooKeeper 服务集群</strong>。<strong>会话 (Session) 从第一次连接开始就已经建立，之后通过心跳检测机制来保持有效的会话状态</strong>。通过这个连接，客户端可以发送请求并接收响应，同时也可以接收到 Watch 事件的通知。</p>
<p>每个 ZooKeeper 客户端配置中都配置了 ZooKeeper 服务器集群列表。启动时，客户端会遍历列表去尝试建立连接。如果失败，它会尝试连接下一个服务器，依次类推。</p>
<p>一旦一台客户端与一台服务器建立连接，这台服务器会为这个客户端创建一个新的会话。<strong>每个会话都会有一个超时时间，若服务器在超时时间内没有收到任何请求，则相应会话被视为过期</strong>。一旦会话过期，就无法再重新打开，且任何与该会话相关的临时 znode 都会被删除。</p>
<p>通常来说，会话应该长期存在，而这需要由客户端来保证。客户端可以通过心跳方式（ping）来保持会话不过期。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200602182239.png" alt="img"></p>
<p>ZooKeeper 的会话具有四个属性：</p>
<ul>
<li><code>sessionID</code> - 会话 ID，唯一标识一个会话，每次客户端创建新的会话时，Zookeeper 都会为其分配一个全局唯一的 sessionID。</li>
<li><code>TimeOut</code> - 会话超时时间，客户端在构造 Zookeeper 实例时，会配置 sessionTimeout 参数用于指定会话的超时时间，Zookeeper 客户端向服务端发送这个超时时间后，服务端会根据自己的超时时间限制最终确定会话的超时时间。</li>
<li><code>TickTime</code> - 下次会话超时时间点，为了便于 Zookeeper 对会话实行”分桶策略”管理，同时为了高效低耗地实现会话的超时检查与清理，Zookeeper 会为每个会话标记一个下次会话超时时间点，其值大致等于当前时间加上 TimeOut。</li>
<li><code>isClosing</code> - 标记一个会话是否已经被关闭，当服务端检测到会话已经超时失效时，会将该会话的 isClosing 标记为”已关闭”，这样就能确保不再处理来自该会话的心情求了。</li>
</ul>
<p>Zookeeper 的会话管理主要是通过 <code>SessionTracker</code> 来负责，其采用了<strong>分桶策略</strong>（将类似的会话放在同一区块中进行管理）进行管理，以便 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。</p>
<h2 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h2><blockquote>
<p>ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。**<em>ZAB 协议不是 Paxos 算法</em>**，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。</p>
<p>ZAB 协议是 Zookeeper 专门设计的一种<strong>支持崩溃恢复的原子广播协议</strong>。</p>
<p>ZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。</p>
</blockquote>
<p>ZAB 协议定义了两个可以<strong>无限循环</strong>的流程：</p>
<ul>
<li><strong><code>选举 Leader</code></strong> - 用于故障恢复，从而保证高可用。</li>
<li><strong><code>原子广播</code></strong> - 用于主从同步，从而保证数据一致性。</li>
</ul>
<h3 id="选举-Leader"><a href="#选举-Leader" class="headerlink" title="选举 Leader"></a>选举 Leader</h3><blockquote>
<p><strong>ZooKeeper 的故障恢复</strong></p>
<p>ZooKeeper 集群采用一主（称为 Leader）多从（称为 Follower）模式，主从节点通过副本机制保证数据一致。</p>
<ul>
<li><strong>如果 Follower 节点挂了</strong> - ZooKeeper 集群中的每个节点都会单独在内存中维护自身的状态，并且各节点之间都保持着通讯，<strong>只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务</strong>。</li>
<li><strong>如果 Leader 节点挂了</strong> - 如果 Leader 节点挂了，系统就不能正常工作了。此时，需要通过 ZAB 协议的选举 Leader 机制来进行故障恢复。</li>
</ul>
<p>ZAB 协议的选举 Leader 机制简单来说，就是：基于过半选举机制产生新的 Leader，之后其他机器将从新的 Leader 上同步状态，当有过半机器完成状态同步后，就退出选举 Leader 模式，进入原子广播模式。</p>
</blockquote>
<h4 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h4><ul>
<li><strong>myid</strong> - 每个 Zookeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 Zookeeper 集群唯一的 ID（整数）。</li>
<li><strong>zxid</strong> - 类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal ID。为了保证顺序性，该 zxid 必须单调递增。因此 Zookeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zxid 的全局递增性。</li>
</ul>
<h4 id="服务器状态"><a href="#服务器状态" class="headerlink" title="服务器状态"></a>服务器状态</h4><ul>
<li><strong><em>LOOKING</em></strong> - 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举</li>
<li><strong><em>FOLLOWING</em></strong> - 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁</li>
<li><strong><em>LEADING</em></strong> - 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳</li>
<li><strong><em>OBSERVING</em></strong> - 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票</li>
</ul>
<h4 id="选票数据结构"><a href="#选票数据结构" class="headerlink" title="选票数据结构"></a>选票数据结构</h4><p>每个服务器在进行领导选举时，会发送如下关键信息</p>
<ul>
<li><strong><em>logicClock</em></strong> - 每个服务器会维护一个自增的整数，名为 logicClock，它表示这是该服务器发起的第多少轮投票</li>
<li><strong><em>state</em></strong> - 当前服务器的状态</li>
<li><strong><em>self_id</em></strong> - 当前服务器的 myid</li>
<li><strong><em>self_zxid</em></strong> - 当前服务器上所保存的数据的最大 zxid</li>
<li><strong><em>vote_id</em></strong> - 被推举的服务器的 myid</li>
<li><strong><em>vote_zxid</em></strong> - 被推举的服务器上所保存的数据的最大 zxid</li>
</ul>
<h4 id="投票流程"><a href="#投票流程" class="headerlink" title="投票流程"></a>投票流程</h4><p>（1）<strong>自增选举轮次</strong> - Zookeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。</p>
<p>（2）<strong>初始化选票</strong> - 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。</p>
<p>（3）<strong>发送初始化选票</strong> - 每个服务器最开始都是通过广播把票投给自己。</p>
<p>（4）<strong>接收外部投票</strong> - 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。</p>
<p>（5）<strong>判断选举轮次</strong> - 收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理</p>
<ul>
<li>外部投票的 logicClock 大于自己的 logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 logicClock 更新为收到的 logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。</li>
<li>外部投票的 logicClock 小于自己的 logicClock。当前服务器直接忽略该投票，继续处理下一个投票。</li>
<li>外部投票的 logickClock 与自己的相等。当时进行选票 PK。</li>
</ul>
<p>（6）<strong>选票 PK</strong> - 选票 PK 是基于<code>(self_id, self_zxid)</code> 与 <code>(vote_id, vote_zxid)</code> 的对比</p>
<ul>
<li>外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock</li>
<li>若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖</li>
<li>若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱</li>
</ul>
<p>（7）<strong>统计选票</strong> - 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。</p>
<p>（8）<strong>更新服务器状态</strong> - 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING</p>
<p>通过以上流程分析，我们不难看出：要使 Leader 获得多数 Server 的支持，则 <strong>ZooKeeper 集群节点数必须是奇数。且存活的节点数目不得少于 <code>N + 1</code></strong> 。</p>
<p>每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。</p>
<h3 id="原子广播（Atomic-Broadcast）"><a href="#原子广播（Atomic-Broadcast）" class="headerlink" title="原子广播（Atomic Broadcast）"></a>原子广播（Atomic Broadcast）</h3><p><strong>ZooKeeper 通过副本机制来实现高可用</strong>。</p>
<p>那么，ZooKeeper 是如何实现副本机制的呢？答案是：ZAB 协议的原子广播。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_3.png" alt="img"></p>
<p>ZAB 协议的原子广播要求：</p>
<p>**<em>所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应</em>**。这有些类似数据库中的两阶段提交协议。</p>
<p>在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。</p>
<blockquote>
<p>ZAB 是通过“一切以领导者为准”的强领导者模型和严格按照顺序提交日志，来实现操作的顺序性的，这一点和 Raft 是一样的。</p>
</blockquote>
<h2 id="ZooKeeper-应用"><a href="#ZooKeeper-应用" class="headerlink" title="ZooKeeper 应用"></a>ZooKeeper 应用</h2><blockquote>
<p><strong>ZooKeeper 可以用于发布&#x2F;订阅、负载均衡、命令服务、分布式协调&#x2F;通知、集群管理、Master 选举、分布式锁和分布式队列等功能</strong> 。</p>
</blockquote>
<h3 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h3><p>在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，ZooKeeper 可以通过顺序节点的特性来生成全局唯一 ID，从而可以对分布式系统提供命名服务。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200602182548.png" alt="img"></p>
<h3 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h3><p>利用 ZooKeeper 的观察机制，可以将其作为一个高可用的配置存储器，允许分布式应用的参与者检索和更新配置文件。</p>
<h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>可以通过 ZooKeeper 的临时节点和 Watcher 机制来实现分布式排它锁。</p>
<p>举例来说，有一个分布式系统，有三个节点 A、B、C，试图通过 ZooKeeper 获取分布式锁。</p>
<p>（1）访问 <code>/lock</code> （这个目录路径由程序自己决定），创建 <strong>带序列号的临时节点（EPHEMERAL）</strong> 。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200602191358.png" alt="img"></p>
<p>（2）每个节点尝试获取锁时，拿到 <code>/locks</code>节点下的所有子节点（<code>id_0000</code>,<code>id_0001</code>,<code>id_0002</code>），<strong>判断自己创建的节点是不是序列号最小的</strong></p>
<ul>
<li>如果序列号是最小的，则成功获取到锁。<ul>
<li>释放锁：执行完操作后，把创建的节点给删掉。</li>
</ul>
</li>
<li>如果不是，则监听比自己要小 1 的节点变化。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200602192619.png" alt="img"></p>
<p>（3）释放锁，即删除自己创建的节点。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200602192341.png" alt="img"></p>
<p>图中，NodeA 删除自己创建的节点 <code>id_0000</code>，NodeB 监听到变化，发现自己的节点已经是最小节点，即可获取到锁。</p>
<h3 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h3><p>ZooKeeper 还能解决大多数分布式系统中的问题：</p>
<ul>
<li>如可以通过创建临时节点来建立心跳检测机制。如果分布式系统的某个服务节点宕机了，则其持有的会话会超时，此时该临时节点会被删除，相应的监听事件就会被触发。</li>
<li>分布式系统的每个服务节点还可以将自己的节点状态写入临时节点，从而完成状态报告或节点工作进度汇报。</li>
<li>通过数据的订阅和发布功能，ZooKeeper 还能对分布式系统进行模块的解耦和任务的调度。</li>
<li>通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容。</li>
</ul>
<h3 id="选举-Leader-节点"><a href="#选举-Leader-节点" class="headerlink" title="选举 Leader 节点"></a>选举 Leader 节点</h3><p>分布式系统一个重要的模式就是主从模式 (Master&#x2F;Salves)，ZooKeeper 可以用于该模式下的 Matser 选举。可以让所有服务节点去竞争性地创建同一个 ZNode，由于 ZooKeeper 不能有路径相同的 ZNode，必然只有一个服务节点能够创建成功，这样该服务节点就可以成为 Master 节点。</p>
<h3 id="队列管理"><a href="#队列管理" class="headerlink" title="队列管理"></a>队列管理</h3><p>ZooKeeper 可以处理两种类型的队列：</p>
<ol>
<li>当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。</li>
<li>队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。</li>
</ol>
<p>同步队列用 ZooKeeper 实现的实现思路如下：</p>
<p>创建一个父目录 <code>/synchronizing</code>，每个成员都监控标志（Set Watch）位目录 <code>/synchronizing/start</code> 是否存在，然后每个成员都加入这个队列，加入队列的方式就是创建 <code>/synchronizing/member_i</code> 的临时目录节点，然后每个成员获取 <code>/synchronizing</code> 目录的所有目录节点，也就是 <code>member_i</code>。判断 i 的值是否已经是成员的个数，如果小于成员个数等待 <code>/synchronizing/start</code> 的出现，如果已经相等就创建 <code>/synchronizing/start</code>。</p>
<h2 id="ZooKeeper-的缺点"><a href="#ZooKeeper-的缺点" class="headerlink" title="ZooKeeper 的缺点"></a>ZooKeeper 的缺点</h2><p>ZooKeeper 的监听是一次性的。</p>
<h3 id="ZooKeeper-不是为高可用性设计的"><a href="#ZooKeeper-不是为高可用性设计的" class="headerlink" title="ZooKeeper 不是为高可用性设计的"></a>ZooKeeper 不是为高可用性设计的</h3><p>生产环境中常常需要通过多机房部署来容灾。出于成本考虑，一般多机房都是同时提供服务的，即一个机房撑不住所有流量。<strong>ZooKeeper 集群只能有一个 Leader</strong>，一旦机房之间连接出现故障，那么只有 Leader 所在的机房可以正常工作，其他机房只能停摆。于是所有流量集中到 Leader 所在的机房，由于处理不过来而导致崩溃。</p>
<p>即使是在同一个机房里面，由于网段的不同，在调整机房交换机的时候偶尔也会发生网段隔离的情况。实际上机房每个月基本上都会发生短暂的网络隔离之类的子网段调整。在那个时刻 ZooKeeper 将处于不可用状态。如果业务系统重度依赖 ZooKeeper（比如用 Dubbo 作为 RPC，且使用 ZooKeeper 作为注册中心），则系统的可用性将非常脆弱。</p>
<p>由于 ZooKeeper 对于网络隔离的极度敏感，导致 ZooKeeper 对于网络的任何风吹草动都会做出激烈反应。这使得 ZooKeeper 的<strong>不可用</strong>时间比较多。我们不能让 ZooKeeper 的<strong>不可用</strong>，变成系统的<strong>不可用</strong>。</p>
<h3 id="ZooKeeper-的选举过程速度很慢"><a href="#ZooKeeper-的选举过程速度很慢" class="headerlink" title="ZooKeeper 的选举过程速度很慢"></a>ZooKeeper 的选举过程速度很慢</h3><p>互联网环境中，网络不稳定几乎是必然的，而 ZooKeeper 网络隔离非常敏感。一旦出现网络隔离，zookeeper 就要发起选举流程。</p>
<p>ZooKeeper 的选举流程通常耗时 30 到 120 秒，期间 ZooKeeper 由于没有 Leader，都是不可用的。</p>
<p>对于网络里面偶尔出现的，比如半秒一秒的网络隔离，ZooKeeper 会由于选举过程，而把不可用时间放大几十倍。</p>
<h3 id="ZooKeeper-的性能是有限的"><a href="#ZooKeeper-的性能是有限的" class="headerlink" title="ZooKeeper 的性能是有限的"></a>ZooKeeper 的性能是有限的</h3><p>典型的 ZooKeeper 的 TPS 大概是一万多，无法支撑每天动辄几十亿次的调用。因此，每次请求都去 ZooKeeper 获取业务系统信息是不可能的。</p>
<p>为此，ZooKeeper 的 client 必须自己缓存业务系统的信息。这就导致 ZooKeeper 提供的<strong>强一致性</strong>实际上是做不到的。如果我们需要强一致性，还需要其他机制来进行保障：比如用自动化脚本把业务系统的 old master 给 kill 掉，但是这可能会引发很多其他问题。</p>
<h3 id="ZooKeeper-无法进行有效的权限控制"><a href="#ZooKeeper-无法进行有效的权限控制" class="headerlink" title="ZooKeeper 无法进行有效的权限控制"></a>ZooKeeper 无法进行有效的权限控制</h3><p>ZooKeeper 的权限控制非常弱。在大型的复杂系统里面，使用 ZooKeeper 必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问 ZooKeeper。</p>
<p>额外的权限控制系统不但增加了系统复杂性和维护成本，而且降低了系统的总体性能。</p>
<h3 id="即使有了-ZooKeeper-也很难避免业务系统的数据不一致"><a href="#即使有了-ZooKeeper-也很难避免业务系统的数据不一致" class="headerlink" title="即使有了 ZooKeeper 也很难避免业务系统的数据不一致"></a>即使有了 ZooKeeper 也很难避免业务系统的数据不一致</h3><p>由于 ZooKeeper 的性能限制，我们无法让每次系统内部调用都走 ZooKeeper，因此总有某些时刻，业务系统会存在两份数据（业务系统 client 那边缓存的业务系统信息是定时从 ZooKeeper 更新的，因此会有更新不同步的问题）。</p>
<p>如果要保持数据的强一致性，唯一的方法是“先 kill 掉当前 Leader，再在 ZooKeeper 上更新 Leader 信息”。是否要 kill 掉当前 Leader 这个问题上，程序是无法完全自动决定的（因为网络隔离的时候 ZooKeeper 已经不可用了，自动脚本没有全局信息，不管怎么做都可能是错的，什么都不做也可能是错的。当网络故障的时候，只有运维人员才有全局信息，程序是无法得知其他机房的情况的）。因此系统无法自动的保障数据一致性，必须要人工介入。而人工介入的典型时间是半个小时以上，我们不能让系统这么长时间不可用。因此我们必须在某个方向上进行妥协，最常见的妥协方式是放弃<strong>强一致性</strong>，而接受<strong>最终一致性</strong>。</p>
<p>如果我们需要人工介入才能保证<em>可靠的强一致性</em>，那么 ZooKeeper 的价值就大打折扣。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><strong>官方</strong><ul>
<li><a target="_blank" rel="noopener" href="http://zookeeper.apache.org/">ZooKeeper 官网</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/ZOOKEEPER">ZooKeeper 官方文档</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/apache/zookeeper">ZooKeeper Github</a></li>
</ul>
</li>
<li><strong>书籍</strong><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/12109713.html">《Hadoop 权威指南（第四版）》</a></li>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11622772.html">《从 Paxos 到 Zookeeper 分布式一致性原理与实践》</a></li>
</ul>
</li>
<li><strong>文章</strong><ul>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/index.html">分布式服务框架 ZooKeeper – 管理分布式环境中的数据</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/felixzh/p/5869212.html">ZooKeeper 的功能以及工作原理</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/ZooKeeper%E7%AE%80%E4%BB%8B%E5%8F%8A%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5.md">ZooKeeper 简介及核心概念</a></li>
<li><a target="_blank" rel="noopener" href="https://draveness.me/zookeeper-chubby">详解分布式协调服务 ZooKeeper</a></li>
<li><a target="_blank" rel="noopener" href="http://www.jasongj.com/zookeeper/fastleaderelection/">深入浅出 Zookeeper（一） Zookeeper 架构及 FastLeaderElection 机制</a></li>
<li><a target="_blank" rel="noopener" href="https://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper">Introduction to Apache ZooKeeper</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/wwwsq/article/details/7644445">Zookeeper 的优缺点</a></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/bb5e61/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/bb5e61/" class="post-title-link" itemprop="url">ZooKeeper运维</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-02 22:28:38" itemprop="dateCreated datePublished" datetime="2020-06-02T22:28:38+08:00">2020-06-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C/" itemprop="url" rel="index"><span itemprop="name">分布式协同</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C/ZooKeeper/" itemprop="url" rel="index"><span itemprop="name">ZooKeeper</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ZooKeeper-运维指南"><a href="#ZooKeeper-运维指南" class="headerlink" title="ZooKeeper 运维指南"></a>ZooKeeper 运维指南</h1><h2 id="单点服务部署"><a href="#单点服务部署" class="headerlink" title="单点服务部署"></a>单点服务部署</h2><p>在安装 ZooKeeper 之前，请确保你的系统是在以下任一操作系统上运行：</p>
<ul>
<li><strong>任意 Linux OS</strong> - 支持开发和部署。适合演示应用程序。</li>
<li><strong>Windows OS</strong> - 仅支持开发。</li>
<li><strong>Mac OS</strong> - 仅支持开发。</li>
</ul>
<p>安装步骤如下：</p>
<h3 id="下载解压"><a href="#下载解压" class="headerlink" title="下载解压"></a>下载解压</h3><p>进入官方下载地址：<a target="_blank" rel="noopener" href="http://zookeeper.apache.org/releases.html#download">http://zookeeper.apache.org/releases.html#download</a> ，选择合适版本。</p>
<p>解压到本地：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf zookeeper-3.4.6.tar.gz</span><br><span class="line"><span class="built_in">cd</span> zookeeper-3.4.6</span><br></pre></td></tr></table></figure>

<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>执行 <code>vim /etc/profile</code>，添加环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/app/zookeeper-3.4.14</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$ZOOKEEPER_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>再执行 <code>source /etc/profile</code> ， 使得配置的环境变量生效。</p>
<h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>你必须创建 <code>conf/zoo.cfg</code> 文件，否则启动时会提示你没有此文件。</p>
<p>初次尝试，不妨直接使用 Kafka 提供的模板配置文件 <code>conf/zoo_sample.cfg</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> conf/zoo_sample.cfg conf/zoo.cfg</span><br></pre></td></tr></table></figure>

<p>修改后完整配置如下：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The number of milliseconds of each tick</span></span><br><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="comment"># The number of ticks that the initial</span></span><br><span class="line"><span class="comment"># synchronization phase can take</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">10</span></span><br><span class="line"><span class="comment"># The number of ticks that can pass between</span></span><br><span class="line"><span class="comment"># sending a request and getting an acknowledgement</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="string">5</span></span><br><span class="line"><span class="comment"># the directory where the snapshot is stored.</span></span><br><span class="line"><span class="comment"># do not use /tmp for storage, /tmp here is just</span></span><br><span class="line"><span class="comment"># example sakes.</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">/usr/local/zookeeper/data</span></span><br><span class="line"><span class="attr">dataLogDir</span>=<span class="string">/usr/local/zookeeper/log</span></span><br><span class="line"><span class="comment"># the port at which the clients will connect</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br><span class="line"><span class="comment"># the maximum number of client connections.</span></span><br><span class="line"><span class="comment"># increase this if you need to handle more clients</span></span><br><span class="line"><span class="comment">#maxClientCnxns=60</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Be sure to read the maintenance section of the</span></span><br><span class="line"><span class="comment"># administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The number of snapshots to retain in dataDir</span></span><br><span class="line"><span class="comment">#autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="comment"># Purge task interval in hours</span></span><br><span class="line"><span class="comment"># Set to &quot;0&quot; to disable auto purge feature</span></span><br><span class="line"><span class="comment">#autopurge.purgeInterval=1</span></span><br></pre></td></tr></table></figure>

<p>配置参数说明：</p>
<ul>
<li><strong>tickTime</strong>：用于计算的基础时间单元。比如 session 超时：N*tickTime；</li>
<li><strong>initLimit</strong>：用于集群，允许从节点连接并同步到 master 节点的初始化连接时间，以 tickTime 的倍数来表示；</li>
<li><strong>syncLimit</strong>：用于集群， master 主节点与从节点之间发送消息，请求和应答时间长度（心跳机制）；</li>
<li><strong>dataDir</strong>：数据存储位置；</li>
<li><strong>dataLogDir</strong>：日志目录；</li>
<li><strong>clientPort</strong>：用于客户端连接的端口，默认 2181</li>
</ul>
<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><p>执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>执行此命令后，你将收到以下响应</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JMX enabled by default</span><br><span class="line">Using config: /Users/../zookeeper-3.4.6/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure>

<h3 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h3><p>可以使用以下命令停止 zookeeper 服务器。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh stop</span><br></pre></td></tr></table></figure>

<h2 id="集群服务部署"><a href="#集群服务部署" class="headerlink" title="集群服务部署"></a>集群服务部署</h2><p>分布式系统节点数一般都要求是奇数，且最少为 3 个节点，Zookeeper 也不例外。</p>
<p>这里，规划一个含 3 个节点的最小 ZooKeeper 集群，主机名分别为 hadoop001，hadoop002，hadoop003 。</p>
<h3 id="修改配置-1"><a href="#修改配置-1" class="headerlink" title="修改配置"></a>修改配置</h3><p>修改配置文件 <code>zoo.cfg</code>，内容如下：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">10</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="string">5</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">/usr/local/zookeeper-cluster/data/</span></span><br><span class="line"><span class="attr">dataLogDir</span>=<span class="string">/usr/local/zookeeper-cluster/log/</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># server.1 这个1是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到dataDir目录下面myid文件里</span></span><br><span class="line"><span class="comment"># 指名集群间通讯端口和选举端口</span></span><br><span class="line"><span class="attr">server.1</span>=<span class="string">hadoop001:2287:3387</span></span><br><span class="line"><span class="attr">server.2</span>=<span class="string">hadoop002:2287:3387</span></span><br><span class="line"><span class="attr">server.3</span>=<span class="string">hadoop003:2287:3387</span></span><br></pre></td></tr></table></figure>

<h3 id="标识节点"><a href="#标识节点" class="headerlink" title="标识节点"></a>标识节点</h3><p>分别在三台主机的 <code>dataDir</code> 目录下新建 <code>myid</code> 文件,并写入对应的节点标识。Zookeeper 集群通过 <code>myid</code> 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 Leader 节点。</p>
<p>创建存储目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三台主机均执行该命令</span></span><br><span class="line"><span class="built_in">mkdir</span> -vp  /usr/local/zookeeper-cluster/data/</span><br></pre></td></tr></table></figure>

<p>创建并写入节点标识到 <code>myid</code> 文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hadoop001主机</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;1&quot;</span> &gt; /usr/local/zookeeper-cluster/data/myid</span><br><span class="line"><span class="comment"># hadoop002主机</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;2&quot;</span> &gt; /usr/local/zookeeper-cluster/data/myid</span><br><span class="line"><span class="comment"># hadoop003主机</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;3&quot;</span> &gt; /usr/local/zookeeper-cluster/data/myid</span><br></pre></td></tr></table></figure>

<h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><p>分别在三台主机上，执行如下命令启动服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/app/zookeeper-cluster/zookeeper/bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<h3 id="集群验证"><a href="#集群验证" class="headerlink" title="集群验证"></a>集群验证</h3><p>启动后使用 <code>zkServer.sh status</code> 查看集群各个节点状态。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.w3cschool.cn/zookeeper/zookeeper_installation.html">Zookeeper 安装</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/installation/Zookeeper%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E5%92%8C%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">Zookeeper 单机环境和集群环境搭建</a></li>
<li><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/zookeeper-bs-command.html">Zookeeper 客户端基础命令使用</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/263c40/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/263c40/" class="post-title-link" itemprop="url">HBase 命令</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-02 22:28:18" itemprop="dateCreated datePublished" datetime="2020-06-02T22:28:18+08:00">2020-06-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%97%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">列式数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%97%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/HBase/" itemprop="url" rel="index"><span itemprop="name">HBase</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="HBase-命令"><a href="#HBase-命令" class="headerlink" title="HBase 命令"></a>HBase 命令</h1><blockquote>
<p>进入 HBase Shell 控制台：<code>./bin/hbase shell</code></p>
<p>如果有 kerberos 认证，需要事先使用相应的 keytab 进行一下认证（使用 kinit 命令），认证成功之后再使用 hbase shell 进入可以使用 whoami 命令可查看当前用户.</p>
</blockquote>
<h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><ul>
<li>获取帮助信息：<code>help</code></li>
<li>获取命令的详细帮助信息：<code>help &#39;status&#39;</code></li>
<li>查看服务器状态：<code>status</code></li>
<li>查看版本信息：<code>version</code></li>
<li>查看当前登录用户：<code>whoami</code></li>
</ul>
<h2 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h2><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><p>【语法】<code>create &#39;表名称&#39;,&#39;列族名称 1&#39;,&#39;列族名称 2&#39;,&#39;列名称 N&#39;</code></p>
<p>【示例】</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一张名为 <span class="built_in">test</span> 的表，columnFamliy1、columnFamliy2 是 table1 表的列族。</span></span><br><span class="line">create &#x27;test&#x27;,&#x27;columnFamliy1&#x27;,&#x27;columnFamliy2&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="启用、禁用表"><a href="#启用、禁用表" class="headerlink" title="启用、禁用表"></a>启用、禁用表</h3><ul>
<li>启用表：<code>enable &#39;test&#39;</code></li>
<li>禁用表：<code>disable &#39;test&#39;</code></li>
<li>检查表是否被启用：<code>is_enabled &#39;test&#39;</code></li>
<li>检查表是否被禁用：<code>is_disabled &#39;test&#39;</code></li>
</ul>
<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><p>注意：删除表前需要先禁用表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">disable &#x27;test&#x27;</span><br><span class="line">drop &#x27;test&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><h4 id="添加列族"><a href="#添加列族" class="headerlink" title="添加列族"></a>添加列族</h4><p><strong>命令格式</strong>： alter ‘表名’, ‘列族名’</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;test&#x27;, &#x27;teacherInfo&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="删除列族"><a href="#删除列族" class="headerlink" title="删除列族"></a>删除列族</h4><p><strong>命令格式</strong>：alter ‘表名’, {NAME &#x3D;&gt; ‘列族名’, METHOD &#x3D;&gt; ‘delete’}</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;test&#x27;, &#123;NAME =&gt; &#x27;teacherInfo&#x27;, METHOD =&gt; &#x27;delete&#x27;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="更改列族存储版本的限制"><a href="#更改列族存储版本的限制" class="headerlink" title="更改列族存储版本的限制"></a>更改列族存储版本的限制</h4><p>默认情况下，列族只存储一个版本的数据，如果需要存储多个版本的数据，则需要修改列族的属性。修改后可通过 <code>desc</code> 命令查看。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter &#x27;test&#x27;,&#123;NAME=&gt;&#x27;columnFamliy1&#x27;,VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure>

<h3 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h3><ul>
<li>查看所有表：<code>list</code></li>
<li>查看表的详细信息：<code>describe &#39;test&#39;</code></li>
<li>检查表是否存在：<code>exists &#39;test&#39;</code></li>
</ul>
<h2 id="增删改"><a href="#增删改" class="headerlink" title="增删改"></a>增删改</h2><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><p><strong>命令格式</strong>：<code>put &#39;表名&#39;, &#39;行键&#39;,&#39;列族:列&#39;,&#39;值&#39;</code></p>
<p><strong>注意：如果新增数据的行键值、列族名、列名与原有数据完全相同，则相当于更新操作</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">put &#x27;test&#x27;, &#x27;rowkey1&#x27;, &#x27;columnFamliy1:a&#x27;, &#x27;valueA&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey1&#x27;, &#x27;columnFamliy1:b&#x27;, &#x27;valueB&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey1&#x27;, &#x27;columnFamliy1:c&#x27;, &#x27;valueC&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey2&#x27;, &#x27;columnFamliy1:a&#x27;, &#x27;valueA&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey2&#x27;, &#x27;columnFamliy1:b&#x27;, &#x27;valueB&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey2&#x27;, &#x27;columnFamliy1:c&#x27;, &#x27;valueC&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey3&#x27;, &#x27;columnFamliy1:a&#x27;, &#x27;valueA&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey3&#x27;, &#x27;columnFamliy1:b&#x27;, &#x27;valueB&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey3&#x27;, &#x27;columnFamliy1:c&#x27;, &#x27;valueC&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey1&#x27;, &#x27;columnFamliy2:a&#x27;, &#x27;valueA&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey1&#x27;, &#x27;columnFamliy2:b&#x27;, &#x27;valueB&#x27;</span><br><span class="line">put &#x27;test&#x27;, &#x27;rowkey1&#x27;, &#x27;columnFamliy2:c&#x27;, &#x27;valueC&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="获取指定行、列族、列"><a href="#获取指定行、列族、列" class="headerlink" title="获取指定行、列族、列"></a>获取指定行、列族、列</h3><ul>
<li>获取指定行中所有列的数据信息：<code>get &#39;test&#39;,&#39;rowkey2&#39;</code></li>
<li>获取指定行中指定列族下所有列的数据信息：<code>get &#39;test&#39;,&#39;rowkey2&#39;,&#39;columnFamliy1&#39;</code></li>
<li>获取指定行中指定列的数据信息：<code>get &#39;test&#39;,&#39;rowkey2&#39;,&#39;columnFamliy1:a&#39;</code></li>
</ul>
<h3 id="删除指定行、列"><a href="#删除指定行、列" class="headerlink" title="删除指定行、列"></a>删除指定行、列</h3><ul>
<li>删除指定行：<code>delete &#39;test&#39;,&#39;rowkey2&#39;</code></li>
<li>删除指定行中指定列的数据：<code>delete &#39;test&#39;,&#39;rowkey2&#39;,&#39;columnFamliy1:a&#39;</code></li>
</ul>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>hbase 中访问数据有两种基本的方式：</p>
<ul>
<li>按指定 rowkey 获取数据：<code>get</code> 方法；</li>
<li>按指定条件获取数据：<code>scan</code> 方法。</li>
</ul>
<p><code>scan</code> 可以设置 begin 和 end 参数来访问一个范围内所有的数据。get 本质上就是 begin 和 end 相等的一种特殊的 scan。</p>
<h3 id="get-查询"><a href="#get-查询" class="headerlink" title="get 查询"></a>get 查询</h3><ul>
<li>获取指定行中所有列的数据信息：<code>get &#39;test&#39;,&#39;rowkey2&#39;</code></li>
<li>获取指定行中指定列族下所有列的数据信息：<code>get &#39;test&#39;,&#39;rowkey2&#39;,&#39;columnFamliy1&#39;</code></li>
<li>获取指定行中指定列的数据信息：<code>get &#39;test&#39;,&#39;rowkey2&#39;,&#39;columnFamliy1:a&#39;</code></li>
</ul>
<h3 id="scan-查询"><a href="#scan-查询" class="headerlink" title="scan 查询"></a>scan 查询</h3><h4 id="查询整表数据"><a href="#查询整表数据" class="headerlink" title="查询整表数据"></a>查询整表数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="查询指定列簇的数据"><a href="#查询指定列簇的数据" class="headerlink" title="查询指定列簇的数据"></a>查询指定列簇的数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;, &#123;COLUMN=&gt;&#x27;columnFamliy1&#x27;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询指定列的数据</span></span><br><span class="line">scan &#x27;test&#x27;, &#123;COLUMNS=&gt; &#x27;columnFamliy1:a&#x27;&#125;</span><br></pre></td></tr></table></figure>

<p>除了列 <code>（COLUMNS）</code> 修饰词外，HBase 还支持 <code>Limit</code>（限制查询结果行数），<code>STARTROW</code>（<code>ROWKEY</code> 起始行，会先根据这个 <code>key</code> 定位到 <code>region</code>，再向后扫描）、<code>STOPROW</code>(结束行)、<code>TIMERANGE</code>（限定时间戳范围）、<code>VERSIONS</code>（版本数）、和 <code>FILTER</code>（按条件过滤行）等。</p>
<p>如下代表从 <code>rowkey2</code> 这个 <code>rowkey</code> 开始，查找下两个行的最新 3 个版本的 name 列的数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;, &#123;COLUMNS=&gt; &#x27;columnFamliy1:a&#x27;,STARTROW =&gt; &#x27;rowkey2&#x27;,STOPROW =&gt; &#x27;rowkey3&#x27;,LIMIT=&gt;2, VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure>

<h4 id="条件过滤"><a href="#条件过滤" class="headerlink" title="条件过滤"></a>条件过滤</h4><p>Filter 可以设定一系列条件来进行过滤。如我们要查询值等于 24 的所有数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;, FILTER=&gt;&quot;ValueFilter(=,&#x27;binary:24&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<p>值包含 valueA 的所有数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;, FILTER=&gt;&quot;ValueFilter(=,&#x27;substring:valueA&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<p>列名中的前缀为 b 的：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;b&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<p>FILTER 中支持多个过滤条件通过括号、AND 和 OR 进行组合：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">列名中的前缀为 b 且列值中包含1998的数据</span></span><br><span class="line">scan &#x27;test&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;b&#x27;) AND ValueFilter ValueFilter(=,&#x27;substring:A&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<p><code>PrefixFilter</code> 用于对 Rowkey 的前缀进行判断：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;, FILTER=&gt;&quot;PrefixFilter(&#x27;wr&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hbase_Shell.md">Hbase 常用 Shell 命令</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/0a8826/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/0a8826/" class="post-title-link" itemprop="url">Zipkin 快速入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-03-23 22:56:45" itemprop="dateCreated datePublished" datetime="2020-03-23T22:56:45+08:00">2020-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/%E8%BD%AF%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">软件</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/%E8%BD%AF%E4%BB%B6/%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/" itemprop="url" rel="index"><span itemprop="name">监控诊断</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Zipkin-快速入门"><a href="#Zipkin-快速入门" class="headerlink" title="Zipkin 快速入门"></a>Zipkin 快速入门</h1><p><strong>Zipkin 是一个基于 Java 开发的、开源的、分布式实时数据跟踪系统（Distributed Tracking System）</strong>。它采集有助于解决服务架构中延迟问题的实时数据。</p>
<p>Zipkin 主要功能是聚集来自各个异构系统的实时监控数据。分布式跟踪系统还有其他比较成熟的实现，例如：Naver 的 Pinpoint、Apache 的 HTrace、阿里的鹰眼 Tracing、京东的 Hydra、新浪的 Watchman，美团点评的 CAT，skywalking 等。</p>
<p>Zipkin 基于 Google Dapper 的论文设计而来，由 Twitter 公司开发贡献。</p>
<h2 id="一、Zipkin-简介"><a href="#一、Zipkin-简介" class="headerlink" title="一、Zipkin 简介"></a>一、Zipkin 简介</h2><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>如果日志文件中有跟踪 ID，则可以直接跳至该跟踪 ID。 否则，您可以基于属性进行查询，例如服务，操作名称，标签和持续时间。 将为您总结一些有趣的数据，例如在服务中花费的时间百分比以及操作是否失败。</p>
<p>Zipkin UI 还提供了一个依赖关系图，该关系图显示了每个应用程序中跟踪了多少个请求。这对于识别聚合行为（包括错误路径或对不赞成使用的服务的调用）很有帮助。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200211161706.png" alt="Zipkin UI"></p>
<h3 id="多平台"><a href="#多平台" class="headerlink" title="多平台"></a>多平台</h3><p>Zipkin 官方支持 C#、Go、Java、JavaScript、Ruby、Scala、PHP 语言。</p>
<p>除此以外，社区还贡献了多种其他语言的支持，详情可以参考官方文档：<a target="_blank" rel="noopener" href="https://zipkin.io/pages/tracers_instrumentation.html">Tracers and Instrumentation</a></p>
<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>Zipkin 服务器捆绑了用于采集和存储数据的扩展。</p>
<p>默认情况下，数据可以通过 <code>Http</code>，<code>Kafka</code> 、<code>RabbitMQ</code> 或 RPC 传输。</p>
<p>并存储在内存中或 <code>MySQL</code>、<code>Cassandra</code> 或 <code>Elasticsearch</code> 中。</p>
<p>数据以 json 形式存储，可以参考：<a target="_blank" rel="noopener" href="https://zipkin.io/zipkin-api/#/default/post_spans">Zipkin 官方的 Swagger API</a></p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200211162055.png" alt="Zipkin Swagger API"></p>
<h2 id="二、Zipkin-安装"><a href="#二、Zipkin-安装" class="headerlink" title="二、Zipkin 安装"></a>二、Zipkin 安装</h2><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p>Docker 启动方式：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 9411:9411 openzipkin/zipkin</span><br></pre></td></tr></table></figure>

<h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><blockquote>
<p>注意：必须运行在 JDK8+ 环境</p>
</blockquote>
<p>Java 启动方式：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -sSL https://zipkin.io/quickstart.sh | bash -s</span><br><span class="line">java -jar zipkin.jar</span><br></pre></td></tr></table></figure>

<h3 id="编译方式"><a href="#编译方式" class="headerlink" title="编译方式"></a>编译方式</h3><p>适用于需要订制化的场景。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">get the latest <span class="built_in">source</span></span></span><br><span class="line">git clone https://github.com/openzipkin/zipkin</span><br><span class="line">cd zipkin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Build the server and also make its dependencies</span></span><br><span class="line">./mvnw -DskipTests --also-make -pl zipkin-server clean install</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Run the server</span></span><br><span class="line">java -jar ./zipkin-server/target/zipkin-server-*exec.jar</span><br></pre></td></tr></table></figure>

<h2 id="三、Zipkin-架构"><a href="#三、Zipkin-架构" class="headerlink" title="三、Zipkin 架构"></a>三、Zipkin 架构</h2><p>ZipKin 可以分为两部分，</p>
<ul>
<li>一部分是 Zipkin server，用来作为数据的采集存储、数据分析与展示；</li>
<li>另一部分是 Zipkin client 是 Zipkin 基于不同的语言及框架封装的一些列客户端工具，这些工具完成了追踪数据的生成与上报功能。</li>
</ul>
<p>架构如下：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200211155836.png" alt="Zipkin 架构"></p>
<h3 id="Zipkin-Server"><a href="#Zipkin-Server" class="headerlink" title="Zipkin Server"></a>Zipkin Server</h3><p>Zipkin Server 主要包括四个模块：</p>
<ul>
<li><strong>Collector</strong> - 负责采集客户端传输的数据。</li>
<li><strong>Storage</strong> - 负责存储采集的数据。当前支持 Memory，MySQL，Cassandra，ElasticSearch 等，默认存储在内存中。</li>
<li><strong>API（Query）</strong> - 负责查询 Storage 中存储的数据。提供简单的 JSON API 获取数据，主要提供给 web UI 使用。</li>
<li><strong>UI</strong> - 提供简单的 web 界面。</li>
</ul>
<p>Instrumented Client 和 Instrumented Server，是指分布式架构中使用了 Trace 工具的两个应用，Client 会调用 Server 提供的服务，两者都会向 Zipkin 上报 Trace 相关信息。在 Client 和 Server 通过 Transport 上报 Trace 信息后，由 Zipkin 的 Collector 模块接收，并由 Storage 模块将数据存储在对应的存储介质中，然后 Zipkin 提供 API 供 UI 界面查询 Trace 跟踪信息。Non-Instrumented Server，指的是未使用 Trace 工具的 Server，显然它不会上报 Trace 信息。</p>
<h3 id="Zipkin-Client"><a href="#Zipkin-Client" class="headerlink" title="Zipkin Client"></a>Zipkin Client</h3><ul>
<li><strong>Tracer</strong> - <code>Tracer</code> 存在于你的应用中，它负责采集关于已发生操作的实时元数据。它们通常会检测库，因此对于用户是透明的。例如，已检测的 Web 服务器记录它何时接收到请求，以及何时发送响应。收集的跟踪数据称为跨度（Span）。</li>
<li><strong>Instrumentation</strong> - Instrumentation 保证了生产环境的安全性和很少的开销。因此，它们仅在内部传播 ID，以告知接收方正在进行追踪。完成的 Span 将通过外部通信告知 Zipkin，类似于应用程序异步报告指标的方式。例如，当跟踪某个操作并且需要发出 http 请求时，会添加一些 header 来传播 ID。header 不用于发送详细信息，例如操作名称。</li>
<li><strong>Reporter</strong> - 能够将数据发送到 Zipkin 的检测应用程序中的组件，被称为 Reporter。Reporter 有多种传输方式，可以将跟踪数据发送到 Zipkin 采集器，后者将跟踪数据持久化保存到存储中。稍后，API 会查询存储以向 UI 提供渲染数据。</li>
</ul>
<p>以下是 Zipkin 的一个示例工作流：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐</span><br><span class="line">│ User Code   │ │ Trace Instrumentation │  │ Http Client │  │ Zipkin Collector │</span><br><span class="line">└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘</span><br><span class="line">       │                 │                         │                 │</span><br><span class="line">           ┌─────────┐</span><br><span class="line">       │ ──┤GET /foo ├─▶ │ ────┐                   │                 │</span><br><span class="line">           └─────────┘         │ record tags</span><br><span class="line">       │                 │ ◀───┘                   │                 │</span><br><span class="line">                           ────┐</span><br><span class="line">       │                 │     │ add trace headers │                 │</span><br><span class="line">                           ◀───┘</span><br><span class="line">       │                 │ ────┐                   │                 │</span><br><span class="line">                               │ record timestamp</span><br><span class="line">       │                 │ ◀───┘                   │                 │</span><br><span class="line">                             ┌─────────────────┐</span><br><span class="line">       │                 │ ──┤GET /foo         ├─▶ │                 │</span><br><span class="line">                             │X-B3-TraceId: aa │     ────┐</span><br><span class="line">       │                 │   │X-B3-SpanId: 6b  │   │     │           │</span><br><span class="line">                             └─────────────────┘         │ invoke</span><br><span class="line">       │                 │                         │     │ request   │</span><br><span class="line">                                                         │</span><br><span class="line">       │                 │                         │     │           │</span><br><span class="line">                                 ┌────────┐          ◀───┘</span><br><span class="line">       │                 │ ◀─────┤200 OK  ├─────── │                 │</span><br><span class="line">                           ────┐ └────────┘</span><br><span class="line">       │                 │     │ record duration   │                 │</span><br><span class="line">            ┌────────┐     ◀───┘</span><br><span class="line">       │ ◀──┤200 OK  ├── │                         │                 │</span><br><span class="line">            └────────┘       ┌────────────────────────────────┐</span><br><span class="line">       │                 │ ──┤ asynchronously report span     ├────▶ │</span><br><span class="line">                             │                                │</span><br><span class="line">                             │&#123;                               │</span><br><span class="line">                             │  &quot;traceId&quot;: &quot;aa&quot;,              │</span><br><span class="line">                             │  &quot;id&quot;: &quot;6b&quot;,                   │</span><br><span class="line">                             │  &quot;name&quot;: &quot;get&quot;,                │</span><br><span class="line">                             │  &quot;timestamp&quot;: 1483945573944000,│</span><br><span class="line">                             │  &quot;duration&quot;: 386000,           │</span><br><span class="line">                             │  &quot;annotations&quot;: [              │</span><br><span class="line">                             │--snip--                        │</span><br><span class="line">                             └────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<p>Instrumented client 和 server 是分别使用了 ZipKin Client 的服务，Zipkin Client 会根据配置将追踪数据发送到 Zipkin Server 中进行数据存储、分析和展示。</p>
<h2 id="四、Zipkin-客户端"><a href="#四、Zipkin-客户端" class="headerlink" title="四、Zipkin 客户端"></a>四、Zipkin 客户端</h2><p><a target="_blank" rel="noopener" href="https://github.com/openzipkin/brave">Brave</a> 是 Java 版的 zipkin 客户端。</p>
<p>一般不会手动编写 Trace 相关的代码，Brave 提供可一些开箱即用的库，帮助我们追踪一些特定的请求。比如：dubbo、grpc、servlet、mysql、httpClient、kafka、springMVC 等。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://zipkin.io/">Zipkin 官网</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/openzipkin/zipkin">Zipkin Github</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/openzipkin/brave">brave</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/53aedb/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/53aedb/" class="post-title-link" itemprop="url">Spring AOP</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-02-26 23:47:47" itemprop="dateCreated datePublished" datetime="2020-02-26T23:47:47+08:00">2020-02-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:52" itemprop="dateModified" datetime="2024-12-12T10:02:52+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/%E6%A1%86%E6%9E%B6/Spring/" itemprop="url" rel="index"><span itemprop="name">Spring</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/%E6%A1%86%E6%9E%B6/Spring/Spring%E6%A0%B8%E5%BF%83/" itemprop="url" rel="index"><span itemprop="name">Spring核心</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h1><h2 id="AOP-概念"><a href="#AOP-概念" class="headerlink" title="AOP 概念"></a>AOP 概念</h2><h3 id="什么是-AOP"><a href="#什么是-AOP" class="headerlink" title="什么是 AOP"></a>什么是 AOP</h3><p>AOP(Aspect-Oriented Programming，即 <strong>面向切面编程</strong>)与 OOP( Object-Oriented Programming，面向对象编程) 相辅相成，提供了与 OOP 不同的抽象软件结构的视角。</p>
<p>在 OOP 中，我们以类(class)作为我们的基本单元，而 AOP 中的基本单元是 <strong>Aspect(切面)</strong></p>
<h3 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h3><h4 id="Aspect-切面"><a href="#Aspect-切面" class="headerlink" title="Aspect(切面)"></a>Aspect(切面)</h4><p><code>aspect</code> 由 <code>pointcount</code> 和 <code>advice</code> 组成, 它既包含了横切逻辑的定义, 也包括了连接点的定义. Spring AOP 就是负责实施切面的框架, 它将切面所定义的横切逻辑织入到切面所指定的连接点中.<br>AOP 的工作重心在于如何将增强织入目标对象的连接点上, 这里包含两个工作:</p>
<ol>
<li>如何通过 pointcut 和 advice 定位到特定的 joinpoint 上</li>
<li>如何在 advice 中编写切面代码.</li>
</ol>
<p><strong>可以简单地认为, 使用 @Aspect 注解的类就是切面.</strong></p>
<h4 id="advice-增强"><a href="#advice-增强" class="headerlink" title="advice(增强)"></a>advice(增强)</h4><p>由 aspect 添加到特定的 join point(即满足 point cut 规则的 join point) 的一段代码.<br>许多 AOP 框架, 包括 Spring AOP, 会将 advice 模拟为一个拦截器(interceptor), 并且在 join point 上维护多个 advice, 进行层层拦截.<br>例如 HTTP 鉴权的实现, 我们可以为每个使用 RequestMapping 标注的方法织入 advice, 当 HTTP 请求到来时, 首先进入到 advice 代码中, 在这里我们可以分析这个 HTTP 请求是否有相应的权限, 如果有, 则执行 Controller, 如果没有, 则抛出异常. 这里的 advice 就扮演着鉴权拦截器的角色了.</p>
<h4 id="连接点-join-point"><a href="#连接点-join-point" class="headerlink" title="连接点(join point)"></a>连接点(join point)</h4><blockquote>
<p>a point during the execution of a program, such as the execution of a method or the handling of an exception. In Spring AOP, a join point always represents a method execution.</p>
</blockquote>
<p>程序运行中的一些时间点, 例如一个方法的执行, 或者是一个异常的处理.<br><code>在 Spring AOP 中, join point 总是方法的执行点, 即只有方法连接点.</code></p>
<h4 id="切点-point-cut"><a href="#切点-point-cut" class="headerlink" title="切点(point cut)"></a>切点(point cut)</h4><p>匹配 join point 的谓词(a predicate that matches join points).<br>Advice 是和特定的 point cut 关联的, 并且在 point cut 相匹配的 join point 中执行.<br><code>在 Spring 中, 所有的方法都可以认为是 joinpoint, 但是我们并不希望在所有的方法上都添加 Advice, 而 pointcut 的作用就是提供一组规则(使用 AspectJ pointcut expression language 来描述) 来匹配joinpoint, 给满足规则的 joinpoint 添加 Advice.</code></p>
<h4 id="关于-join-point-和-point-cut-的区别"><a href="#关于-join-point-和-point-cut-的区别" class="headerlink" title="关于 join point 和 point cut 的区别"></a>关于 join point 和 point cut 的区别</h4><p>在 Spring AOP 中, 所有的方法执行都是 join point. 而 point cut 是一个描述信息, 它修饰的是 join point, 通过 point cut, 我们就可以确定哪些 join point 可以被织入 Advice. 因此 join point 和 point cut 本质上就是两个不同纬度上的东西.<br><code>advice 是在 join point 上执行的, 而 point cut 规定了哪些 join point 可以执行哪些 advice</code></p>
<h4 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h4><p>为一个类型添加额外的方法或字段. Spring AOP 允许我们为 <code>目标对象</code> 引入新的接口(和对应的实现). 例如我们可以使用 introduction 来为一个 bean 实现 IsModified 接口, 并以此来简化 caching 的实现.</p>
<h4 id="目标对象-Target"><a href="#目标对象-Target" class="headerlink" title="目标对象(Target)"></a>目标对象(Target)</h4><p>织入 advice 的目标对象. 目标对象也被称为 <code>advised object</code>.<br><code>因为 Spring AOP 使用运行时代理的方式来实现 aspect, 因此 adviced object 总是一个代理对象(proxied object)</code><br><code>注意, adviced object 指的不是原来的类, 而是织入 advice 后所产生的代理类.</code></p>
<h4 id="AOP-proxy"><a href="#AOP-proxy" class="headerlink" title="AOP proxy"></a>AOP proxy</h4><p>一个类被 AOP 织入 advice, 就会产生一个结果类, 它是融合了原类和增强逻辑的代理类.<br>在 Spring AOP 中, 一个 AOP 代理是一个 JDK 动态代理对象或 CGLIB 代理对象.</p>
<h4 id="织入-Weaving"><a href="#织入-Weaving" class="headerlink" title="织入(Weaving)"></a>织入(Weaving)</h4><p>将 aspect 和其他对象连接起来, 并创建 adviced object 的过程.<br>根据不同的实现技术, AOP 织入有三种方式:</p>
<ul>
<li>编译器织入, 这要求有特殊的 Java 编译器.</li>
<li>类装载期织入, 这需要有特殊的类装载器.</li>
<li>动态代理织入, 在运行期为目标类添加增强(Advice)生成子类的方式.<br>Spring 采用动态代理织入, 而 AspectJ 采用编译器织入和类装载期织入.</li>
</ul>
<h3 id="advice-的类型"><a href="#advice-的类型" class="headerlink" title="advice 的类型"></a>advice 的类型</h3><ul>
<li>before advice, 在 join point 前被执行的 advice. 虽然 before advice 是在 join point 前被执行, 但是它并不能够阻止 join point 的执行, 除非发生了异常(即我们在 before advice 代码中, 不能人为地决定是否继续执行 join point 中的代码)</li>
<li>after return advice, 在一个 join point 正常返回后执行的 advice</li>
<li>after throwing advice, 当一个 join point 抛出异常后执行的 advice</li>
<li>after(final) advice, 无论一个 join point 是正常退出还是发生了异常, 都会被执行的 advice.</li>
<li>around advice, 在 join point 前和 joint point 退出后都执行的 advice. 这个是最常用的 advice.</li>
</ul>
<h3 id="关于-AOP-Proxy"><a href="#关于-AOP-Proxy" class="headerlink" title="关于 AOP Proxy"></a>关于 AOP Proxy</h3><p>Spring AOP 默认使用标准的 JDK 动态代理(dynamic proxy)技术来实现 AOP 代理, 通过它, 我们可以为任意的接口实现代理.<br><code>如果需要为一个类实现代理, 那么可以使用 CGLIB 代理.</code> 当一个业务逻辑对象没有实现接口时, 那么 Spring AOP 就默认使用 CGLIB 来作为 AOP 代理了. 即如果我们需要为一个方法织入 advice, 但是这个方法不是一个接口所提供的方法, 则此时 Spring AOP 会使用 CGLIB 来实现动态代理. 鉴于此, Spring AOP 建议基于接口编程, 对接口进行 AOP 而不是类.</p>
<h3 id="彻底理解-aspect-join-point-point-cut-advice"><a href="#彻底理解-aspect-join-point-point-cut-advice" class="headerlink" title="彻底理解 aspect, join point, point cut, advice"></a>彻底理解 aspect, join point, point cut, advice</h3><p>看完了上面的理论部分知识, 我相信还是会有不少朋友感觉到 AOP 的概念还是很模糊, 对 AOP 中的各种概念理解的还不是很透彻. 其实这很正常, 因为 AOP 中的概念是在是太多了, 我当时也是花了老大劲才梳理清楚的.<br>下面我以一个简单的例子来比喻一下 AOP 中 aspect, jointpoint, pointcut 与 advice 之间的关系.</p>
<p>让我们来假设一下, 从前有一个叫爪哇的小县城, 在一个月黑风高的晚上, 这个县城中发生了命案. 作案的凶手十分狡猾, 现场没有留下什么有价值的线索. 不过万幸的是, 刚从隔壁回来的老王恰好在这时候无意中发现了凶手行凶的过程, 但是由于天色已晚, 加上凶手蒙着面, 老王并没有看清凶手的面目, 只知道凶手是个男性, 身高约七尺五寸. 爪哇县的县令根据老王的描述, 对守门的士兵下命令说: 凡是发现有身高七尺五寸的男性, 都要抓过来审问. 士兵当然不敢违背县令的命令, 只好把进出城的所有符合条件的人都抓了起来.</p>
<p>来让我们看一下上面的一个小故事和 AOP 到底有什么对应关系.<br>首先我们知道, 在 Spring AOP 中 join point 指代的是所有方法的执行点, 而 point cut 是一个描述信息, 它修饰的是 join point, 通过 point cut, 我们就可以确定哪些 join point 可以被织入 Advice. 对应到我们在上面举的例子, 我们可以做一个简单的类比, join point 就相当于 <strong>爪哇的小县城里的百姓</strong>, point cut 就相当于 <strong>老王所做的指控, 即凶手是个男性, 身高约七尺五寸</strong>, 而 advice 则是施加在符合老王所描述的嫌疑人的动作: <strong>抓过来审问</strong>.<br>为什么可以这样类比呢?</p>
<ul>
<li>join point –&gt; 爪哇的小县城里的百姓: 因为根据定义, join point 是所有可能被织入 advice 的候选的点, 在 Spring AOP 中, 则可以认为所有方法执行点都是 join point. 而在我们上面的例子中, 命案发生在小县城中, 按理说在此县城中的所有人都有可能是嫌疑人.</li>
<li>point cut –&gt; 男性, 身高约七尺五寸: 我们知道, 所有的方法(joint point) 都可以织入 advice, 但是我们并不希望在所有方法上都织入 advice, 而 pointcut 的作用就是提供一组规则来匹配 joinpoint, 给满足规则的 joinpoint 添加 advice. 同理, 对于县令来说, 他再昏庸, 也知道不能把县城中的所有百姓都抓起来审问, 而是根据<code>凶手是个男性, 身高约七尺五寸</code>, 把符合条件的人抓起来. 在这里<code>凶手是个男性, 身高约七尺五寸</code> 就是一个修饰谓语, 它限定了凶手的范围, 满足此修饰规则的百姓都是嫌疑人, 都需要抓起来审问.</li>
<li>advice –&gt; 抓过来审问, advice 是一个动作, 即一段 Java 代码, 这段 Java 代码是作用于 point cut 所限定的那些 join point 上的. 同理, 对比到我们的例子中, <code>抓过来审问</code> 这个动作就是对作用于那些满足 <code>男性, 身高约七尺五寸</code> 的<code>爪哇的小县城里的百姓</code>.</li>
<li>aspect: aspect 是 point cut 与 advice 的组合, 因此在这里我们就可以类比: <strong>“根据老王的线索, 凡是发现有身高七尺五寸的男性, 都要抓过来审问”</strong> 这一整个动作可以被认为是一个 aspect.</li>
</ul>
<p>或则我们也可以从语法的角度来简单类比一下. 我们在学英语时, 经常会接触什么 <code>定语</code>, <code>被动句</code> 之类的概念, 那么可以做一个不严谨的类比, 即 <code>joinpoint</code> 可以认为是一个 <code>宾语</code>, 而 <code>pointcut</code> 则可以类比为修饰 <code>joinpoint</code> 的定语, 那么整个 <code>aspect</code> 就可以描述为: <code>满足 pointcut 规则的 joinpoint 会被添加相应的 advice 操作.</code></p>
<h2 id="AspectJ-支持"><a href="#AspectJ-支持" class="headerlink" title="@AspectJ 支持"></a>@AspectJ 支持</h2><p><strong><code>@AspectJ</code></strong> 是一种使用 Java 注解来实现 AOP 的编码风格。</p>
<p>@AspectJ 风格的 AOP 是 AspectJ Project 在 AspectJ 5 中引入的, 并且 Spring 也支持 @AspectJ 的 AOP 风格.</p>
<h3 id="使能-AspectJ-支持"><a href="#使能-AspectJ-支持" class="headerlink" title="使能 @AspectJ 支持"></a>使能 @AspectJ 支持</h3><p>@AspectJ 可以以 XML 的方式或以注解的方式来使能, 并且不论以哪种方式使能@ASpectJ, 我们都必须保证 aspectjweaver.jar 在 classpath 中.</p>
<h4 id="使用-Java-Configuration-方式使能-AspectJ"><a href="#使用-Java-Configuration-方式使能-AspectJ" class="headerlink" title="使用 Java Configuration 方式使能@AspectJ"></a>使用 Java Configuration 方式使能@AspectJ</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableAspectJAutoProxy</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AppConfig</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用-XML-方式使能-AspectJ"><a href="#使用-XML-方式使能-AspectJ" class="headerlink" title="使用 XML 方式使能@AspectJ"></a>使用 XML 方式使能@AspectJ</h4><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;aop:aspectj-<span class="built_in">auto</span>proxy/&gt;</span><br></pre></td></tr></table></figure>

<h3 id="定义-aspect-切面"><a href="#定义-aspect-切面" class="headerlink" title="定义 aspect(切面)"></a>定义 aspect(切面)</h3><p>当使用注解 <strong>@Aspect</strong> 标注一个 Bean 后, 那么 Spring 框架会自动收集这些 Bean, 并添加到 Spring AOP 中, 例如:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyTest</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>注意, 仅仅使用@Aspect 注解, 并不能将一个 Java 对象转换为 Bean, 因此我们还需要使用类似 @Component 之类的注解.</code><br><code>注意, 如果一个 类被@Aspect 标注, 则这个类就不能是其他 aspect 的 **advised object** 了, 因为使用 @Aspect 后, 这个类就会被排除在 auto-proxying 机制之外.</code></p>
<h3 id="声明-pointcut"><a href="#声明-pointcut" class="headerlink" title="声明 pointcut"></a>声明 pointcut</h3><p>一个 pointcut 的声明由两部分组成:</p>
<ul>
<li>一个方法签名, 包括方法名和相关参数</li>
<li>一个 pointcut 表达式, 用来指定哪些方法执行是我们感兴趣的(即因此可以织入 advice).</li>
</ul>
<p>在@AspectJ 风格的 AOP 中, 我们使用一个方法来描述 pointcut, 即:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Pointcut(&quot;execution(* com.xys.service.UserService.*(..))&quot;)</span> <span class="comment">// 切点表达式</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">dataAccessOperation</span><span class="params">()</span> &#123;&#125; <span class="comment">// 切点前面</span></span><br></pre></td></tr></table></figure>

<p><code>这个方法必须无返回值.</code><br><code>这个方法本身就是 pointcut signature, pointcut 表达式使用@Pointcut 注解指定.</code><br>上面我们简单地定义了一个 pointcut, 这个 pointcut 所描述的是: 匹配所有在包 <strong>com.xys.service.UserService</strong> 下的所有方法的执行.</p>
<h4 id="切点标志符-designator"><a href="#切点标志符-designator" class="headerlink" title="切点标志符(designator)"></a>切点标志符(designator)</h4><p>AspectJ5 的切点表达式由标志符(designator)和操作参数组成. 如 “execution(* greetTo(..))” 的切点表达式, **execution** 就是 标志符, 而圆括号里的 *****greetTo(..) 就是操作参数</p>
<h5 id="execution"><a href="#execution" class="headerlink" title="execution"></a>execution</h5><p>匹配 join point 的执行, 例如 “execution(* hello(..))” 表示匹配所有目标类中的 hello() 方法. 这个是最基本的 pointcut 标志符.</p>
<h5 id="within"><a href="#within" class="headerlink" title="within"></a>within</h5><p>匹配特定包下的所有 join point, 例如 <code>within(com.xys.*)</code> 表示 com.xys 包中的所有连接点, 即包中的所有类的所有方法. 而<code>within(com.xys.service.*Service)</code> 表示在 com.xys.service 包中所有以 Service 结尾的类的所有的连接点.</p>
<h5 id="this-与-target"><a href="#this-与-target" class="headerlink" title="this 与 target"></a>this 与 target</h5><p>this 的作用是匹配一个 bean, 这个 bean(Spring AOP proxy) 是一个给定类型的实例(instance of). 而 target 匹配的是一个目标对象(target object, 即需要织入 advice 的原始的类), 此对象是一个给定类型的实例(instance of).</p>
<h5 id="bean"><a href="#bean" class="headerlink" title="bean"></a>bean</h5><p>匹配 bean 名字为指定值的 bean 下的所有方法, 例如:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">bean</span><span class="params">(*Service)</span></span> <span class="comment">// 匹配名字后缀为 Service 的 bean 下的所有方法</span></span><br><span class="line"><span class="function"><span class="title">bean</span><span class="params">(myService)</span></span> <span class="comment">// 匹配名字为 myService 的 bean 下的所有方法</span></span><br></pre></td></tr></table></figure>

<h5 id="args"><a href="#args" class="headerlink" title="args"></a>args</h5><p>匹配参数满足要求的的方法.<br>例如:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Pointcut(&quot;within(com.xys.demo2.*)&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pointcut2</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before(value = &quot;pointcut2()  &amp;&amp;  args(name)&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">(String name)</span> &#123;</span><br><span class="line">    logger.info(<span class="string">&quot;---page: &#123;&#125;---&quot;</span>, name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NormalService</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Logger</span> <span class="variable">logger</span> <span class="operator">=</span> LoggerFactory.getLogger(getClass());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">someMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        logger.info(<span class="string">&quot;---NormalService: someMethod invoked---&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">test</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        logger.info(<span class="string">&quot;---NormalService: test invoked---&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;服务一切正常&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当 NormalService.test 执行时, 则 advice <code>doSomething</code> 就会执行, test 方法的参数 name 就会传递到 <code>doSomething</code> 中.</p>
<p>常用例子:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 匹配只有一个参数 name 的方法</span></span><br><span class="line"><span class="meta">@Before(value = &quot;aspectMethod()  &amp;&amp;  args(name)&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">(String name)</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配第一个参数为 name 的方法</span></span><br><span class="line"><span class="meta">@Before(value = &quot;aspectMethod()  &amp;&amp;  args(name, ..)&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">(String name)</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配第二个参数为 name 的方法</span></span><br><span class="line">Before(value = <span class="string">&quot;aspectMethod()  &amp;&amp;  args(*, name, ..)&quot;</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">(String name)</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="annotation"><a href="#annotation" class="headerlink" title="@annotation"></a>@annotation</h5><p>匹配由指定注解所标注的方法, 例如:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Pointcut(&quot;@annotation(com.xys.demo1.AuthChecker)&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pointcut</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>则匹配由注解 <code>AuthChecker</code> 所标注的方法.</p>
<h4 id="常见的切点表达式"><a href="#常见的切点表达式" class="headerlink" title="常见的切点表达式"></a>常见的切点表达式</h4><h5 id="匹配方法签名"><a href="#匹配方法签名" class="headerlink" title="匹配方法签名"></a>匹配方法签名</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 匹配指定包中的所有的方法</span></span><br><span class="line"><span class="function"><span class="title">execution</span><span class="params">(* com.xys.service.*(..)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配当前包中的指定类的所有方法</span></span><br><span class="line"><span class="function"><span class="title">execution</span><span class="params">(* UserService.*(..)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配指定包中的所有 public 方法</span></span><br><span class="line"><span class="function"><span class="title">execution</span><span class="params">(public * com.xys.service.*(..)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配指定包中的所有 public 方法, 并且返回值是 int 类型的方法</span></span><br><span class="line"><span class="function"><span class="title">execution</span><span class="params">(public int com.xys.service.*(..)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配指定包中的所有 public 方法, 并且第一个参数是 String, 返回值是 int 类型的方法</span></span><br><span class="line"><span class="function"><span class="title">execution</span><span class="params">(public int com.xys.service.*(String name, ..)</span></span>)</span><br></pre></td></tr></table></figure>

<h5 id="匹配类型签名"><a href="#匹配类型签名" class="headerlink" title="匹配类型签名"></a>匹配类型签名</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 匹配指定包中的所有的方法, 但不包括子包</span></span><br><span class="line"><span class="function"><span class="title">within</span><span class="params">(com.xys.service.*)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配指定包中的所有的方法, 包括子包</span></span><br><span class="line"><span class="function"><span class="title">within</span><span class="params">(com.xys.service..*)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配当前包中的指定类中的方法</span></span><br><span class="line"><span class="function"><span class="title">within</span><span class="params">(UserService)</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配一个接口的所有实现类中的实现的方法</span></span><br><span class="line"><span class="function"><span class="title">within</span><span class="params">(UserDao+)</span></span></span><br></pre></td></tr></table></figure>

<h5 id="匹配-Bean-名字"><a href="#匹配-Bean-名字" class="headerlink" title="匹配 Bean 名字"></a>匹配 Bean 名字</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 匹配以指定名字结尾的 Bean 中的所有方法</span></span><br><span class="line"><span class="function"><span class="title">bean</span><span class="params">(*Service)</span></span></span><br></pre></td></tr></table></figure>

<h5 id="切点表达式组合"><a href="#切点表达式组合" class="headerlink" title="切点表达式组合"></a>切点表达式组合</h5><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 匹配以 Service 或 ServiceImpl 结尾的 bean</span></span><br><span class="line">bean<span class="comment">(*Service || *ServiceImpl)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">// 匹配名字以 Service 结尾, 并且在包 com.xys.service 中的 bean</span></span><br><span class="line"><span class="comment">bean(*Service) &amp;&amp; within(com.xys.service.*)</span></span><br></pre></td></tr></table></figure>

<h3 id="声明-advice"><a href="#声明-advice" class="headerlink" title="声明 advice"></a>声明 advice</h3><p>advice 是和一个 pointcut 表达式关联在一起的, 并且会在匹配的 join point 的方法执行的前&#x2F;后&#x2F;周围 运行. <code>pointcut 表达式可以是简单的一个 pointcut 名字的引用, 或者是完整的 pointcut 表达式</code>.<br>下面我们以几个简单的 advice 为例子, 来看一下一个 advice 是如何声明的.</p>
<h4 id="Before-advice"><a href="#Before-advice" class="headerlink" title="Before advice"></a>Before advice</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> xiongyongshun</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@created</span> 16/9/9 13:13</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BeforeAspectTest</span> &#123;</span><br><span class="line">    <span class="comment">// 定义一个 Pointcut, 使用 切点表达式函数 来描述对哪些 Join point 使用 advise.</span></span><br><span class="line">    <span class="meta">@Pointcut(&quot;execution(* com.xys.service.UserService.*(..))&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dataAccessOperation</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdviseDefine</span> &#123;</span><br><span class="line">    <span class="comment">// 定义 advise</span></span><br><span class="line">    <span class="meta">@Before(&quot;com.xys.aspect.PointcutDefine.dataAccessOperation()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doBeforeAccessCheck</span><span class="params">(JoinPoint joinPoint)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;*****Before advise, method: &quot;</span> + joinPoint.getSignature().toShortString() + <span class="string">&quot; *****&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里, <strong>@Before</strong> 引用了一个 pointcut, 即 “com.xys.aspect.PointcutDefine.dataAccessOperation()” 是一个 pointcut 的名字.<br>如果我们在 advice 在内置 pointcut, 则可以:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdviseDefine</span> &#123;</span><br><span class="line">    <span class="comment">// 将 pointcut 和 advice 同时定义</span></span><br><span class="line">    <span class="meta">@Before(&quot;within(com.xys.service..*)&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doAccessCheck</span><span class="params">(JoinPoint joinPoint)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;*****doAccessCheck, Before advise, method: &quot;</span> + joinPoint.getSignature().toShortString() + <span class="string">&quot; *****&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="around-advice"><a href="#around-advice" class="headerlink" title="around advice"></a>around advice</h4><p>around advice 比较特别, 它可以在一个方法的之前之前和之后添加不同的操作, 并且甚至可以决定何时, 如何, 是否调用匹配到的方法.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdviseDefine</span> &#123;</span><br><span class="line">    <span class="comment">// 定义 advise</span></span><br><span class="line">    <span class="meta">@Around(&quot;com.xys.aspect.PointcutDefine.dataAccessOperation()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">doAroundAccessCheck</span><span class="params">(ProceedingJoinPoint pjp)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">        <span class="type">StopWatch</span> <span class="variable">stopWatch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StopWatch</span>();</span><br><span class="line">        stopWatch.start();</span><br><span class="line">        <span class="comment">// 开始</span></span><br><span class="line">        <span class="type">Object</span> <span class="variable">retVal</span> <span class="operator">=</span> pjp.proceed();</span><br><span class="line">        stopWatch.stop();</span><br><span class="line">        <span class="comment">// 结束</span></span><br><span class="line">        System.out.println(<span class="string">&quot;invoke method: &quot;</span> + pjp.getSignature().getName() + <span class="string">&quot;, elapsed time: &quot;</span> + stopWatch.getTotalTimeMillis());</span><br><span class="line">        <span class="keyword">return</span> retVal;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>around advice 和前面的 before advice 差不多, 只是我们把注解 <strong>@Before</strong> 改为了 <strong>@Around</strong> 了.</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://item.jd.com/11899370.html">《 Spring 实战（第 4 版）》</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/e1b37c/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/e1b37c/" class="post-title-link" itemprop="url">Hive 入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-02-24 21:14:47" itemprop="dateCreated datePublished" datetime="2020-02-24T21:14:47+08:00">2020-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hive/" itemprop="url" rel="index"><span itemprop="name">hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-入门"><a href="#Hive-入门" class="headerlink" title="Hive 入门"></a>Hive 入门</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Hive 是一个构建在 Hadoop 之上的数据仓库，它可以将结构化的数据文件映射成表，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。</p>
<p><strong>特点</strong>：</p>
<ol>
<li>简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很好地进行大数据分析；</li>
<li>灵活性高，可以自定义用户函数 (UDF) 和存储格式；</li>
<li>为超大的数据集设计的计算和存储能力，集群扩展容易;</li>
<li>统一的元数据管理，可与 presto／impala／sparksql 等共享数据；</li>
<li>执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。</li>
</ol>
<h2 id="Hive-的体系架构"><a href="#Hive-的体系架构" class="headerlink" title="Hive 的体系架构"></a>Hive 的体系架构</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200224193019.png" alt="img"></p>
<h3 id="command-line-shell-thrift-jdbc"><a href="#command-line-shell-thrift-jdbc" class="headerlink" title="command-line shell &amp; thrift&#x2F;jdbc"></a>command-line shell &amp; thrift&#x2F;jdbc</h3><p>可以用 command-line shell 和 thrift／jdbc 两种方式来操作数据：</p>
<ul>
<li><strong>command-line shell</strong>：通过 hive 命令行的的方式来操作数据；</li>
<li><strong>thrift／jdbc</strong>：通过 thrift 协议按照标准的 JDBC 的方式操作数据。</li>
</ul>
<h3 id="Metastore"><a href="#Metastore" class="headerlink" title="Metastore"></a>Metastore</h3><p>在 Hive 中，表名、表结构、字段名、字段类型、表的分隔符等统一被称为元数据。所有的元数据默认存储在 Hive 内置的 derby 数据库中，但由于 derby 只能有一个实例，也就是说不能有多个命令行客户端同时访问，所以在实际生产环境中，通常使用 MySQL 代替 derby。</p>
<p>Hive 进行的是统一的元数据管理，就是说你在 Hive 上创建了一张表，然后在 presto／impala／sparksql 中都是可以直接使用的，它们会从 Metastore 中获取统一的元数据信息，同样的你在 presto／impala／sparksql 中创建一张表，在 Hive 中也可以直接使用。</p>
<h3 id="HQL-的执行流程"><a href="#HQL-的执行流程" class="headerlink" title="HQL 的执行流程"></a>HQL 的执行流程</h3><p>Hive 在执行一条 HQL 的时候，会经过以下步骤：</p>
<ol>
<li>语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象 语法树 AST Tree；</li>
<li>语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；</li>
<li>生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree；</li>
<li>优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量；</li>
<li>生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务；</li>
<li>优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。</li>
</ol>
<blockquote>
<p>关于 Hive SQL 的详细执行流程可以参考美团技术团队的文章：<a target="_blank" rel="noopener" href="https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html">Hive SQL 的编译过程</a></p>
</blockquote>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><p>Hive 表中的列支持以下基本数据类型：</p>
<table>
<thead>
<tr>
<th>大类</th>
<th>类型</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Integers（整型）</strong></td>
<td>TINYINT—1 字节的有符号整数 <br/>SMALLINT—2 字节的有符号整数<br/> INT—4 字节的有符号整数<br/> BIGINT—8 字节的有符号整数</td>
</tr>
<tr>
<td><strong>Boolean（布尔型）</strong></td>
<td>BOOLEAN—TRUE&#x2F;FALSE</td>
</tr>
<tr>
<td><strong>Floating point numbers（浮点型）</strong></td>
<td>FLOAT— 单精度浮点型 <br/>DOUBLE—双精度浮点型</td>
</tr>
<tr>
<td><strong>Fixed point numbers（定点数）</strong></td>
<td>DECIMAL—用户自定义精度定点数，比如 DECIMAL(7,2)</td>
</tr>
<tr>
<td><strong>String types（字符串）</strong></td>
<td>STRING—指定字符集的字符序列<br/> VARCHAR—具有最大长度限制的字符序列 <br/>CHAR—固定长度的字符序列</td>
</tr>
<tr>
<td><strong>Date and time types（日期时间类型）</strong></td>
<td>TIMESTAMP — 时间戳 <br/>TIMESTAMP WITH LOCAL TIME ZONE — 时间戳，纳秒精度<br/> DATE—日期类型</td>
</tr>
<tr>
<td><strong>Binary types（二进制类型）</strong></td>
<td>BINARY—字节序列</td>
</tr>
</tbody></table>
<blockquote>
<p>TIMESTAMP 和 TIMESTAMP WITH LOCAL TIME ZONE 的区别如下：</p>
<ul>
<li><strong>TIMESTAMP WITH LOCAL TIME ZONE</strong>：用户提交时间给数据库时，会被转换成数据库所在的时区来保存。查询时则按照查询客户端的不同，转换为查询客户端所在时区的时间。</li>
<li><strong>TIMESTAMP</strong> ：提交什么时间就保存什么时间，查询时也不做任何转换。</li>
</ul>
</blockquote>
<h3 id="隐式转换"><a href="#隐式转换" class="headerlink" title="隐式转换"></a>隐式转换</h3><p>Hive 中基本数据类型遵循以下的层次结构，按照这个层次结构，子类型到祖先类型允许隐式转换。例如 INT 类型的数据允许隐式转换为 BIGINT 类型。额外注意的是：按照类型层次结构允许将 STRING 类型隐式转换为 DOUBLE 类型。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200224193613.png" alt="img"></p>
<h3 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h3><table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td><strong>STRUCT</strong></td>
<td>类似于对象，是字段的集合，字段的类型可以不同，可以使用 <code>名称.字段名</code> 方式进行访问</td>
<td>STRUCT (‘xiaoming’, 12 , ‘2018-12-12’)</td>
</tr>
<tr>
<td><strong>MAP</strong></td>
<td>键值对的集合，可以使用 <code>名称[key]</code> 的方式访问对应的值</td>
<td>map(‘a’, 1, ‘b’, 2)</td>
</tr>
<tr>
<td><strong>ARRAY</strong></td>
<td>数组是一组具有相同类型和名称的变量的集合，可以使用 <code>名称[index]</code> 访问对应的值</td>
<td>ARRAY(‘a’, ‘b’, ‘c’, ‘d’)</td>
</tr>
</tbody></table>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>如下给出一个基本数据类型和复杂数据类型的使用示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> students(</span><br><span class="line">  name      STRING,   <span class="comment">-- 姓名</span></span><br><span class="line">  age       <span class="type">INT</span>,      <span class="comment">-- 年龄</span></span><br><span class="line">  subject   <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span>,   <span class="comment">--学科</span></span><br><span class="line">  score     MAP<span class="operator">&lt;</span>STRING,<span class="type">FLOAT</span><span class="operator">&gt;</span>,  <span class="comment">--各个学科考试成绩</span></span><br><span class="line">  address   STRUCT<span class="operator">&lt;</span>houseNumber:<span class="type">int</span>, street:STRING, city:STRING, province：STRING<span class="operator">&gt;</span>  <span class="comment">--家庭居住地址</span></span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;;</span><br></pre></td></tr></table></figure>

<h2 id="内容格式"><a href="#内容格式" class="headerlink" title="内容格式"></a>内容格式</h2><p>当数据存储在文本文件中，必须按照一定格式区别行和列，如使用逗号作为分隔符的 CSV 文件 (Comma-Separated Values) 或者使用制表符作为分隔值的 TSV 文件 (Tab-Separated Values)。但此时也存在一个缺点，就是正常的文件内容中也可能出现逗号或者制表符。</p>
<p>所以 Hive 默认使用了几个平时很少出现的字符，这些字符一般不会作为内容出现在文件中。Hive 默认的行和列分隔符如下表所示。</p>
<table>
<thead>
<tr>
<th>分隔符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>\n</strong></td>
<td>对于文本文件来说，每行是一条记录，所以可以使用换行符来分割记录</td>
</tr>
<tr>
<td><strong>^A (Ctrl+A)</strong></td>
<td>分割字段 (列)，在 CREATE TABLE 语句中也可以使用八进制编码 <code>\001</code> 来表示</td>
</tr>
<tr>
<td><strong>^B</strong></td>
<td>用于分割 ARRAY 或者 STRUCT 中的元素，或者用于 MAP 中键值对之间的分割，<br/>在 CREATE TABLE 语句中也可以使用八进制编码 <code>\002</code> 表示</td>
</tr>
<tr>
<td><strong>^C</strong></td>
<td>用于 MAP 中键和值之间的分割，在 CREATE TABLE 语句中也可以使用八进制编码 <code>\003</code> 表示</td>
</tr>
</tbody></table>
<p>使用示例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="type">INT</span>, userid <span class="type">BIGINT</span>)</span><br><span class="line"> <span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">   FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\001&#x27;</span></span><br><span class="line">   COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\002&#x27;</span></span><br><span class="line">   MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\003&#x27;</span></span><br><span class="line"> STORED <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>

<h2 id="存储格式"><a href="#存储格式" class="headerlink" title="存储格式"></a>存储格式</h2><h3 id="支持的存储格式"><a href="#支持的存储格式" class="headerlink" title="支持的存储格式"></a>支持的存储格式</h3><p>Hive 会在 HDFS 为每个数据库上创建一个目录，数据库中的表是该目录的子目录，表中的数据会以文件的形式存储在对应的表目录下。Hive 支持以下几种文件存储格式：</p>
<table>
<thead>
<tr>
<th>格式</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>TextFile</strong></td>
<td>存储为纯文本文件。 这是 Hive 默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。</td>
</tr>
<tr>
<td><strong>SequenceFile</strong></td>
<td>SequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以&lt;key,value&gt;的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。</td>
</tr>
<tr>
<td><strong>RCFile</strong></td>
<td>RCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。</td>
</tr>
<tr>
<td><strong>ORC Files</strong></td>
<td>ORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。</td>
</tr>
<tr>
<td><strong>Avro Files</strong></td>
<td>Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro 提供的机制使动态语言可以方便地处理 Avro 数据。</td>
</tr>
<tr>
<td><strong>Parquet</strong></td>
<td>Parquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了 IO 效率。</td>
</tr>
</tbody></table>
<blockquote>
<p>以上压缩格式中 ORC 和 Parquet 的综合性能突出，使用较为广泛，推荐使用这两种格式。</p>
</blockquote>
<h3 id="指定存储格式"><a href="#指定存储格式" class="headerlink" title="指定存储格式"></a>指定存储格式</h3><p>通常在创建表的时候使用 <code>STORED AS</code> 参数指定：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="type">INT</span>, userid <span class="type">BIGINT</span>)</span><br><span class="line"> <span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">   FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\001&#x27;</span></span><br><span class="line">   COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\002&#x27;</span></span><br><span class="line">   MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\003&#x27;</span></span><br><span class="line"> STORED <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>

<p>各个存储文件类型指定方式如下：</p>
<ul>
<li>STORED AS TEXTFILE</li>
<li>STORED AS SEQUENCEFILE</li>
<li>STORED AS ORC</li>
<li>STORED AS PARQUET</li>
<li>STORED AS AVRO</li>
<li>STORED AS RCFILE</li>
</ul>
<h2 id="内部表和外部表"><a href="#内部表和外部表" class="headerlink" title="内部表和外部表"></a>内部表和外部表</h2><p>内部表又叫做管理表 (Managed&#x2F;Internal Table)，创建表时不做任何指定，默认创建的就是内部表。想要创建外部表 (External Table)，则需要使用 External 进行修饰。 内部表和外部表主要区别如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>内部表</th>
<th>外部表</th>
</tr>
</thead>
<tbody><tr>
<td>数据存储位置</td>
<td>内部表数据存储的位置由 hive.metastore.warehouse.dir 参数指定，默认情况下表的数据存储在 HDFS 的 <code>/user/hive/warehouse/数据库名.db/表名/</code> 目录下</td>
<td>外部表数据的存储位置创建表时由 <code>Location</code> 参数指定；</td>
</tr>
<tr>
<td>导入数据</td>
<td>在导入数据到内部表，内部表将数据移动到自己的数据仓库目录下，数据的生命周期由 Hive 来进行管理</td>
<td>外部表不会将数据移动到自己的数据仓库目录下，只是在元数据中存储了数据的位置</td>
</tr>
<tr>
<td>删除表</td>
<td>删除元数据（metadata）和文件</td>
<td>只删除元数据（metadata）</td>
</tr>
</tbody></table>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">Hive Getting Started</a></li>
<li><a target="_blank" rel="noopener" href="https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html">Hive SQL 的编译过程</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">LanguageManual DDL</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types">LanguageManual Types</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables">Managed vs. External Tables</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/18eb58/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/18eb58/" class="post-title-link" itemprop="url">Hive 分区表和分桶表</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-02-24 21:14:47" itemprop="dateCreated datePublished" datetime="2020-02-24T21:14:47+08:00">2020-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hive/" itemprop="url" rel="index"><span itemprop="name">hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-分区表和分桶表"><a href="#Hive-分区表和分桶表" class="headerlink" title="Hive 分区表和分桶表"></a>Hive 分区表和分桶表</h1><h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Hive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。</p>
<p><strong>分区为 HDFS 上表目录的子目录</strong>，数据按照分区存储在子目录中。如果查询的 <code>where</code> 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。</p>
<blockquote>
<p>这里说明一下分区表并非 Hive 独有的概念，实际上这个概念非常常见。比如在我们常用的 Oracle 数据库中，当表中的数据量不断增大，查询数据的速度就会下降，这时也可以对表进行分区。表进行分区后，逻辑上表仍然是一张完整的表，只是将表中的数据存放到多个表空间（物理文件上），这样查询数据时，就不必要每次都扫描整张表，从而提升查询性能。</p>
</blockquote>
<h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>通常，在管理大规模数据集的时候都需要进行分区，比如将日志文件按天进行分区，从而保证数据细粒度的划分，使得查询性能得到提升。</p>
<h3 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h3><p>在 Hive 中可以使用 <code>PARTITIONED BY</code> 子句创建分区表。表可以包含一个或多个分区列，程序会为分区列中的每个不同值组合创建单独的数据目录。下面的我们创建一张雇员表作为测试：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> emp_partition(</span><br><span class="line">   empno <span class="type">INT</span>,</span><br><span class="line">   ename STRING,</span><br><span class="line">   job STRING,</span><br><span class="line">   mgr <span class="type">INT</span>,</span><br><span class="line">   hiredate <span class="type">TIMESTAMP</span>,</span><br><span class="line">   sal <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">   comm <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>)</span><br><span class="line">   )</span><br><span class="line">   PARTITIONED <span class="keyword">BY</span> (deptno <span class="type">INT</span>)   <span class="comment">-- 按照部门编号进行分区</span></span><br><span class="line">   <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;</span><br><span class="line">   LOCATION <span class="string">&#x27;/hive/emp_partition&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="加载数据到分区表"><a href="#加载数据到分区表" class="headerlink" title="加载数据到分区表"></a>加载数据到分区表</h3><p>加载数据到分区表时候必须要指定数据所处的分区：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载部门编号为20的数据到表中</span></span><br><span class="line">LOAD DATA LOCAL INPATH &quot;/usr/file/emp20.txt&quot; OVERWRITE INTO TABLE emp_partition PARTITION (deptno=20)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载部门编号为30的数据到表中</span></span><br><span class="line">LOAD DATA LOCAL INPATH &quot;/usr/file/emp30.txt&quot; OVERWRITE INTO TABLE emp_partition PARTITION (deptno=30)</span><br></pre></td></tr></table></figure>

<h3 id="查看分区目录"><a href="#查看分区目录" class="headerlink" title="查看分区目录"></a>查看分区目录</h3><p>这时候我们直接查看表目录，可以看到表目录下存在两个子目录，分别是 <code>deptno=20</code> 和 <code>deptno=30</code>,这就是分区目录，分区目录下才是我们加载的数据文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop fs -<span class="built_in">ls</span>  hdfs://hadoop001:8020/hive/emp_partition/</span></span><br></pre></td></tr></table></figure>

<p>这时候当你的查询语句的 <code>where</code> 包含 <code>deptno=20</code>，则就去对应的分区目录下进行查找，而不用扫描全表。</p>
<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-hadoop-partitation.png" alt="img"></p>
<h2 id="分桶表"><a href="#分桶表" class="headerlink" title="分桶表"></a>分桶表</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>分区提供了一个隔离数据和优化查询的可行方案，但是并非所有的数据集都可以形成合理的分区，分区的数量也不是越多越好，过多的分区条件可能会导致很多分区上没有数据。同时 Hive 会限制动态分区可以创建的最大分区数，用来避免过多分区文件对文件系统产生负担。鉴于以上原因，Hive 还提供了一种更加细粒度的数据拆分方案：分桶表 (bucket Table)。</p>
<p>分桶表会将指定列的值进行哈希散列，并对 bucket（桶数量）取余，然后存储到对应的 bucket（桶）中。</p>
<h3 id="理解分桶表"><a href="#理解分桶表" class="headerlink" title="理解分桶表"></a>理解分桶表</h3><p>单从概念上理解分桶表可能会比较晦涩，其实和分区一样，分桶这个概念同样不是 Hive 独有的，对于 Java 开发人员而言，这可能是一个每天都会用到的概念，因为 Hive 中的分桶概念和 Java 数据结构中的 HashMap 的分桶概念是一致的。</p>
<p>当调用 HashMap 的 put() 方法存储数据时，程序会先对 key 值调用 hashCode() 方法计算出 hashcode，然后对数组长度取模计算出 index，最后将数据存储在数组 index 位置的链表上，链表达到一定阈值后会转换为红黑树 (JDK1.8+)。下图为 HashMap 的数据结构图：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200224194352.png" alt="img"></p>
<p>图片引用自：<a target="_blank" rel="noopener" href="http://www.itcuties.com/java/hashmap-hashtable/">HashMap vs. Hashtable</a></p>
<h3 id="创建分桶表"><a href="#创建分桶表" class="headerlink" title="创建分桶表"></a>创建分桶表</h3><p>在 Hive 中，我们可以通过 <code>CLUSTERED BY</code> 指定分桶列，并通过 <code>SORTED BY</code> 指定桶中数据的排序参考列。下面为分桶表建表语句示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> emp_bucket(</span><br><span class="line">  empno <span class="type">INT</span>,</span><br><span class="line">  ename STRING,</span><br><span class="line">  job STRING,</span><br><span class="line">  mgr <span class="type">INT</span>,</span><br><span class="line">  hiredate <span class="type">TIMESTAMP</span>,</span><br><span class="line">  sal <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">  comm <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">  deptno <span class="type">INT</span>)</span><br><span class="line">  CLUSTERED <span class="keyword">BY</span>(empno) SORTED <span class="keyword">BY</span>(empno <span class="keyword">ASC</span>) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS  <span class="comment">--按照员工编号散列到四个 bucket 中</span></span><br><span class="line">  <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;</span><br><span class="line">  LOCATION <span class="string">&#x27;/hive/emp_bucket&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="加载数据到分桶表"><a href="#加载数据到分桶表" class="headerlink" title="加载数据到分桶表"></a>加载数据到分桶表</h3><p>这里直接使用 <code>Load</code> 语句向分桶表加载数据，数据时可以加载成功的，但是数据并不会分桶。</p>
<p>这是由于分桶的实质是对指定字段做了 hash 散列然后存放到对应文件中，这意味着向分桶表中插入数据是必然要通过 MapReduce，且 Reducer 的数量必须等于分桶的数量。由于以上原因，分桶表的数据通常只能使用 CTAS(CREATE TABLE AS SELECT) 方式插入，因为 CTAS 操作会触发 MapReduce。加载数据步骤如下：</p>
<h4 id="设置强制分桶"><a href="#设置强制分桶" class="headerlink" title="设置强制分桶"></a>设置强制分桶</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing <span class="operator">=</span> <span class="literal">true</span>; <span class="comment">--Hive 2.x 不需要这一步</span></span><br></pre></td></tr></table></figure>

<p>在 Hive 0.x and 1.x 版本，必须使用设置 <code>hive.enforce.bucketing = true</code>，表示强制分桶，允许程序根据表结构自动选择正确数量的 Reducer 和 cluster by column 来进行分桶。</p>
<h4 id="CTAS-导入数据"><a href="#CTAS-导入数据" class="headerlink" title="CTAS 导入数据"></a>CTAS 导入数据</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> emp_bucket <span class="keyword">SELECT</span> <span class="operator">*</span>  <span class="keyword">FROM</span> emp;  <span class="comment">--这里的 emp 表就是一张普通的雇员表</span></span><br></pre></td></tr></table></figure>

<p>可以从执行日志看到 CTAS 触发 MapReduce 操作，且 Reducer 数量和建表时候指定 bucket 数量一致：</p>
<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-hadoop-mapreducer.png" alt="img"></p>
<h3 id="查看分桶文件"><a href="#查看分桶文件" class="headerlink" title="查看分桶文件"></a>查看分桶文件</h3><p>bucket(桶) 本质上就是表目录下的具体文件：</p>
<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-hadoop-bucket.png" alt="img"></p>
<h2 id="分区表和分桶表结合使用"><a href="#分区表和分桶表结合使用" class="headerlink" title="分区表和分桶表结合使用"></a>分区表和分桶表结合使用</h2><p>分区表和分桶表的本质都是将数据按照不同粒度进行拆分，从而使得在查询时候不必扫描全表，只需要扫描对应的分区或分桶，从而提升查询效率。两者可以结合起来使用，从而保证表数据在不同粒度上都能得到合理的拆分。下面是 Hive 官方给出的示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view_bucketed(</span><br><span class="line">	viewTime <span class="type">INT</span>,</span><br><span class="line">    userid <span class="type">BIGINT</span>,</span><br><span class="line">    page_url STRING,</span><br><span class="line">    referrer_url STRING,</span><br><span class="line">    ip STRING )</span><br><span class="line"> PARTITIONED <span class="keyword">BY</span>(dt STRING)</span><br><span class="line"> CLUSTERED <span class="keyword">BY</span>(userid) SORTED <span class="keyword">BY</span>(viewTime) <span class="keyword">INTO</span> <span class="number">32</span> BUCKETS</span><br><span class="line"> <span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">   FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\001&#x27;</span></span><br><span class="line">   COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\002&#x27;</span></span><br><span class="line">   MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\003&#x27;</span></span><br><span class="line"> STORED <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>

<p>此时导入数据时需要指定分区：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE page_view_bucketed</span><br><span class="line">PARTITION (dt=&#x27;2009-02-25&#x27;)</span><br><span class="line">SELECT * FROM page_view WHERE dt=&#x27;2009-02-25&#x27;;</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables">LanguageManual DDL BucketedTables</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/5e2d71/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/5e2d71/" class="post-title-link" itemprop="url">Hive 视图和索引</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-02-24 21:14:47" itemprop="dateCreated datePublished" datetime="2020-02-24T21:14:47+08:00">2020-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hive/" itemprop="url" rel="index"><span itemprop="name">hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-视图和索引"><a href="#Hive-视图和索引" class="headerlink" title="Hive 视图和索引"></a>Hive 视图和索引</h1><h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Hive 中的视图和 RDBMS 中视图的概念一致，都是一组数据的逻辑表示，本质上就是一条 SELECT 语句的结果集。视图是纯粹的逻辑对象，没有关联的存储 (Hive 3.0.0 引入的物化视图除外)，当查询引用视图时，Hive 可以将视图的定义与查询结合起来，例如将查询中的过滤器推送到视图中。</p>
<h3 id="创建视图"><a href="#创建视图" class="headerlink" title="创建视图"></a>创建视图</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]view_name   <span class="comment">-- 视图名称</span></span><br><span class="line">  [(column_name [COMMENT column_comment], ...) ]    <span class="comment">--列名</span></span><br><span class="line">  [COMMENT view_comment]  <span class="comment">--视图注释</span></span><br><span class="line">  [TBLPROPERTIES (property_name <span class="operator">=</span> property_value, ...)]  <span class="comment">--额外信息</span></span><br><span class="line">  <span class="keyword">AS</span> <span class="keyword">SELECT</span> ...;</span><br></pre></td></tr></table></figure>

<p>在 Hive 中可以使用 <code>CREATE VIEW</code> 创建视图，如果已存在具有相同名称的表或视图，则会抛出异常，建议使用 <code>IF NOT EXISTS</code> 预做判断。在使用视图时候需要注意以下事项：</p>
<ul>
<li><p>视图是只读的，不能用作 <code>LOAD</code> &#x2F; <code>INSERT</code> &#x2F; <code>ALTER</code> 的目标；</p>
</li>
<li><p>在创建视图时候视图就已经固定，对基表的后续更改（如添加列）将不会反映在视图；</p>
</li>
<li><p>删除基表并不会删除视图，需要手动删除视图；</p>
</li>
<li><p>视图可能包含 <code>ORDER BY</code> 和 <code>LIMIT</code> 子句。如果引用视图的查询语句也包含这类子句，其执行优先级低于视图对应字句。例如，视图 <code>custom_view</code> 指定 LIMIT 5，查询语句为 <code>select * from custom_view LIMIT 10</code>，此时结果最多返回 5 行。</p>
</li>
<li><p>创建视图时，如果未提供列名，则将从 SELECT 语句中自动派生列名；</p>
</li>
<li><p>创建视图时，如果 SELECT 语句中包含其他表达式，例如 x + y，则列名称将以_C0，_C1 等形式生成；</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span>  IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> custom_view <span class="keyword">AS</span> <span class="keyword">SELECT</span> empno, empno<span class="operator">+</span>deptno , <span class="number">1</span><span class="operator">+</span><span class="number">2</span> <span class="keyword">FROM</span> emp;</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-1-2-view.png" alt="img"></p>
<h3 id="查看视图"><a href="#查看视图" class="headerlink" title="查看视图"></a>查看视图</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看所有视图： 没有单独查看视图列表的语句，只能使用 show tables</span></span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="comment">-- 查看某个视图</span></span><br><span class="line"><span class="keyword">desc</span> view_name;</span><br><span class="line"><span class="comment">-- 查看某个视图详细信息</span></span><br><span class="line"><span class="keyword">desc</span> formatted view_name;</span><br></pre></td></tr></table></figure>

<h3 id="删除视图"><a href="#删除视图" class="headerlink" title="删除视图"></a>删除视图</h3><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> [<span class="keyword">IF</span> <span class="keyword">EXISTS</span>] [db_name.]view_name;</span><br></pre></td></tr></table></figure>

<p>删除视图时，如果被删除的视图被其他视图所引用，这时候程序不会发出警告，但是引用该视图其他视图已经失效，需要进行重建或者删除。</p>
<h3 id="修改视图"><a href="#修改视图" class="headerlink" title="修改视图"></a>修改视图</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> [db_name.]view_name <span class="keyword">AS</span> select_statement;</span><br></pre></td></tr></table></figure>

<p>被更改的视图必须存在，且视图不能具有分区，如果视图具有分区，则修改失败。</p>
<h3 id="修改视图属性"><a href="#修改视图属性" class="headerlink" title="修改视图属性"></a>修改视图属性</h3><p>语法：</p>
<figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> [db_name.]view_name <span class="keyword">SET</span> TBLPROPERTIES table_properties;</span><br><span class="line"></span><br><span class="line">table_properties:</span><br><span class="line">  : (property_name = property_value, property_name = property_value, ...)</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> custom_view <span class="keyword">SET</span> TBLPROPERTIES (<span class="string">&#x27;create&#x27;</span>=<span class="string">&#x27;heibaiying&#x27;</span>,<span class="string">&#x27;date&#x27;</span>=<span class="string">&#x27;2019-05-05&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-view-properties.png" alt="img"></p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h3><p>Hive 在 0.7.0 引入了索引的功能，索引的设计目标是提高表某些列的查询速度。如果没有索引，带有谓词的查询（如’WHERE table1.column &#x3D; 10’）会加载整个表或分区并处理所有行。但是如果 column 存在索引，则只需要加载和处理文件的一部分。</p>
<h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h3><p>在指定列上建立索引，会产生一张索引表（表结构如下），里面的字段包括：索引列的值、该值对应的 HDFS 文件路径、该值在文件中的偏移量。在查询涉及到索引字段时，首先到索引表查找索引列值对应的 HDFS 文件路径及偏移量，这样就避免了全表扫描。</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+--------------+----------------+----------+--+</span><br><span class="line">|<span class="string">   col_name   </span>|<span class="string">   data_type    </span>|<span class="string"> comment     </span>|</span><br><span class="line">+--------------+----------------+----------+--+</span><br><span class="line">|<span class="string"> empno        </span>|<span class="string"> int            </span>|<span class="string">  建立索引的列  </span>|</span><br><span class="line">|<span class="string"> _bucketname  </span>|<span class="string"> string         </span>|<span class="string">  HDFS 文件路径  </span>|</span><br><span class="line">|<span class="string"> _offsets     </span>|<span class="string"> array&lt;bigint&gt;  </span>|<span class="string">  偏移量       </span>|</span><br><span class="line">+--------------+----------------+----------+--+</span><br></pre></td></tr></table></figure>

<h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> INDEX index_name     <span class="comment">--索引名称</span></span><br><span class="line">  <span class="keyword">ON</span> <span class="keyword">TABLE</span> base_table_name (col_name, ...)  <span class="comment">--建立索引的列</span></span><br><span class="line">  <span class="keyword">AS</span> index_type    <span class="comment">--索引类型</span></span><br><span class="line">  [<span class="keyword">WITH</span> DEFERRED REBUILD]    <span class="comment">--重建索引</span></span><br><span class="line">  [IDXPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]  <span class="comment">--索引额外属性</span></span><br><span class="line">  [<span class="keyword">IN</span> <span class="keyword">TABLE</span> index_table_name]    <span class="comment">--索引表的名字</span></span><br><span class="line">  [</span><br><span class="line">     [ <span class="type">ROW</span> FORMAT ...] STORED <span class="keyword">AS</span> ...</span><br><span class="line">     <span class="operator">|</span> STORED <span class="keyword">BY</span> ...</span><br><span class="line">  ]   <span class="comment">--索引表行分隔符 、 存储格式</span></span><br><span class="line">  [LOCATION hdfs_path]  <span class="comment">--索引表存储位置</span></span><br><span class="line">  [TBLPROPERTIES (...)]   <span class="comment">--索引表表属性</span></span><br><span class="line">  [COMMENT &quot;index comment&quot;];  <span class="comment">--索引注释</span></span><br></pre></td></tr></table></figure>

<h3 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a>查看索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--显示表上所有列的索引</span></span><br><span class="line"><span class="keyword">SHOW</span> FORMATTED INDEX <span class="keyword">ON</span> table_name;</span><br></pre></td></tr></table></figure>

<h3 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h3><p>删除索引会删除对应的索引表。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> INDEX [IF <span class="keyword">EXISTS</span>] index_name <span class="keyword">ON</span> table_name;</span><br></pre></td></tr></table></figure>

<p>如果存在索引的表被删除了，其对应的索引和索引表都会被删除。如果被索引表的某个分区被删除了，那么分区对应的分区索引也会被删除。</p>
<h3 id="重建索引"><a href="#重建索引" class="headerlink" title="重建索引"></a>重建索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> INDEX index_name <span class="keyword">ON</span> table_name [<span class="keyword">PARTITION</span> partition_spec] REBUILD;</span><br></pre></td></tr></table></figure>

<p>重建索引。如果指定了 PARTITION，则仅重建该分区的索引。</p>
<h2 id="索引案例"><a href="#索引案例" class="headerlink" title="索引案例"></a>索引案例</h2><h3 id="创建索引-1"><a href="#创建索引-1" class="headerlink" title="创建索引"></a>创建索引</h3><p>在 emp 表上针对 <code>empno</code> 字段创建名为 <code>emp_index</code>,索引数据存储在 <code>emp_index_table</code> 索引表中</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> index emp_index <span class="keyword">on</span> <span class="keyword">table</span> emp(empno) <span class="keyword">as</span></span><br><span class="line"><span class="string">&#x27;org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> deferred rebuild</span><br><span class="line"><span class="keyword">in</span> <span class="keyword">table</span> emp_index_table ;</span><br></pre></td></tr></table></figure>

<p>此时索引表中是没有数据的，需要重建索引才会有索引的数据。</p>
<h3 id="重建索引-1"><a href="#重建索引-1" class="headerlink" title="重建索引"></a>重建索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> index emp_index <span class="keyword">on</span> emp rebuild;</span><br></pre></td></tr></table></figure>

<p>Hive 会启动 MapReduce 作业去建立索引，建立好后查看索引表数据如下。三个表字段分别代表：索引列的值、该值对应的 HDFS 文件路径、该值在文件中的偏移量。</p>
<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-index-table.png" alt="img"></p>
<h3 id="自动使用索引"><a href="#自动使用索引" class="headerlink" title="自动使用索引"></a>自动使用索引</h3><p>默认情况下，虽然建立了索引，但是 Hive 在查询时候是不会自动去使用索引的，需要开启相关配置。开启配置后，涉及到索引列的查询就会使用索引功能去优化查询。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.HiveInputFormat;</span><br><span class="line"><span class="keyword">SET</span> hive.optimize.index.filter<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">SET</span> hive.optimize.index.filter.compact.minsize<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<h3 id="查看索引-1"><a href="#查看索引-1" class="headerlink" title="查看索引"></a>查看索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> INDEX <span class="keyword">ON</span> emp;</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-index-show.png" alt="img"></p>
<h2 id="索引的缺陷"><a href="#索引的缺陷" class="headerlink" title="索引的缺陷"></a>索引的缺陷</h2><p>索引表最主要的一个缺陷在于：索引表无法自动 rebuild，这也就意味着如果表中有数据新增或删除，则必须手动 rebuild，重新执行 MapReduce 作业，生成索引表数据。</p>
<p>同时按照<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Indexing">官方文档</a> 的说明，Hive 会从 3.0 开始移除索引功能，主要基于以下两个原因：</p>
<ul>
<li>具有自动重写的物化视图 (Materialized View) 可以产生与索引相似的效果（Hive 2.3.0 增加了对物化视图的支持，在 3.0 之后正式引入）。</li>
<li>使用列式存储文件格式（Parquet，ORC）进行存储时，这些格式支持选择性扫描，可以跳过不需要的文件或块。</li>
</ul>
<blockquote>
<p>ORC 内置的索引功能可以参阅这篇文章：<a target="_blank" rel="noopener" href="http://lxw1234.com/archives/2016/04/632.htm">Hive 性能优化之 ORC 索引–Row Group Index vs Bloom Filter Index</a></p>
</blockquote>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Create/Drop/AlterView">Create&#x2F;Drop&#x2F;Alter View</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Materialized+views">Materialized views</a></li>
<li><a target="_blank" rel="noopener" href="http://lxw1234.com/archives/2015/05/207.htm">Hive 索引</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Indexing">Overview of Hive Indexes</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.ligoudan.cn/pages/b7b857/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/ligoudan.png">
      <meta itemprop="name" content="李狗蛋">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIGOUDAN">
      <meta itemprop="description" content="天气不错哇，你看这大冰雹下得">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LIGOUDAN">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/pages/b7b857/" class="post-title-link" itemprop="url">Hive 数据查询详解</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-02-24 21:14:47" itemprop="dateCreated datePublished" datetime="2020-02-24T21:14:47+08:00">2020-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-12 10:02:53" itemprop="dateModified" datetime="2024-12-12T10:02:53+08:00">2024-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hive/" itemprop="url" rel="index"><span itemprop="name">hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-数据查询详解"><a href="#Hive-数据查询详解" class="headerlink" title="Hive 数据查询详解"></a>Hive 数据查询详解</h1><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>为了演示查询操作，这里需要预先创建三张表，并加载测试数据。</p>
<blockquote>
<p>数据文件 emp.txt 和 dept.txt 可以从本仓库的<a target="_blank" rel="noopener" href="https://github.com/heibaiying/BigData-Notes/tree/master/resources">resources</a> 目录下载。</p>
</blockquote>
<h3 id="员工表"><a href="#员工表" class="headerlink" title="员工表"></a>员工表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">-- 建表语句</span></span><br><span class="line"> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> emp(</span><br><span class="line">     empno <span class="type">INT</span>,     <span class="comment">-- 员工表编号</span></span><br><span class="line">     ename STRING,  <span class="comment">-- 员工姓名</span></span><br><span class="line">     job STRING,    <span class="comment">-- 职位类型</span></span><br><span class="line">     mgr <span class="type">INT</span>,</span><br><span class="line">     hiredate <span class="type">TIMESTAMP</span>,  <span class="comment">--雇佣日期</span></span><br><span class="line">     sal <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>),  <span class="comment">--工资</span></span><br><span class="line">     comm <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">     deptno <span class="type">INT</span>)   <span class="comment">--部门编号</span></span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">--加载数据</span></span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/usr/file/emp.txt&quot; OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> emp;</span><br></pre></td></tr></table></figure>

<h3 id="部门表"><a href="#部门表" class="headerlink" title="部门表"></a>部门表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 建表语句</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dept(</span><br><span class="line">    deptno <span class="type">INT</span>,   <span class="comment">--部门编号</span></span><br><span class="line">    dname STRING,  <span class="comment">--部门名称</span></span><br><span class="line">    loc STRING    <span class="comment">--部门所在的城市</span></span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">--加载数据</span></span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/usr/file/dept.txt&quot; OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> dept;</span><br></pre></td></tr></table></figure>

<h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><p>这里需要额外创建一张分区表，主要是为了演示分区查询：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> emp_ptn(</span><br><span class="line">      empno <span class="type">INT</span>,</span><br><span class="line">      ename STRING,</span><br><span class="line">      job STRING,</span><br><span class="line">      mgr <span class="type">INT</span>,</span><br><span class="line">      hiredate <span class="type">TIMESTAMP</span>,</span><br><span class="line">      sal <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">      comm <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>)</span><br><span class="line">  )</span><br><span class="line"> PARTITIONED <span class="keyword">BY</span> (deptno <span class="type">INT</span>)   <span class="comment">-- 按照部门编号进行分区</span></span><br><span class="line"> <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">--加载数据</span></span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/usr/file/emp.txt&quot; OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> emp_ptn <span class="keyword">PARTITION</span> (deptno<span class="operator">=</span><span class="number">20</span>)</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/usr/file/emp.txt&quot; OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> emp_ptn <span class="keyword">PARTITION</span> (deptno<span class="operator">=</span><span class="number">30</span>)</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/usr/file/emp.txt&quot; OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> emp_ptn <span class="keyword">PARTITION</span> (deptno<span class="operator">=</span><span class="number">40</span>)</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/usr/file/emp.txt&quot; OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> emp_ptn <span class="keyword">PARTITION</span> (deptno<span class="operator">=</span><span class="number">50</span>)</span><br></pre></td></tr></table></figure>

<h2 id="单表查询"><a href="#单表查询" class="headerlink" title="单表查询"></a>单表查询</h2><h3 id="SELECT"><a href="#SELECT" class="headerlink" title="SELECT"></a>SELECT</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询表中全部数据</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp;</span><br></pre></td></tr></table></figure>

<h3 id="WHERE"><a href="#WHERE" class="headerlink" title="WHERE"></a>WHERE</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询 10 号部门中员工编号大于 7782 的员工信息</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">WHERE</span> empno <span class="operator">&gt;</span> <span class="number">7782</span> <span class="keyword">AND</span> deptno <span class="operator">=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<h3 id="DISTINCT"><a href="#DISTINCT" class="headerlink" title="DISTINCT"></a>DISTINCT</h3><p>Hive 支持使用 DISTINCT 关键字去重。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询所有工作类型</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> job <span class="keyword">FROM</span> emp;</span><br></pre></td></tr></table></figure>

<h3 id="分区查询"><a href="#分区查询" class="headerlink" title="分区查询"></a>分区查询</h3><p>分区查询 (Partition Based Queries)，可以指定某个分区或者分区范围。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询分区表中部门编号在[20,40]之间的员工</span></span><br><span class="line"><span class="keyword">SELECT</span> emp_ptn.<span class="operator">*</span> <span class="keyword">FROM</span> emp_ptn</span><br><span class="line"><span class="keyword">WHERE</span> emp_ptn.deptno <span class="operator">&gt;=</span> <span class="number">20</span> <span class="keyword">AND</span> emp_ptn.deptno <span class="operator">&lt;=</span> <span class="number">40</span>;</span><br></pre></td></tr></table></figure>

<h3 id="LIMIT"><a href="#LIMIT" class="headerlink" title="LIMIT"></a>LIMIT</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询薪资最高的 5 名员工</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">ORDER</span> <span class="keyword">BY</span> sal <span class="keyword">DESC</span> LIMIT <span class="number">5</span>;</span><br></pre></td></tr></table></figure>

<h3 id="GROUP-BY"><a href="#GROUP-BY" class="headerlink" title="GROUP BY"></a>GROUP BY</h3><p>Hive 支持使用 GROUP BY 进行分组聚合操作。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询各个部门薪酬综合</span></span><br><span class="line"><span class="keyword">SELECT</span> deptno,<span class="built_in">SUM</span>(sal) <span class="keyword">FROM</span> emp <span class="keyword">GROUP</span> <span class="keyword">BY</span> deptno;</span><br></pre></td></tr></table></figure>

<p><code>hive.map.aggr</code> 控制程序如何进行聚合。默认值为 false。如果设置为 true，Hive 会在 map 阶段就执行一次聚合。这可以提高聚合效率，但需要消耗更多内存。</p>
<h3 id="ORDER-AND-SORT"><a href="#ORDER-AND-SORT" class="headerlink" title="ORDER AND SORT"></a>ORDER AND SORT</h3><p>可以使用 ORDER BY 或者 Sort BY 对查询结果进行排序，排序字段可以是整型也可以是字符串：如果是整型，则按照大小排序；如果是字符串，则按照字典序排序。ORDER BY 和 SORT BY 的区别如下：</p>
<ul>
<li>使用 ORDER BY 时会有一个 Reducer 对全部查询结果进行排序，可以保证数据的全局有序性；</li>
<li>使用 SORT BY 时只会在每个 Reducer 中进行排序，这可以保证每个 Reducer 的输出数据是有序的，但不能保证全局有序。</li>
</ul>
<p>由于 ORDER BY 的时间可能很长，如果你设置了严格模式 (hive.mapred.mode &#x3D; strict)，则其后面必须再跟一个 <code>limit</code> 子句。</p>
<blockquote>
<p>注 ：hive.mapred.mode 默认值是 nonstrict ，也就是非严格模式。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询员工工资，结果按照部门升序，按照工资降序排列</span></span><br><span class="line"><span class="keyword">SELECT</span> empno, deptno, sal <span class="keyword">FROM</span> emp <span class="keyword">ORDER</span> <span class="keyword">BY</span> deptno <span class="keyword">ASC</span>, sal <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<h3 id="HAVING"><a href="#HAVING" class="headerlink" title="HAVING"></a>HAVING</h3><p>可以使用 HAVING 对分组数据进行过滤。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询工资总和大于 9000 的所有部门</span></span><br><span class="line"><span class="keyword">SELECT</span> deptno,<span class="built_in">SUM</span>(sal) <span class="keyword">FROM</span> emp <span class="keyword">GROUP</span> <span class="keyword">BY</span> deptno <span class="keyword">HAVING</span> <span class="built_in">SUM</span>(sal)<span class="operator">&gt;</span><span class="number">9000</span>;</span><br></pre></td></tr></table></figure>

<h3 id="DISTRIBUTE-BY"><a href="#DISTRIBUTE-BY" class="headerlink" title="DISTRIBUTE BY"></a>DISTRIBUTE BY</h3><p>默认情况下，MapReduce 程序会对 Map 输出结果的 Key 值进行散列，并均匀分发到所有 Reducer 上。如果想要把具有相同 Key 值的数据分发到同一个 Reducer 进行处理，这就需要使用 DISTRIBUTE BY 字句。</p>
<p>需要注意的是，DISTRIBUTE BY 虽然能保证具有相同 Key 值的数据分发到同一个 Reducer，但是不能保证数据在 Reducer 上是有序的。情况如下：</p>
<p>把以下 5 个数据发送到两个 Reducer 上进行处理：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">k1</span></span><br><span class="line"><span class="attr">k2</span></span><br><span class="line"><span class="attr">k4</span></span><br><span class="line"><span class="attr">k3</span></span><br><span class="line"><span class="attr">k1</span></span><br></pre></td></tr></table></figure>

<p>Reducer1 得到如下乱序数据：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">k1</span></span><br><span class="line"><span class="attr">k2</span></span><br><span class="line"><span class="attr">k1</span></span><br></pre></td></tr></table></figure>

<p>Reducer2 得到数据如下：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">k4</span></span><br><span class="line"><span class="attr">k3</span></span><br></pre></td></tr></table></figure>

<p>如果想让 Reducer 上的数据时有序的，可以结合 <code>SORT BY</code> 使用 (示例如下)，或者使用下面我们将要介绍的 CLUSTER BY。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 将数据按照部门分发到对应的 Reducer 上处理</span></span><br><span class="line"><span class="keyword">SELECT</span> empno, deptno, sal <span class="keyword">FROM</span> emp DISTRIBUTE <span class="keyword">BY</span> deptno SORT <span class="keyword">BY</span> deptno <span class="keyword">ASC</span>;</span><br></pre></td></tr></table></figure>

<h3 id="CLUSTER-BY"><a href="#CLUSTER-BY" class="headerlink" title="CLUSTER BY"></a>CLUSTER BY</h3><p>如果 <code>SORT BY</code> 和 <code>DISTRIBUTE BY</code> 指定的是相同字段，且 SORT BY 排序规则是 ASC，此时可以使用 <code>CLUSTER BY</code> 进行替换，同时 <code>CLUSTER BY</code> 可以保证数据在全局是有序的。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> empno, deptno, sal <span class="keyword">FROM</span> emp CLUSTER  <span class="keyword">BY</span> deptno ;</span><br></pre></td></tr></table></figure>

<h2 id="多表联结查询"><a href="#多表联结查询" class="headerlink" title="多表联结查询"></a>多表联结查询</h2><p>Hive 支持内连接，外连接，左外连接，右外连接，笛卡尔连接，这和传统数据库中的概念是一致的，可以参见下图。</p>
<p>需要特别强调：JOIN 语句的关联条件必须用 ON 指定，不能用 WHERE 指定，否则就会先做笛卡尔积，再过滤，这会导致你得不到预期的结果 (下面的演示会有说明)。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200224195733.png" alt="img"></p>
<h3 id="INNER-JOIN"><a href="#INNER-JOIN" class="headerlink" title="INNER JOIN"></a>INNER JOIN</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询员工编号为 7369 的员工的详细信息</span></span><br><span class="line"><span class="keyword">SELECT</span> e.<span class="operator">*</span>,d.<span class="operator">*</span> <span class="keyword">FROM</span></span><br><span class="line">emp e <span class="keyword">JOIN</span> dept d</span><br><span class="line"><span class="keyword">ON</span> e.deptno <span class="operator">=</span> d.deptno</span><br><span class="line"><span class="keyword">WHERE</span> empno<span class="operator">=</span><span class="number">7369</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--如果是三表或者更多表连接，语法如下</span></span><br><span class="line"><span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key1)</span><br></pre></td></tr></table></figure>

<h3 id="LEFT-OUTER-JOIN"><a href="#LEFT-OUTER-JOIN" class="headerlink" title="LEFT OUTER JOIN"></a>LEFT OUTER JOIN</h3><p>LEFT OUTER JOIN 和 LEFT JOIN 是等价的。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 左连接</span></span><br><span class="line"><span class="keyword">SELECT</span> e.<span class="operator">*</span>,d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> emp e <span class="keyword">LEFT</span> <span class="keyword">OUTER</span>  <span class="keyword">JOIN</span>  dept d</span><br><span class="line"><span class="keyword">ON</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="RIGHT-OUTER-JOIN"><a href="#RIGHT-OUTER-JOIN" class="headerlink" title="RIGHT OUTER JOIN"></a>RIGHT OUTER JOIN</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--右连接</span></span><br><span class="line"><span class="keyword">SELECT</span> e.<span class="operator">*</span>,d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> emp e <span class="keyword">RIGHT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span>  dept d</span><br><span class="line"><span class="keyword">ON</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>

<p>执行右连接后，由于 40 号部门下没有任何员工，所以此时员工信息为 NULL。这个查询可以很好的复述上面提到的——JOIN 语句的关联条件必须用 ON 指定，不能用 WHERE 指定。你可以把 ON 改成 WHERE，你会发现无论如何都查不出 40 号部门这条数据，因为笛卡尔运算不会有 (NULL, 40) 这种情况。</p>
<p><img src="https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-right-join.png" alt="img"></p>
<h3 id="FULL-OUTER-JOIN"><a href="#FULL-OUTER-JOIN" class="headerlink" title="FULL OUTER JOIN"></a>FULL OUTER JOIN</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e.<span class="operator">*</span>,d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> emp e <span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span>  dept d</span><br><span class="line"><span class="keyword">ON</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="LEFT-SEMI-JOIN"><a href="#LEFT-SEMI-JOIN" class="headerlink" title="LEFT SEMI JOIN"></a>LEFT SEMI JOIN</h3><p>LEFT SEMI JOIN （左半连接）是 IN&#x2F;EXISTS 子查询的一种更高效的实现。</p>
<ul>
<li>JOIN 子句中右边的表只能在 ON 子句中设置过滤条件;</li>
<li>查询结果只包含左边表的数据，所以只能 SELECT 左表中的列。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查询在纽约办公的所有员工信息</span></span><br><span class="line"><span class="keyword">SELECT</span> emp.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> emp <span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> dept</span><br><span class="line"><span class="keyword">ON</span> emp.deptno <span class="operator">=</span> dept.deptno <span class="keyword">AND</span> dept.loc<span class="operator">=</span>&quot;NEW YORK&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">--上面的语句就等价于</span></span><br><span class="line"><span class="keyword">SELECT</span> emp.<span class="operator">*</span> <span class="keyword">FROM</span> emp</span><br><span class="line"><span class="keyword">WHERE</span> emp.deptno <span class="keyword">IN</span> (<span class="keyword">SELECT</span> deptno <span class="keyword">FROM</span> dept <span class="keyword">WHERE</span> loc<span class="operator">=</span>&quot;NEW YORK&quot;);</span><br></pre></td></tr></table></figure>

<h3 id="JOIN"><a href="#JOIN" class="headerlink" title="JOIN"></a>JOIN</h3><p>笛卡尔积连接，这个连接日常的开发中可能很少遇到，且性能消耗比较大，基于这个原因，如果在严格模式下 (hive.mapred.mode &#x3D; strict)，Hive 会阻止用户执行此操作。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">JOIN</span> dept;</span><br></pre></td></tr></table></figure>

<h2 id="JOIN-优化"><a href="#JOIN-优化" class="headerlink" title="JOIN 优化"></a>JOIN 优化</h2><h3 id="STREAMTABLE"><a href="#STREAMTABLE" class="headerlink" title="STREAMTABLE"></a>STREAMTABLE</h3><p>在多表进行联结的时候，如果每个 ON 字句都使用到共同的列（如下面的 <code>b.key</code>），此时 Hive 会进行优化，将多表 JOIN 在同一个 map &#x2F; reduce 作业上进行。同时假定查询的最后一个表（如下面的 c 表）是最大的一个表，在对每行记录进行 JOIN 操作时，它将尝试将其他的表缓存起来，然后扫描最后那个表进行计算。因此用户需要保证查询的表的大小从左到右是依次增加的。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`<span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key)`</span><br></pre></td></tr></table></figure>

<p>然后，用户并非需要总是把最大的表放在查询语句的最后面，Hive 提供了 <code>/*+ STREAMTABLE() */</code> 标志，用于标识最大的表，示例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ STREAMTABLE(d) */</span>  e.<span class="operator">*</span>,d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> emp e <span class="keyword">JOIN</span> dept d</span><br><span class="line"><span class="keyword">ON</span> e.deptno <span class="operator">=</span> d.deptno</span><br><span class="line"><span class="keyword">WHERE</span> job<span class="operator">=</span><span class="string">&#x27;CLERK&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="MAPJOIN"><a href="#MAPJOIN" class="headerlink" title="MAPJOIN"></a>MAPJOIN</h3><p>如果所有表中只有一张表是小表，那么 Hive 把这张小表加载到内存中。这时候程序会在 map 阶段直接拿另外一个表的数据和内存中表数据做匹配，由于在 map 就进行了 JOIN 操作，从而可以省略 reduce 过程，这样效率可以提升很多。Hive 中提供了 <code>/*+ MAPJOIN() */</code> 来标记小表，示例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(d) */</span> e.<span class="operator">*</span>,d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> emp e <span class="keyword">JOIN</span> dept d</span><br><span class="line"><span class="keyword">ON</span> e.deptno <span class="operator">=</span> d.deptno</span><br><span class="line"><span class="keyword">WHERE</span> job<span class="operator">=</span><span class="string">&#x27;CLERK&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h2 id="SELECT-的其他用途"><a href="#SELECT-的其他用途" class="headerlink" title="SELECT 的其他用途"></a>SELECT 的其他用途</h2><p>查看当前数据库：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> current_database()</span><br></pre></td></tr></table></figure>

<h2 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h2><p>在上面演示的语句中，大多数都会触发 MapReduce, 少部分不会触发，比如 <code>select * from emp limit 5</code> 就不会触发 MR，此时 Hive 只是简单的读取数据文件中的内容，然后格式化后进行输出。在需要执行 MapReduce 的查询中，你会发现执行时间可能会很长，这时候你可以选择开启本地模式。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--本地模式默认关闭，需要手动开启此功能</span></span><br><span class="line"><span class="keyword">SET</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>启用后，Hive 将分析查询中每个 map-reduce 作业的大小，如果满足以下条件，则可以在本地运行它：</p>
<ul>
<li>作业的总输入大小低于：hive.exec.mode.local.auto.inputbytes.max（默认为 128MB）；</li>
<li>map-tasks 的总数小于：hive.exec.mode.local.auto.tasks.max（默认为 4）；</li>
<li>所需的 reduce 任务总数为 1 或 0。</li>
</ul>
<p>因为我们测试的数据集很小，所以你再次去执行上面涉及 MR 操作的查询，你会发现速度会有显著的提升。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">LanguageManual Select</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins">LanguageManual Joins</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+GroupBy">LanguageManual GroupBy</a></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SortBy">LanguageManual SortBy</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/26/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><span class="page-number current">27</span><a class="page-number" href="/page/28/">28</a><span class="space">&hellip;</span><a class="page-number" href="/page/47/">47</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/28/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2015 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">李狗蛋</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">3.5m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">53:28</span>
  </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/yiyirushi/" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  




<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
